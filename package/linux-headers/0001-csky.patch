diff --git a/README.md b/README.md
new file mode 100644
index 0000000..33ba312
--- /dev/null
+++ b/README.md
@@ -0,0 +1,58 @@
+# Linux/arch/csky
+
+## Introduction
+
+C-SKY linux consisted of standard linux kernel source with arch/csky repo:
+
+https://github.com/c-sky/csky-linux.git
+
+## Setup linux kernel source with copy
+
+```sh
+    # Download the kernel source
+	$ wget https://cdn.kernel.org/pub/linux/kernel/v4.x/linux-4.9.22.tar.gz
+	$ tar zxvf linux-4.9.22.tar.gz
+
+    # Get code from arch/csky repo, and copy if to kernel source
+	$ git clone https://github.com/c-sky/csky-linux.git
+	$ cp csky-linux/arch/csky linux-4.9.22/arch/ -raf
+
+    # Use an empty addons
+	$ cd linux-4.9.22
+	$ mkdir addons
+	$ touch addons/Kconfig
+	$ touch addons/Makefile
+	$ touch addons/none.c
+	$ echo "obj-y += none.o" > addons/Makefile
+
+```
+Now linux-4.9.22 is finished with arch of C-SKY implement.
+
+## Setup linux kernel source with git merge
+
+```sh
+    # Download kernel source, and setup init repo
+	$ wget https://cdn.kernel.org/pub/linux/kernel/v4.x/linux-4.9.22.tar.gz
+	$ tar zxvf linux-4.9.22.tar.gz
+
+    # Use an empty addons
+	$ cd linux-4.9.22
+	$ mkdir addons
+	$ touch addons/Kconfig
+	$ touch addons/Makefile
+	$ touch addons/none.c
+	$ echo "obj-y += none.o" > addons/Makefile
+
+    # Setup local .git
+	$ git init .
+	$ git add .
+	$ git commit -m "init"
+ 
+    # Setup arch csky
+	$ git remote add csky https://github.com/c-sky/csky-linux.git
+	$ git pull csky master
+
+    # Push to your own repo
+	$ git remote add my_repo git://myrepo.git
+	$ git push my_repo master
+```
diff --git a/arch/csky/ChangeLog b/arch/csky/ChangeLog
new file mode 100644
index 0000000..1a72451
--- /dev/null
+++ b/arch/csky/ChangeLog
@@ -0,0 +1,1952 @@
+2015-08-05 Chen linfei <linfei_chen@c-sky.com>
+
+	* arch/csky/kernel/entry.S:
+		Fix bug: tlbinvalid or tlbmodified may occurred utlb,
+			and the mapping isnot in jtlb.
+
+2015-06-30 Chen linfei <linfei_chen@c-sky.com>
+
+	* arch/csky/Kconfig:
+	* arch/csky/ck6408evb/config.c:
+	* arch/csky/ck6408evb/timer.c:
+		Support CK6408evb hrtimer.
+
+2015-06-11 Han weidong <weidong_han@c-sky.com>
+
+	* arch/csky/ck6408evb/include/mach/cklcd.h:
+	* arch/csky/ck6408evb/devices.c:
+	* drivers/video/csky_fb.c:
+		Fix: lcd driver.
+
+2015-06-19 Han weidong <weidong_han@c-sky.com>
+
+	* arch/csky/ck6408evb/include/mach/board.h:
+	* arch/csky/ck6408evb/include/mach/cksdhc.h:
+	* drivers/mmc/core/sd.c:
+	* drivers/mmc/host/cskymci.c:
+		Fix: sdhc driver.
+
+2015-06-11 Chen linfei <linfei_chen@c-sky.com>
+
+	* arch/csky/boot/compressed/head.S:
+	* arch/csky/boot/compressed/misc.c:
+	* arch/csky/boot/compressed/vmlinux.lds.in:
+	* arch/csky/ck6408evb/Makefile.boot:
+		Fix: If (S)DRAM base address is between 0x80000000 to 0xbfffffff,
+		     we cannot use the tlb map in start code, just use mcr30 and mcr31...
+
+2015-04-29 Chen linfei <linfei_chen@c-sky.com>
+
+	* arch/csky/include/asm/io.h:
+		Add ioread16 etc.
+
+2015-04-20 Chen linfei <linfei_chen@c-sky.com>
+
+	* arch/csky/mm/ioremap.c:
+		Add ksyms: __ioremap_mode.
+
+2015-04-13 Chen linfei <linfei_chen@c-sky.com>
+
+	* arch/csky/kernel/csky_ksyms.c:
+		Add ksyms: flush_dcache_page.
+
+2015-03-01 Chen linfei <linfei_chen@c-sky.com>
+
+	* arch/csky/configs/ck6408evb_ck610f_board_defconfig:
+	* arch/csky/configs/ck6408evb_ck610f_qemu_defconfig:
+	* arch/csky/configs/ck6408evb_ck810f_board_defconfig:
+	* arch/csky/configs/ck6408evb_ck810f_qemu_defconfig:
+		Add ck6408evb board and qemu defconfig.
+
+2015-01-21 Chen linfei <linfei_chen@c-sky.com>
+
+	* arch/csky/lib/memcpy_abiv1.S:
+		Fix: address overlap condition.
+
+2015-01-20 Chen linfei <linfei_chen@c-sky.com>
+
+	* arch/csky/lib/Makefile:
+	* arch/csky/lib/memcpy_abiv1.S:
+		Optimize: abiv1 memcpy.
+		If src or dest is misaligned, we piece together a word...
+
+2015-01-20 zhang wenmeng <wenmeng_zhang@c-sky.com>
+
+	* arch/csky/include/asm/delay.h:
+		BogoMIPS: declt + bf should use 2 clcye.
+
+2015-01-08 Chen linfei <linfei_chen@c-sky.com>
+
+	* arch/csky/kernel/module.c:
+		Relocate jsri, "jsri + nop" --> "lrw + jsr".
+
+2015-01-04 Chen linfei <linfei_chen@c-sky.com>
+
+	* arch/csky/include/asm/setup.h:
+		Modify COMMAND_LINE_SIZE: 256 -> 1024.
+
+2015-01-04 Chen linfei <linfei_chen@c-sky.com>
+
+	* arch/csky/boot/compressed/head.S:
+		Fix: jump from USEG to SSEG0 after enable mmu.
+
+2014-12-28 Chen linfei <linfei_chen@c-sky.com>
+
+	* arch/csky/include/asm/cacheflush.h:
+		Fix: compile warning.
+
+2014-11-30 Chen linfei <linfei_chen@c-sky.com>
+
+	* arch/csky/boot/compressed/head.S:
+		Fix: add alignment + stack.
+
+2014-11-28 Chen linfei <linfei_chen@c-sky.com>
+
+	* arch/csky/boot/compressed/Makefile:
+	* arch/csky/boot/compressed/decompress.c:
+	* arch/csky/boot/compressed/head.S:
+	* arch/csky/boot/compressed/misc.c:
+	* arch/csky/boot/compressed/vmlinux.lds.in:
+		Support lzma decompression.
+
+2014-11-28 Chen linfei <linfei_chen@c-sky.com>
+
+	* arch/csky/Kconfig:
+	* arch/csky/kernel/head.S:
+		Add CK610 double data cache line config.
+
+2014-11-24 Chen linfei <linfei_chen@c-sky.com>
+
+	* arch/csky/mm/tlbv1.c:
+		Old CK610M does not have tlb invalid index function.
+		Changing ASID can flush utlb too.
+
+2014-11-12 Chen linfei <linfei_chen@c-sky.com>
+
+	* arch/csky/include/asm/ckmmuv1.h:
+	* arch/csky/include/asm/ckmmuv2.h:
+		dos2unix.
+
+2014-11-12 Chen linfei <linfei_chen@c-sky.com>
+
+	* arch/csky/include/asm/shmparam.h:
+	* arch/csky/mm/mmap.c:
+		Restore SHMLBA, for ltp case shmat01 crashed.
+
+2014-10-15 Chen linfei <linfei_chen@c-sky.com>
+
+	* arch/csky/include/asm/page.h:
+		If cache alias, flush cache in copy_user_page.
+
+2014-10-10 Chen linfei <linfei_chen@c-sky.com>
+
+	* arch/csky/include/asm/io.h:
+		optimize dma_cache_inv, dma_cache_wback, dma_cache_wback_inv.
+
+2014-10-10 Chen linfei <linfei_chen@c-sky.com>
+
+	* arch/csky/mm/fault.c:
+		add '&', then '%0' and '%1' will use different registers.
+
+2014-10-09 Zhang wenmeng <linfei_chen@c-sky.com>
+
+	* arch/csky/mm/cachev1.c:
+		CACHE: disable irq before flush cache which will prevent schedule.
+
+2014-10-08 Chen linfei <linfei_chen@c-sky.com>
+
+	* arch/csky/kernel/entry.S:
+		for abiv2 compile.
+
+2014-10-08 Chen linfei <linfei_chen@c-sky.com>
+
+	* arch/csky/kernel/entry.S:
+		Fix trap2 atomic operations.
+		The "stw a1, (a2)" may produce tlbmodified exception, then may cause schedule.
+
+2014-09-23 Zhang wenmeng <wenmeng_zhang@c-sky.com>
+
+	* arch/csky/kernel/head.S
+		MMU: bit 26 is invalid flush all.
+
+2014-09-22 Chen linfei <linfei_chen@c-sky.com>
+
+	* arch/csky/boot/compressed/head.S:
+		if EntryLo's "C" bit is disabled, compression will be very slow.
+
+2014-09-22 Chen linfei <linfei_chen@c-sky.com>
+
+	* arch/csky/Kconfig:
+	* arch/csky/boot/compressed/Makefile:
+		add configuration of compression.
+
+2014-09-22 Chen linfei <linfei_chen@c-sky.com>
+
+	* arch/csky/include/asm/ckmmuv1.h:
+	* arch/csky/include/asm/ckmmuv2.h:
+	* arch/csky/mm/tlbv1.c:
+	* arch/csky/mm/tlbv2.c:
+		while tlb probe failed, the mappings maybe in utlb, we should invalid it.
+
+2014-09-14 Chen linfei <linfei_chen@c-sky.com>
+
+	* arch/csky/Kconfig:
+	* arch/csky/include/asm/page.h:
+	* arch/csky/include/asm/shmparam.h:
+	* arch/csky/mm/cache.c:
+		add config for cache size. cache alias if cache size >= 16KByte.
+		if cache alias, flush cache in clear_user_page.
+
+2014-09-01 Zhang wenmeng <wenmeng_zhang@c-sky.com>
+	* arch/csky/include/asm/pgtable.h
+		CACHE: add cache flush to pte_clear, while using hardrefill.
+
+2014-08-13 Zhang wenmeng <wenmeng_zhang@c-sky.com>
+	* arch/csky/kernel/head.S
+	* arch/csky/kernel/process.c
+	* arch/csky/kernel/head-nommu.S
+	* arch/csky/kernel/entry.S
+	* arch/csky/boot/compressed/head.S
+		OPTIMIZE: change jsri to jbsr.
+
+2014-08-11 Zhang wenmeng <wenmeng_zhang@c-sky.com>
+	* arch/csky/kernel/head.S
+		OPTIMIZE: change jsri to jmpi.
+
+2014-08-07 Chen linfei <linfei_chen@c-sky.com>
+
+	* arch/csky/include/asm/mmu_context.h:
+	* arch/csky/include/asm/page-nommu.h:
+	* arch/csky/include/asm/page.h:
+	* arch/csky/kernel/entry.S:
+	* arch/csky/kernel/vmlinux.lds.S:
+	* arch/csky/mm/fault.c:
+		optimize function: CONFIG_PHYSICAL_BASE_CHANGE.
+
+2014-08-04 Chen linfei <linfei_chen@c-sky.com>
+
+	* arch/csky/ck6408evb/timer.c:
+		fix gettimeofday. tcn * (1000000 / HZ) maybe overflow.
+
+2014-07-29 Chen linfei <linfei_chen@c-sky.com>
+
+	* arch/csky/kernel/head.S:
+		select cp15 first.
+
+2014-07-02 Zhang wenmeng <wenmeng_zhang@c-sky.com>
+	* arch/csky/include/asm/uaccess.h
+		copy_to_user: bf --> br. a slip of the pen.
+
+2014-06-26 Chen linfei <linfei_chen@c-sky.com>
+	* arch/csky/include/asm/elf.h:
+	* arch/csky/kernel/module.c:
+		add relocate R_CSKY_PCRELJSR_IMM26BY2.
+
+2014-06-26 Zhang wenmeng <wenmeng_zhang@c-sky.com>
+	* arch/csky/kernel/setup.c
+	* arch/csky/mm/cache.c
+	* arch/csky/mm/highmem.c
+	* arch/csky/mm/tlbv1.c
+	* arch/csky/mm/tlbv2.c
+		highmem: fix ck610 highmem support.
+
+2014-06-09 Zhang wenmeng <wenmeng_zhang@c-sky.com>
+	* arch/csky/include/asm/processor.h
+		NOMMU: delete HAVE_ARCH_PICK_MMAP_LAYOUT
+
+2014-06-04 Zhang wenmeng <wenmeng_zhang@c-sky.com>
+
+	* arch/csky/Kconfig
+	* arch/csky/include/asm/entry.h
+	* arch/csky/include/asm/io.h
+	* arch/csky/include/asm/page.h
+	* arch/csky/include/asm/virtconvert.h
+	* arch/csky/kernel/head.S
+	* arch/csky/kernel/vmlinux.lds.S
+	* arch/csky/mm/dma-mapping.c
+	* arch/csky/mm/ioremap.c
+		MMU: support cp15_cr30 and cp15_cr31 setting.
+
+2014-05-30 Zhang wenmeng <wenmeng_zhang@c-sky.com>
+	* arch/csky/boot/Makefile
+	* arch/csky/boot/compressed/head.S
+		boot: fix bootargs.
+
+2014-05-22 Zhang wenmeng <wenmeng_zhang@c-sky.com>
+	* arch/csky/include/asm/cache.h
+	* arch/csky/kernel/head.S
+	* arch/csky/mm/cachev2.c
+	* arch/csky/mm/l2cache.c
+		cache: change register number for compatibility.
+
+2014-05-04 Chen linfei <linfei_chen@c-sky.com>
+	* arch/csky/mm/tlbv1.c
+	* arch/csky/mm/tlbv2.c
+		highmem: tlb probe fix.
+
+2014-04-24 Zhang wenmeng <wenmeng_zhang@c-sky.com>
+	* arch/csky/kernel/vmlinux.lds.S
+		ld script: beginnig of using the vmlinux's LMA.
+
+2014-03-07 Zhang wenmeng <wenmeng_zhang@c-sky.com>
+	* arch/csky/include/asm/uaccess.h
+		optimal performance for copy_to_user/copy_from_user.
+
+2014-03-06 Zhang wenmeng <wenmeng_zhang@c-sky.com>
+	* arch/csky/mm/cachev1.c
+		cache: avoid 610 hardware bug.
+
+2013-06-14 Hu junshan <junshan_hu@c-sky.com>
+
+	* arch/csky/kernel/asm-offsets.c:
+	* arch/csky/kernel/process.c:
+	* arch/csky/kernel/ptrace.c:
+	* arch/csky/kernel/signal.c:
+	* include/asm-csky/fpu.h:
+	* include/asm-csky/ptrace.h:
+	* include/asm-csky/processor.h:
+	* include/asm-csky/sigcontext.h:
+	* include/asm-csky/user.h:
+	    optimize fpu embedded assemble code and add fcr reg in fpu context
+	     for glibc.
+
+2013-06-08 Hu junshan <junshan_hu@c-sky.com>
+
+	* arch/csky/kernel/traps.c:
+		some reg fcr of ck610 only R/W in super mode, so fix it.
+
+2013-05-28 Hu junshan <junshan_hu@c-sky.com>
+
+	* arch/csky/Makefile:
+		Need not define UTS_SYSNAME for uname error in LTP test,
+		 by default UTS_SYSNAME="Linux".  
+
+2013-05-27 Hu junshan <junshan_hu@c-sky.com>
+
+	* arch/csky/kernel/process.c:
+		optimize function kernel_thread by reference arm/mips.
+
+2013-05-27 Hu junshan <junshan_hu@c-sky.com>
+
+	* arch/csky/kernel/entry.S:
+	* arch/csky/kernel/vdso.c:
+		get_tls use trap 3 in ck610, because it's difficult to use vdso.
+
+2013-05-27 Hu junshan <junshan_hu@c-sky.com>
+
+	* arch/csky/include/asm/futex.h:
+		update file futex.h to fixup some bugs in libc test.
+
+2013-05-27 Hu junshan <junshan_hu@c-sky.com>
+
+	* arch/csky/kernel/signal.c:
+		sigstack may NULL when pass flag SA_ONSTACK, so ignore it.
+
+2013-05-27 Hu junshan <junshan_hu@c-sky.com>
+
+	* arch/csky/kernel/entry.S:
+		add syscall pselect6 and ppoll support.
+		optimize code for trap3 exception.
+
+2013-05-06 Hu junshan <junshan_hu@c-sky.com>
+
+	* arch/csky/kernel/setup.c:
+		Optimize /proc/cpuinfo for match get_hardware in android init.
+
+2013-05-06 Hu junshan <junshan_hu@c-sky.com>
+
+	* arch/csky/kernel/entry.S:
+	* arch/csky/kernel/process.c:
+	* arch/csky/kernel/vdso.c:
+		Optimize ck610 get tls by use VDSO.
+
+2013-04-15 Hu junshan <junshan_hu@c-sky.com>
+
+	* arch/csky/include/asm/elf.h:
+	* arch/csky/kernel/process.c:
+		fix bug when GDB use coredump function.
+
+2013-04-12 Hu junshan <junshan_hu@c-sky.com>
+
+	* arch/csky/boot/Makefile:
+		Otimize boot/Makefile.
+
+2013-04-12 Hu junshan <junshan_hu@c-sky.com>
+
+	* arch/csky/mm/dma-mapping.c:
+	* arch/csky/include/asm/dma-mapping.h:
+	* arch/csky/include/asm/sizes.h:
+		add file asm/sizes.h and optimize dma-mapping function.
+
+2013-04-11 Hu junshan <junshan_hu@c-sky.com>
+
+	* arch/csky/BOARD/config.c:
+	* arch/csky/BOARD/devices.c:
+	* arch/csky/kernel/setup.c:
+	* arch/csky/kernel/time.c:
+	* arch/csky/include/asm/machdep.h:
+		optimize API mach_time_init.	
+
+2013-04-08 Hu junshan <junshan_hu@c-sky.com>
+
+	* arch/csky/ck6408evb/Kconfig:
+	* arch/csky/ck6408evb/config.c:
+	* arch/csky/ck6408evb/devices.c:
+	* arch/csky/ck6408evb/devices.h:
+	* arch/csky/ck6408evb/include/mach/ck_iomap.h:
+	* arch/csky/ck6408evb/include/mach/irqs.h:
+		add platform trilobite v9-1 in board ck6408evb.
+
+2013-03-22 Chen linfei <linfei_chen@c-sky.com>
+
+	* driver/i2c/busses/i2c-ck6408.c:
+	* arch/csky/ck6408evb/devices.c:
+		optimize i2c driver.
+
+2013-03-21 Hu junshan <junshan_hu@c-sky.com>
+
+	* arch/csky/ck6408evb/include/mach/ckspi.h:
+	* arch/csky/ck6408evb/config.c:
+	* arch/csky/ck6408evb/device.c:
+	* drivers/spi/spi_ck6408.c:
+	    add csky spi driver.
+
+2013-03-21 Hu junshan <junshan_hu@c-sky.com>
+
+	* arch/csky/include/asm/cache.h:
+		We use MACRO ARCH_SLAB_MINALIGN to let the stack pointer align
+		with 8 for NOMMU's CPU.
+
+2013-03-20 Zhang Wenmeng <wenmeng_zhang@c-sky.com>
+
+	* include/asm/entry.h:
+	* include/asm/mmu_context.h:
+	* kernel/entry.S:
+	* mm/fault.c:
+		add ck610 mmu hard refill function.
+
+2013-03-18 Hu Junshan <junshan_hu@c-sky.com>
+
+	* arch/csky/include/asm/cacheflush.h
+	* arch/csky/include/asm/io.h:
+	* arch/csky/mm/ioremap.c:
+		fix compile error when config android pmem.
+
+2013-03-18 Hu Junshan <junshan_hu@c-sky.com>
+
+	* arch/csky/boot/compressed/head.S:
+		add MGU spuuort.
+
+2013-03-18 Hu Junshan <junshan_hu@c-sky.com>
+
+	* arch/csky/include/asm/highmem.h:
+	* arch/csky/mm/highmem.c:
+		delete compile error for highmem.
+
+2013-03-12 Chen Linfei <linfei_chen@c-sky.com>
+
+	* driver/video/csky_fb.c:
+		fix LCD driver bug, CSKY_LCD_SOURCE_SIZE register
+		 only in DIOSCURI.
+
+2013-03-12 Chen Linfei <linfei_chen@c-sky.com>
+
+	* arch/csky/lib/checksum.c:
+		fix bug of telnet(endian error).
+
+2013-03-12 Chen Linfei <linfei_chen@c-sky.com>
+
+	* arch/csky/include/asm/unistd.h:
+	* arch/csky/kernel/entry.S:
+		function sync_file_range use syscall sys_sync_file_rang2.
+
+2013-03-12 Chen Linfei <linfei_chen@c-sky.com>
+
+	* arch/csky/include/asm/uaccess.h:
+		fix bug of function __puter_asm_64.
+
+2013-03-12 Chen Linfei <linfei_chen@c-sky.com>
+
+	* arch/csky/kernel/sys_csky.c:
+	* arch/csky/kernel/entry.S:
+		Since syscall sys_fadvise64_64 has loff_t stye params,
+		 but loff_t is a 64 bit type we avoid a lot of ABI hassle
+		 with a different argument ordering.
+
+2013-03-12 Chen Linfei <linfei_chen@c-sky.com>
+
+	* arch/csky/dioscuri/devices.c:
+		fix new MAC driver bug.
+
+2013-02-01 Hu Junshan <junshan_hu@c-sky.com>
+
+	* arch/csky/kernel/entry.S:
+	* arch/csky/kernel/signal.c:
+	* arch/csky/include/asm/unistd.h:
+		optimize syscall sigreturn and rt_sigreturn.
+
+2013-02-01 Hu Junshan <junshan_hu@c-sky.com>
+
+	* arch/csky/kernel/entry.S:
+	* arch/csky/kernel/signal.c:
+		Fix bug in LTP case(clone02), use r11 to judge restart syscall.
+
+2013-02-01 Hu Junshan <junshan_hu@c-sky.com>
+
+	* arch/csky/include/asm/elf.h:
+	* arch/csky/include/asm/mmu.h:
+	* arch/csky/include/asm/mmu_context.h:
+	* arch/csky/include/asm/processor.h:
+	* arch/csky/kernel/Makefile:
+	* arch/csky/kernel/signal.c:
+	* arch/csky/mm/mmap.c:
+	* arch/csky/include/asm/vdso.h:
+	* arch/csky/kernel/vdso.c:
+		add vdso support, which let sigreturn code not flush cache.
+	
+2013-01-29 Hu Junshan <junshan_hu@c-sky.com>
+
+	* arch/csky/kernel/signal.c:
+		sig_setframe write syscall sigreturn need flush dcache and icache.
+	
+2013-01-29 Hu Junshan <junshan_hu@c-sky.com>
+
+	* arch/csky/include/asm/fpu.h:
+		fix bug when vfp init.	
+
+2013-01-25 Mao Han <han_mao@c-sky.com>
+
+	* arch/csky/boot/compressed/head.S:
+	* arch/csky/boot/compressed/Makefile:
+	* arch/csky/boot/compressed/misc.c:
+	* arch/csky/boot/compressed/piggy.S:
+	* arch/csky/boot/compressed/vmlinux.lds.in:
+	* arch/csky/boot/compressed/Makefile.debug:
+	* arch/csky/ck6408evb/Makefile.boot:
+	* arch/csky/ck6408evb/include/mach/uncompress.h:
+	* arch/csky/dioscuri/Makefile.boot:
+	* arch/csky/dioscuri/include/mach/uncompress.h:
+		optimize zimage by reference arm.
+
+2013-01-14 Zhang Wenmeng <wenmeng_zhang@c-sky.com>
+
+	* arch/csky/include/asm/outercache.h:
+	* arch/csky/mm/cachev2.c:
+	* arch/csky/mm/l2cache.c:
+	* arch/csky/Kconfig:
+	* arch/csky/include/asm/cache.h:
+	* arch/csky/include/asm/cacheflush.h:
+	* arch/csky/kernel/head.S:
+	* arch/csky/mm/Makefile:
+		add ck810 cache line flush function.
+
+2013-01-09 Chen Linfei <linfei_chen@c-sky.com>
+
+	* driver/net/Makefile:
+	* driver/net/Kconfig:
+	* driver/net/cskymac.h:
+	* driver/net/cskymac.c:
+		add ck6408evb mac driver.
+
+2013-01-09 Chen Linfei <linfei_chen@c-sky.com>
+
+	* arch/csky/include/asm/prfl.h:
+	* arch/csky/kernel/entry.S:
+		move hardware profile regs context switch as a macro.
+
+2013-01-09 Chen Linfei <linfei_chen@c-sky.com>
+
+	* arch/csky/Kconfig:
+	* arch/csky/include/asm/entry.h:
+	* arch/csky/include/asm/fpu.h:
+	* arch/csky/include/asm/processor.h:
+	* arch/csky/include/asm/ptrace.h:
+	* arch/csky/include/asm/regdef.h:
+	* arch/csky/include/asm/sigcontext.h:
+	* arch/csky/include/asm/system.h:
+	* arch/csky/include/asm/user.h:
+	* arch/csky/kernel/alignment.c:
+	* arch/csky/kernel/asm-offsets.c:
+	* arch/csky/kernel/entry.S:
+	* arch/csky/kernel/process.c:
+	* arch/csky/kernel/ptrace.c:
+	* arch/csky/kernel/signal.c:
+	* arch/csky/kernel/sys_csky.c:
+	* arch/csky/kernel/traps.c:
+		kernel use compiler's ABI macro and support VFP(for ck800).
+
+2013-01-09 Chen Linfei <linfei_chen@c-sky.com>
+
+	* arch/csky/kernel/signal.c:
+		optimize signal handle.
+
+2013-01-09 Chen Linfei <linfei_chen@c-sky.com>
+
+	* arch/csky/include/asm/thread_info.h:
+	* arch/csky/kernel/entry.S:
+		optimize sig and sched flags by reference ARM and MIPS.
+
+2013-01-03 Hu Junshan <junshan_hu@c-sky.com>
+
+	* arch/csky/ck6408evb/config.c:
+	* arch/csky/dioscuri/config.c:
+	* arch/csky/include/asm/cpu.h:
+	* arch/csky/include/asm/machdep.h:
+	* arch/csky/kernel/cpu-probe.c:
+	* arch/csky/kernel/setup.c:
+		optimize cpuinfo and cpu probe.
+
+2013-01-03 Hu Junshan <junshan_hu@c-sky.com>
+
+	* arch/csky/kernel/entry.S:
+		fixup compile bug when use hardware refill tlbmiss exception in ck810.
+
+2012-12-28 Hu Junshan <junshan_hu@c-sky.com>
+
+	* arch/csky/include/asm/irqflags.h:
+		add membarrier when lock irq operation, it may bring bug if not do.
+
+2012-12-27 Hu Junshan <junshan_hu@c-sky.com>
+
+	* arch/csky/kernel/module.c:
+		kernel module handle relocat R_CSKY_PCRELJSR_IMM11BY2.
+
+2012-12-27 Hu Junshan <junshan_hu@c-sky.com>
+
+	* arch/csky/kernel/alignment.c:
+		fixup alignment exception handle bug in ck610(because struct pt_regs 
+		 changed). 
+
+2012-12-27 Hu Junshan <junshan_hu@c-sky.com>
+
+	* arch/csky/Kconfig:
+		optimize nommu config. 
+
+2012-12-20 Hu Junshan <junshan_hu@c-sky.com>
+
+	* arch/csky/Kconfig:
+	* arch/csky/include/asm/processor.h:
+	* arch/csky/include/asm/traps.h:
+	* arch/csky/include/asm/unistd.h:
+	* arch/csky/include/asm/user.h:
+	* arch/csky/kernel/asm-offsets.:
+	* arch/csky/kernel/entry.S:
+	* arch/csky/kernel/process.c:
+	* arch/csky/kernel/sys_csky.c:
+	* arch/csky/include/asm/prfl.h:
+		add hardware profiling in some ck810.
+
+2012-12-12 Hu Junshan <junshan_hu@c-sky.com>
+
+	* arch/csky/Kconfig:
+	* arch/csky/include/asm/cache.h:
+	* arch/csky/include/asm/cacheflush.h:
+	* arch/csky/mm/cachev1.c:
+		add ck610 cache line flush.
+
+2012-12-12 Hu Junshan <junshan_hu@c-sky.com>
+
+	* arch/csky/kernel/entry.S:
+	* arch/csky/kernel/traps.c:
+		optimize tlbmiss exception handle.
+
+2012-12-12 Hu Junshan <junshan_hu@c-sky.com>
+
+	* arch/csky/include/asm/processor.h:
+	* arch/csky/include/asm/ptrace.h:
+	* arch/csky/include/asm/user.h:
+	* arch/csky/kernel/entry.S:
+	* arch/csky/kernel/ptrace.c:
+		optimize for gdbserver and strace..
+
+2012-12-12 Hu Junshan <junshan_hu@c-sky.com>
+
+	* arch/csky/include/asm/pgtable.h:
+		fix bug when page convert(page flags = IS_ZERO).
+
+2012-12-12 Hu Junshan <junshan_hu@c-sky.com>
+
+	* arch/csky/kernel/entry.S:
+	* arch/csky/kernel/sys_csky.c:
+		1. Delete csky_pread/csky_pwrite but use sys_pread64/sys_pwrite64, 
+		 for long long type endian format.
+		2. let exception trap 2 as function kernel_cmpxchg.
+
+2012-12-12 Hu Junshan <junshan_hu@c-sky.com>
+
+	* arch/csky/ck6408evb/devices.c:
+	* arch/csky/dioscuri/devices.c:
+		fb need init displays to fix bug: FBIOPUT_VSCREENINFO failed.
+
+2012-12-12 Hu Junshan <junshan_hu@c-sky.com>
+
+	* arch/csky/Kconfig:
+		add power managerment config.
+
+2012-12-12 Hu Junshan <junshan_hu@c-sky.com>
+
+	* arch/csky/mm/tlbv1.c:
+		fix bug in function local_flush_tlb_kernel_range, is bad use ASID and
+		 bit G.
+
+2012-12-12 Hu Junshan <junshan_hu@c-sky.com>
+
+	* drivers/...:
+		update csky's i2c, mmc, rtc, usb and lcd driver
+
+2012-10-29 Hu Junshan <junshan_hu@c-sky.com>
+
+	* arch/csky/kernel/entry.S:
+	* arch/csky/kernel/process.c:
+	* arch/csky/kernel/process.c:
+	* arch/csky/kernel/sys_csky.c:
+		support tls reg(r31) in ck810 and change syscall clone from
+		 csky_clone(struct pt_regs *regs) to 
+		 csky_clone(unsigned long clone_flags, unsigned long newsp,
+		           int __user *parent_tidptr, int __user *child_tidptr,
+		           int tls_val, struct pt_regs *regs)
+
+2012-10-26 Chen Linfei <linfei_chen@c-sky.com>
+
+	* arch/csky/ck6408evb/devices.c:
+	* arch/csky/ck6408evb/config.c:
+	* arch/csky/ck6408evb/devices.h:
+		add board ck6408evb's rtc and i2c platform resource.
+
+2012-10-26 Chen Linfei <linfei_chen@c-sky.com>
+
+	* drivers/input/keyboard/Kconfig:
+	* drivers/input/keyboard/Makefile:
+	* drivers/input/keyboard/ck6408-keypad.c:
+		add csky i2c keyboard driver.
+
+2012-10-26 Chen Linfei <linfei_chen@c-sky.com>
+
+	* drivers/i2c/busses/Kconfig:
+	* drivers/i2c/busses/Makefile:
+	* drivers/i2c/busses/i2c-ck6408.c:
+		add csky i2c driver.
+
+2012-10-26 Chen Linfei <linfei_chen@c-sky.com>
+
+	* drivers/rtc/Kconfig:
+	* drivers/rtc/Makefile:
+	* drivers/rtc/rtc-ck6408.c:
+		add csky rtc driver.
+
+2012-10-21 Hu Junshan <junshan_hu@c-sky.com>
+
+	* drivers/mtd/nand/Kconfig:
+	* drivers/mtd/nand/Makefile:
+	* drivers/mtd/nand/csky_nand.c:
+		add nand flash driver for csky's test soc chips.
+
+2012-09-26 Hu Junshan <junshan_hu@c-sky.com>
+
+	* arch/csky/kernel/aligment.c:
+		delete ck610 compile error.
+
+2012-09-14 Hu Junshan <junshan_hu@c-sky.com>
+
+	* arch/csky/configs/ck6408evb_abiv2_defconfig:
+		add abiv2 defconfig
+
+2012-09-12 Hu Junshan <junshan_hu@c-sky.com>
+
+	* arch/csky/include/asm/elf.h:
+	* arch/csky/kernel/module.c:
+		module add new relocation handle.
+
+2012-09-12 Hu Junshan <junshan_hu@c-sky.com>
+
+	* drivers/usb/Kconfig:
+	* drivers/usb/host/ohci-hcd.c:
+	* drivers/usb/host/ohci-csky.c:
+		add csky usb host driver.
+
+2012-09-12 Hu Junshan <junshan_hu@c-sky.com>
+
+	* arch/csky/include/asm/virtconvert.h:
+		fix bug when DMA function call page_to_phys.
+
+2012-09-12 Hu Junshan <junshan_hu@c-sky.com>
+
+	* arch/csky/include/asm/system.h:
+		delete bug but need optimize by reference arch ARM and MIPS.
+
+2012-09-12 Hu Junshan <junshan_hu@c-sky.com>
+
+	* arch/csky/Kconfig:
+	* arch/csky/kernel/alignment.c:
+		add kernel mode to handle missalign exception but now it's 
+		not full and need to be optimized.
+
+2012-08-24 Chen Linfei <linfei_chen@c-sky.com>
+
+	* arch/csky/Kconfig:
+	* arch/csky/ck6408evb/gpio.c:
+	* arch/csky/ck6408evb/Makefile:
+	* arch/csky/include/asm/gpio.h:
+	* arch/csky/ck6408evb/config.c:
+	* arch/csky/ck6408evb/devices.c:
+	* arch/csky/ck6408evb/irq.c:
+	* arch/csky/ck6408evb/include/mach/ckgpio.h:
+		add gpio lib.
+
+2012-06-26 Zhou Feng <feng_zhou@c-sky.com>
+
+	* arch/csky/Kconfig:
+		add abiv2 config and relate mmu with cpu.
+
+2012-06-26 Zhou Feng <feng_zhou@c-sky.com>
+	
+	* arch/csky/include/asm/regdef.h:
+		add this file for register software rename to suport abiv2.
+
+2012-06-26 Zhou Feng <feng_zhou@c-sky.com>
+
+	* arch/csky/include/asm/ptrace.h:
+	* arch/csky/include/asm/sigcontext.h:
+	struct adjust: pt_regs, switch_stack, sigcontext;  
+	regs = {pc,orig_a0,a0,a1,a2,a3,regs[10],r15,exregs[16],rhi,rlo;};                         abi v1:  r2,r3,r4,r5,r6.r7; sp = r0, syscallid = r1;
+		  abi v2:  r0,r1,r2,r3;       sp = r14,syscallid = r7; 
+
+2012-06-26 Zhou Feng <feng_zhou@c-sky.com>
+
+	* arch/csky/include/asm/entry.h:
+		1 add    Macro PT_REGS_ADJUST  rx.
+		2 modify Macro SAVE_ALL, RESTORE_ALL.
+		3 modify Macro SAVE_SWITCH_STACK, RESTORE_SWITCH_STACK.
+
+2012-06-26 Zhou Feng <feng_zhou@c-sky.com>
+
+	* arch/csky/include/asm/processor.h:
+		modify function rdusp and wrusp.
+
+2012-06-26 Zhou Feng <feng_zhou@c-sky.com>
+
+	* arch/csky/include/asm/elf.h:
+	* arch/csky/include/asm/system.h:
+	* arch/csky/include/asm/thread_info.h:
+		modify these because of register software rename 
+			to support abiv2. 
+
+2012-06-26 Zhou Feng <feng_zhou@c-sky.com>
+
+	* arch/csky/kernel/entry.S:
+	      1 modify these because of register software rename 
+			to support abiv2.
+	      2 move sys_execve from process.c to this file.
+	      3 major changes to Entry(system_call) due to 
+		parameter from (abiv1) 6 to (abiv2) 4.
+	      4 use Macro PT_REGS_ADJUST  rx,such as sys_fork.
+
+2012-06-26 Zhou Feng <feng_zhou@c-sky.com>
+
+	* arch/csky/kernel/head.S:
+	* arch/csky/kernel/head-nommu.S:
+	* arch/csky/kernel/fiq.c:
+	      1 modify these because of register software rename 
+			to support abiv2.
+	      2 instruction decne abiv2 have been removed, replace it.
+
+2012-06-26 Zhou Feng <feng_zhou@c-sky.com>
+
+	* arch/csky/kernel/signal.c:
+	      1 modify these because of register software rename 
+			to support abiv2.
+	      2 fuction do_signal return value chang to regs->a0.
+	      3 modify fuction setup_frame due to instrction movi have changed. 
+
+2012-06-26 Zhou Feng <feng_zhou@c-sky.com>
+
+	* arch/csky/kernel/ptrace.c:
+	* arch/csky/kernel/process.c:
+	* arch/csky/kernel/sys_csky.c:
+	* arch/csky/kernel/traps.c:
+	* arch/csky/kernel/asm-offsets.c:	
+		modify these because of register software rename 
+			to support abiv2.	
+
+********************************************
+	
+2012-04-06 Hu junshan <junshan_hu@c-sky.com>
+	* all code:
+		Porting the arch csky form linux2.6.32 to linux3.0.
+		This is the first version of csky linux-3.0.
+
+********************************************
+
+2012-01-16 Hu junshan <junshan_hu@c-sky.com>
+	* drivers/net/cskymac.c:
+	* drivers/serial/csky_uart.c:
+	* drivers/usb/host/ohci-csky.c:
+	* drivers/video/csky_fb.c:
+	* drivers/serial/Kconfig:
+		chane ckcore to csky.
+
+2012-01-16 Hu junshan <junshan_hu@c-sky.com>
+	* drivers/char/Kconfig:
+	* drivers/char/Makefile:
+	* drivers/char/csky_serial.c:
+	* drivers/char/csky_serial.h:
+		Delete csky_serial.c driver(base on linux2.4), and use driver 
+		    csky_uart.c.
+2012-01-16 Hu junshan <junshan_hu@c-sky.com>
+	We change arch name frome ckcore to csky after this version.
+
+********************************************
+
+2012-01-15 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/kernel/signal.c:
+	* arch/ckcore/include/asm/fpu.h:
+		fix embedded asemble code bug.
+
+2011-12-14 Hu junshan <junshan_hu@c-sky.com>
+	* drivers/video/csky_fb.c:
+		Fix csky fb driver bug.
+
+2011-12-14 Hu junshan <junshan_hu@c-sky.com>
+	* drivers/usb/host/ohci.h:
+	* drivers/usb/host/ohci-csky.c:
+	* drivers/usb/host/ohci-hcd.c:
+	* drivers/usb/Kconfig:
+		add csky usb host driver. 
+
+2011-12-14 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/include/asm/uaccess.h:
+		Fix bug when call get_user like get_user(x, p++);  maybe add 2.
+
+2011-11-24 Hu junshan <junshan_hu@c-sky.com>
+	* drivers/mtd/nand/Kconfig:
+	* drivers/mtd/nand/Makefile:
+	* drivers/mtd/nand/csky_nand.c:
+		Add csky nand driver.
+
+2011-11-24 Hu junshan <junshan_hu@c-sky.com>	
+	* drivers/mtd/chips/cfi_cmdset_0002.c:
+	* drivers/mtd/chips/jedec_probe.c:
+		Add norflash chip sst39vf6401b support.
+		more info please reference:
+		  http://blog.tianya.cn/blogger/post_show.asp?BlogID=803354&PostID=19231483
+		  http://www.pubbs.net/200906/kernel/36263-add-support-for-the-sst-39vf3202-39vf6401b-and-39vf6402b-flash-chips.html
+
+2011-11-24 Hu junshan <junshan_hu@c-sky.com>
+	* drivers/mtd/maps/Kconfig:
+	* drivers/mtd/maps/Makefile:
+	* drivers/mtd/maps/csky_norflash.c:
+		Add csky norflash driver.
+	
+2011-11-24 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/kernel/Makefile:
+	* arch/ckcore/kernel/traps.c:
+	* arch/ckcore/kernel/alignment.c:
+	* arch/ckcore/Kconfig:
+		Add file alignment.c and move the aligment exception handler 
+		from trap.c to it, it's control by macro 
+		CONFIG_SOFT_HANDMISSALIGN.
+
+2011-11-10 Hu junshan <junshan_hu@c-sky.com>
+	* drivers/serial/Kconfig:
+	* drivers/serial/Makefile:
+	* drivers/serial/csky_uart.c:
+		add  csky uart driver.
+
+2011-11-10 Hu junshan <junshan_hu@c-sky.com>
+	* drivers/video/csky_fb.h:
+	* drivers/video/csky_fb.c:
+	* drivers/video/Makefile:
+	* drivers/video/Kconfig:
+		add  csky fb driver.
+
+2011-11-10 Hu junshan <junshan_hu@c-sky.com>
+	* ipc/shm.c:
+		Change to support shm for nommu.
+	
+2011-11-10 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/kernel/setup.c:
+		add framebuffer console support.
+
+2011-11-10 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/mm/mmap.c:
+	* arch/ckcore/include/asm/pgtable-nommu.h:
+		add function get_fb_unmaped_area for nommu CPU.
+
+2011-11-10 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/ckm5208/irq.c:
+	* arch/ckcore/ck6408evb/irq.c:
+		add init call set_irq_handler(i, handle_level_irq); for all irq
+		 to support SHARED IRQ.
+
+2011-11-10 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/ck6408evb/devices.c:
+	* arch/ckcore/ck6408evb/config.c:
+		change to support uart and LCD drivers.
+
+2011-10-11 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/mm/nommu.c:
+		the function setup_memory need setup memory region when bootload
+		 or commandline not setup memory region.
+
+2011-10-11 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/ckm5208/: 
+	* arch/ckcore/configs/ckm5208_defconfig:
+	* arch/ckcore/Makefile:
+	* arch/ckcore/Kconfig:
+		add board ckm5208.
+
+2011-10-11 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/include/asm/bitops.h:
+	* arch/ckcore/include/asm/atomic.h:
+	* arch/ckcore/include/asm/system.h:
+	* arch/ckcore/include/asm/irqflags.h:
+		move the macros loca_irq_xxx in file asm/irqflags.h and delete 
+		the macro sti, cli, save_flags ande soon on.
+
+2011-10-11 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/kernel/entry.S:
+	* arch/ckcore/include/asm/sigcontext.h:
+	* arch/ckcore/include/asm/ucontext.h:
+	* arch/ckcore/kernel/signal.c:
+		optimize the signal handle by reference arch arm and not use 
+		struct switch_struct.
+
+2011-10-11 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/kernel/entry.S:
+	* arch/ckcore/include/asm/entry.h:
+	* arch/ckcore/include/asm/ptrace.h:
+	* arch/ckcore/kernel/process.c:
+		optimize the task context and redefine struct switch_struct 
+		because the task switch need not save/restore destroyed register
+		 like r2~r7.
+
+2011-10-11 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/include/asm/entry.h:
+	* arch/ckcore/include/asm/ptrace.h:
+	* arch/ckcore/kernel/traps.c:
+	* arch/ckcore/kernel/ptrace.c:
+	* arch/ckcore/kernel/asm-offsets.c:
+		csky v2 need save/restore reg hi/lo when handle interrupt and
+		 syscall, so change struct pt_regs.
+
+2011-10-11 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/kernel/entry.S:
+	* arch/ckcore/include/asm/tlb.h:
+	* arch/ckcore/include/asm/pgtable.h:
+	* arch/ckcore/include/asm/pgalloc.h:
+	* arch/ckcore/include/asm/mmu_context.h:
+	* arch/ckcore/include/asm/cacheflush.h:
+	* arch/ckcore/mm/cachev1.c:
+	* arch/ckcore/mm/fault.c:
+	* arch/ckcore/mm/mmu.c:
+		ck810's tlbmiss hardrefill need fill phy address, and OS write 
+		pgd/pte need clear cache.
+
+2011-09-23 Hu junshan <junshan_hu@c-sky.com>
+	* drivers/net/cskymac.c:
+		function xx_xmit need unlock before return.
+
+2011-09-23 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/Makefile:
+		compile kernel code  need not produce DSP and float instruction.
+
+2011-09-23 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/include/asm/uaccess.h:
+	* arch/ckcore/lib/usercopy.c:
+		Driver compile with module may produce section __ex_table. 
+		This section mast align by 4 byte, so add ".align   2".
+
+2011-09-01 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/include/asm/user.h:
+		adjust the struct user, because uClibc need use it.
+
+2011-09-01 Hu junshan <junshan_hu@c-sky.com>
+	* rch/ckcore/include/asm/pgtable.h:
+	* arch/ckcore/include/asm/pgtable-nommu.h:
+	* arch/ckcore/include/asm/pgtable-bits.h:
+		MMUV2.0's tlb flags in PTE local at bit 0~6.
+
+2011-09-01 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/include/asm/entry.h:
+		support CSKY MMU version 2 by macro CONFIG_CPU_MMU_V1/2.
+
+2011-09-01 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/include/asm/ckmmuv2.h:
+	* arch/ckcore/include/asm/ckmmuv1.h:
+	* arch/ckcore/include/asm/ck610mmu.h:
+	* arch/ckcore/include/asm/ck510mmu.h:
+		rm file file ck510mmu.h/ck610mmu.h and add file 
+		 ckmmuv1.h/ckmmuv2.h to support all CSKY MMU version.		
+
+2011-09-01 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/kernel/head.S:
+		ck810 has dsp BTB/BTH, so CPU init need invalid and open it.
+		optimize mmu operation.
+
+2011-09-01 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/kernel/entry.S:
+	* arch/ckcore/kernel/process.c:
+		ck810 has dsp instruction, so need save/restore hi/lo register.
+
+2011-09-01 Hu junshan <junshan_hu@c-sky.com>
+	 * arch/ckcore/kernel/signal.c:
+		CSKY V2 need adjust epc by 4, because trap instruction is 32bit.
+
+2011-09-01 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/kernel/traps.c:
+		delete function write_mmu_context, because not used.
+
+2011-09-01 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/mm/tlbv1.c:
+	* arch/ckcore/mm/Attic/tlbv2.c:
+	* arch/ckcore/mm/Makefile:
+		add file tlbv2.c to support MMU V2.0.
+
+2011-09-01 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/ck6408evb/config.c:
+	* arch/ckcore/ck6408evb/irq.c:
+		Add function ckcore_get_auto_irqno to get irq number when use 
+		auto interrupt.
+
+2011-09-01 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/include/asm/mmu_context.h:
+	* arch/ckcore/mm/init.c:
+	* arch/ckcore/mm/fault.c:
+		when config CONFIG_MMU_HARD_REFILL, kernel not use valrable 
+		pgd_current but register CP15_29.
+	* arch/ckcore/Kconfig:
+		Add hard refill tlb miss configuration.
+
+2011-07-19 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/include/asm/cpu.h:
+	* arch/ckcore/Makefile:
+	* arch/ckcore/Kconfig:
+		rename CPU ck801 as ck803.
+
+2011-07-14 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/configs/ck6408evb_defconfig:
+	* ckcore/configs/ck5a6-3c_defconfig:
+	* arch/ckcore/configs/ckcore_defconfig:
+		Rename ckcore_defconfig as ck6408evb_defconfig for MMU CPU demo
+		 configuration and add ck5a6-3c_defconfig for NOMMU CPU demo
+		 configuration.
+
+2011-07-14 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/include/asm/cacheflush.h:
+		For nommu cpu, the function flush_icache_range need fluash all 
+		 cache, because load flat file as data and will made some 
+		 instruction in data cache.
+
+2011-07-11 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/kernel/setup.c:
+		Handle  bootload passed  parms(struct tag).
+		Delete bug(cat /proc/cpuinfo).
+		Optimize function setup_arch.
+
+2011-07-11 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/mm/Attic/nommu.c:
+	* arch/ckcore/mm/Attic/mmu.c:
+	* arch/ckcore/mm/init.c:
+		Partition some memory init operation such as paging_init from 
+		init.c to mmu.c or nommu.c. 
+
+2011-07-11 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/kernel/vmlinux.lds.S:
+	* arch/ckcore/kernel/head.S:
+	* arch/ckcore/kernel/Attic/head-nommu.S:
+		Change to support bootload pass parms.
+
+2011-07-11 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/kernel/Attic/cpu-probe.c:
+	* arch/ckcore/include/asm/cpu.h:
+		change according by C-SKY Product ID SPEC Rev3.3.
+
+2011-07-11 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/mm/Attic/tlbv1.c:
+	* arch/ckcore/include/asm/setup.h:
+	* arch/ckcore/include/asm/bootinfo.h:
+		Move all definiation from file bootinfo.h to setup.h by 
+		    according ARCH ARM.
+
+2011-07-11 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/mm/Attic/highmem.c:
+	* arch/ckcore/include/asm/pgtable.h:
+	* arch/ckcore/include/asm/kmap_types.h:
+	* arch/ckcore/include/asm/Attic/fixmap.h:
+	* arch/ckcore/include/asm/Attic/highmem.h:
+		Add or change this file to support higmen.
+
+2011-07-11 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/include/asm/ckcore.h:
+		Delete unused MACRO and add some nommu config MACRO. 
+
+2011-07-11 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/include/asm/machdep.h:
+	* arch/ckcore/ck6408evb/config.c:
+	* arch/ckcore/ck6408evb/Kconfig:
+		Kernel command line pass by bootload or by config, so need not
+		 do in board init. And the board API config_BSP not need  parms.
+
+2011-07-11 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/Kconfig:
+		add macro CONFIG_CMDLINE for kernel commamd line and some nommu 
+		configuration, such as consecutive memory region for malloc.
+
+2011-07-04 Dou shaobin <shaobin_dou@c-sky.com>
+	Delete the Macros of PAGE_SIZE_16KB and PAGE_SIZEZ_64KB.	
+	Rename file c-ck610.c to cachev1.c, and file tlb-ck610.c to tlbv1.c. 
+	Added the files page-nommu.h and cpu-probe.c
+	Added the function of probing CPU type automatically.
+	Added support for the architecture of ck801.
+	Added support for the architecture of nommu.
+
+2011-04-20 Hu junshan <junshan_hu@c-sky.com>
+	* ckcore/kernel/vmlinux.lds.S:
+		Let the linker file support between gcc3.2 and gcc4.5.
+
+2011-04-20 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/kernel/process.c:
+	* arch/ckcore/lib/memcpy.c:
+	* arch/ckcore/lib/memset.c:
+	* arch/ckcore/include/asm/uaccess_mm.h:
+		Delete compile error for csky-gcc4.5. Because the new compiler's
+		 syntax is more strict.
+
+2010-12-17 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/include/asm/pgtable_mm.h:
+		Add define pgprot_noncached to delete pretreatment error.
+		Please see buzilla:BUG 286 for more info.
+
+2010-11-24 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/include/asm/bitops_mm.h:
+		the assemble code of function set_bit as follow:
+			ld  r6, (r14, 0)
+			......
+			mfcr    r7, psr
+			psrclr  ie
+			bseti   r6, 2
+			st  r6, (r14, 0)
+			mtcr    r7, psr
+		obviously, the operation is not atomic. So we change it by add
+		     key word volatile to let it atomic. We also change other
+		     function which not atomic. After change the code is like
+		     that:
+		    static inline void set_bit(int nr, volatile void * addr)
+		    {
+		      volatile unsigned int *a = (volatile unsigned int *) addr;
+		      ......
+		      save_flags(flags); cli();
+		      *a |= mask;
+		      restore_flags(flags);
+		    }
+		
+2010-11-10 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/Makefile:
+		Add parameter BJCOPYFLAGS and GZFLAGS to make right image file.
+
+2010-11-04 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/ck6408evb/time.c:
+	* arch/ckcore/ck6408evb/include/mach/ckuart.h:
+	* arch/ckcore/ck6408evb/include/mach/cktimer.h:
+	* arch/ckcore/ck6408evb/include/mach/ckpic.h:
+		Let base address and irqnumber define from ck_iomap.h to irqs.h.
+
+2010-11-04 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/ck6408evb/include/mach/irqs.h:
+	* arch/ckcore/ck6408evb/include/mach/ck_iomap.h:
+		Add all base address and irq number of peripheral devices.
+
+2010-11-04 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/ck6408evb/include/mach/fb.h:
+	* arch/ckcore/ck6408evb/include/mach/cklcd.h:
+		Add head file for LCD driver.
+
+2010-11-04 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/ck6408evb/include/mach/cknand.h:
+	* arch/ckcore/ck6408evb/include/mach/board.h:
+		Add head file for Nand Flash driver.
+
+2010-11-04 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/ck6408evb/config.c:
+	* arch/ckcore/ck6408evb/devices.h:
+	* arch/ckcore/ck6408evb/devices.c:
+		Add usb host and LCD driver.
+
+2010-11-04 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/include/asm/delay_mm.h: 
+		The origined function of udelay is error.
+
+2010-11-04 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/include/asm/io_mm.h:
+	* arch/ckcore/include/asm/dma-mapping.h:
+	* arch/ckcore/mm/dma-mapping.c:
+		Implement all dma interface by reference arch-MIPS.
+
+2010-10-22 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/include/asm/processor_mm.h:
+		We will set ptregs->r7=0 in function start_thread, because
+		     __uClibc_main need this reg to distinguish between the 
+		    argument "rtdl" is passed form kernel or linker.
+
+2010-09-21 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/mm/dma-mapping.c:
+		The implementation of the "dma_alloc_coherent()" function is 
+		    buggy:  It never returns the correct uncached address. 
+		    Because the type of variable ret is unsigned int *, it will
+		    calculate addr addition by multiply 4 in UNCAC_ADDR(ret) and
+		    get error result. The right change is define ret as type
+		    void *.
+
+2010-09-03 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/include/asm/mmu_context.h:
+		We need to flush all cache to avoid problem of 16k cache.
+
+2010-09-03 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/mm/cache.c:
+	* arch/ckcore/include/asm/cacheflush_mm.h:
+	* arch/ckcore/include/asm/pgtable_mm.h:
+		Add __update_cache and flush all cache to avoid problem of 16k
+		     cache alians.
+
+2010-09-03 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/include/asm/tlb.h:
+		The function tlb_start_vma will be called when free 
+		    phy-page(use syscall munmap), we need flush cache in this
+		    file. If we don't flush cache, it will lead to cache 
+		    unalians when cache >=16k.
+
+2010-08-05 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/kernel/sys_ckcore.c:
+	* arch/ckcore/include/asm/shmparam.h:
+		Map virtual address in thrread space need 16k aligan to avoid 
+		    cache probem(if cache>16k, ...).
+
+2010-08-02 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/include/asm/checksum_mm.h: 
+		Support little endian and use assemble code to optimize
+		     performance.
+	* arch/ckcore/lib/checksum.c:
+		Support little endian.
+
+2010-08-02 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/mm/ioremap.c:
+		The arg 1 of pfn_pte is pfn not phy-address.
+
+2010-08-02 Hu junshan <junshan_hu@c-sky.com> 
+	* arch/ckcore/kernel/ints.c:
+	* arch/ckcore/kernel/fiq.c:
+	* arch/ckcore/kernel/entry.S:
+		Support auto interrupt handle.
+	* arch/ckcore/kernel/setup.c:
+	* arch/ckcore/include/asm/machdep_mm.h:
+		Add machine API mach_get_auto_fiqno and mach_get_auto_irqno to
+		     get IRQ/FIQ number when use auto interrupt.	
+
+2010-08-02 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/kernel/fiq.c:
+	* arch/ckcore/kernel/entry.S:
+	* arch/ckcore/include/asm/irq_mm.h:
+	* arch/ckcore/include/asm/fiq.h:
+	* arch/ckcore/ck6408evb/include/mach/irqs.h:
+	* arch/ckcore/ck6408evb/include/mach/ckuart.h:
+	* arch/ckcore/ck6408evb/timer.c:
+	* arch/ckcore/ck6408evb/irq.c:
+		According to CPU, the IRQ number start from 32, but according to
+		     SOC, the IRQ number start from 0. Because the
+		     driver-developer need only to know SOC, we change some to
+		     let the developer can understand the right IRQ number. So
+		     the IRQ number need not to add offset 32.
+
+2010-08-02 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/boot/install.sh:
+	* arch/ckcore/boot/Makefile:
+	* arch/ckcore/Makefile:
+		Use this strips to produce binary image file: Image/zImage/uImage.
+
+2010-07-28 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/include/asm/ck610mmu.h:
+		The tlb entry numbers of CPU CK610 is 128. 
+		
+2010-07-28 Hu junshan <junshan_hu@c-sky.com>
+	* drivers/net/cskymac.c:
+	* drivers/char/csky_serial.c:
+		Let the driver support little endian format.
+	* drivers/char/ckuart.h:
+		Move this file to arch/ckcore/ck6408evb/include/mach.
+
+2010-07-28 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/include/asm/unaligned.h:
+	* arch/ckcore/include/asm/stat.h:
+	* arch/ckcore/include/asm/elf.h:
+	* arch/ckcore/include/asm/byteorder.h:
+		Let the kernel support little endian format.
+
+2010-07-28 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/include/asm/unistd.h:
+	* arch/ckcore/kernel/sys_ckcore.c:
+	* arch/ckcore/kernel/entry.S:
+		Use trap 3 to get TLS and add a syscall sys_set_thread_area to
+		     set TLS.
+
+2010-07-28 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/include/asm/thread_info_mm.h:
+	* arch/ckcore/kernel/process.c:
+	* arch/ckcore/kernel/asm-offset.c:
+		Add a member in sttuct thread_info to support TLS.
+
+2010-07-28 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/kernel/vmlinux.ls.S:
+	* arch/ckcore/lib/math-64bits.h:
+	* arch/ckcore/Makefile:
+	* arch/ckcore/Kconfig:
+		Add config option of CPU-endian select. 
+
+2010-04-21 Hu junshan <junshan_hu@c-sky.com>
+	* drivers/mtd/maps/csky_norflash.c:
+		Optimize the function init_csky_map add the originally code will
+		    lead to kernel dump when probe flash fail.
+
+2010-04-21 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/ck6408evb/config.c: 
+		Add macro #ifdef CONFIG_CPU_USE_FIQ to eliminate compile error,
+		     if not config FIQ.    
+	
+2010-04-20 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/include/asm/fpu.h:
+		will bring a error "Unexpected register 'r13' for 'cprcr/cpwcr'"
+		    when  compile file arch/ckcore/kernel/setup.c. So we use 
+		    "=b(r1)" for the embedded assemble code to eliminate this
+		     error
+
+2010-03-08 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/ck6408evb/irq.c:
+		Unique vector numbers for fast vectored interrupt requests and
+		    fast vectored interrupts Number are 64-95.
+
+2010-03-08 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/ck6408evb/fiq.c:
+		This file define some board cupport function for fiq handler.	
+
+2010-03-08 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/include/asm/traps_mm.h:
+		Change define VEC_XXX to VEC_USER and it maybe used in fiq 
+		    handler. 
+
+2010-03-08 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/include/asm/machdep_mm.h:
+		Add a machine interface --mach_init_FIQ for fiq handler.
+
+2010-03-08 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/include/asm/fiq.h:
+	* arch/ckcore/kernel/fiq.c:
+		Add fiq handler for c-sky cpu.
+
+2010-03-08 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/kernel/setup.c:
+	* arch/ckcore/include/asm/fpu.h:
+		Add FPU init function.		
+
+2010-03-08 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/kernel/entry.S:
+		Add FPU exception and fast interrupt handle. And also add FPU 
+		and DSP register switch in function resume bcause thread switch
+		 need save and restore these context.	
+
+2010-03-08 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/include/asm/system_mm.h:
+		Before resume, we must be confirm the FPU isn't peoduce 
+		    exception. So we add a function _is_fpu_busying and called
+		    by function switch_to. 
+
+2010-03-08 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/include/asm/processor_mm.h:
+		Define FPU context in thread_struct and let user thread select
+		    FPU in function of start_thread when define 
+		    CONFIG_CPU_HAS_FPU.
+
+2010-03-08 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/include/asm/ucontext.h:
+	* arch/ckcore/include/asm/sigcontext.h:
+	* arch/ckcore/kernel/signal.c:
+		Add FPU context save and retore in signal handle. 
+		Let third arg of user register signal-function pointer to 
+		    ucontext and it origal point NULL.
+
+2010-03-08 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/include/asm/traps_mm.h:
+	* arch/ckcore/kernel/traps.c:
+		Add FPU exception handle.
+
+2010-03-08 Hu junshan <junshan_hu@c-sky.com> 
+	* arch/ckcore/include/asm/ptrace.h:
+	* arch/ckcore/kernel/ptrace.c:
+		Add some interface and let gdbserver to look up FPU and DSP
+		     regster. 
+
+2010-03-08 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/include/asm/user.h:
+	* arch/ckcore/kernel/process.c:
+		Add FPU and DSP context save in function copy_thread. And also
+		 implement kernel interface of dump_fpu.
+
+2010-03-08 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/kernel/asm-offset.c:
+		Add offsets of FPU and DSP context in the thread struct.
+
+2010-03-08 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/configs:
+		Update it.
+
+2010-03-08 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/Kconfig:
+		Add config option about FPU, DSP enhanced instruction and Fast 
+		    interrupt support.	
+	
+2009-12-27 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/include/asm/uaccess_mm.h:
+		Change the handle of function __put_user_asm_64 when date type 
+		    is 64bits
+
+2009-12-10 Ye Yun <yun_ye@c-sky.com>
+	* include/linux/dirent.h:
+		 Add dirent&dirent64 to make this head file compatible 
+			to APP for linux2.4
+
+2009-12-09 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/kernel/setup.c:
+	* arch/ckcore/include/asm/machdep_mm.h:
+		Modify some machine API and delete some of it.
+
+2009-12-07 Li Chunqiang <chunqiang_li@c-sky.com>
+	* include/asm-generic/page.h:
+		Fix the problem that __attribute_const__ is not defined, when 
+		    building uClibc-0.9.30.
+
+2009-12-01 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/include/asm/machdep_mm.h:
+		Change the function of get and set real time clock from 
+		    arch_getod to  mach_hwclk.
+	* arch/ckcore/ck6408evb/timer.c:
+		Add an interface to get or set real time clock.
+	* arch/ckcore/ck6408evb/config.c:
+		Add an interface to get or set real time clock.
+	* arch/ckcore/kernel/time.c:
+		Add an interface to get real time clock.
+	* arch/ckcore/kernel/setup.c:
+		Change the function of get and set real time clock from 
+		    arch_getod to mach_hwclk.
+
+2009-12-01 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/kernel/vmlinux.lds.S:
+	* arch/ckcore/kernel/head.S:
+		Change the start code form text section to __HEAD section and it
+		     will delete compile warning.
+	* arch/ckcore/include/asm/page_mm.h:
+		Change PAGE_SIZE with the style of UL to delete compile warning.
+	* kernel/time/ntp.c:
+	* block/cfq-iosched.c:
+	* fs/dcache.c:
+		Add return value after call BUG() to delete compile warning. 
+	* lib/vsprintf.c:
+	* fs/proc/page.c:
+	* fs/libfs.c:
+	* net/sunrpc/svcauth_unix.c:
+	* block/as-iosched.c:
+		Add some variable initial to delete compile warning.
+
+2009-11-20 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/ck6408evb/Kconfig:
+		Add a menu to config commamd "rdinit" to specify the init
+		     programe in the fs.
+	* arch/ckcore/ck6408evb/config.c:
+		Add a commamd rdinit to specify the init programe in the fs.
+
+2009-11-18 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/kernel/head.S:
+		If we  want to jump right from physical address to virtual 
+		    address in start code, we need to fill up page table and map
+		    physical address to the same virtual address before we
+		    enable MMU. So change it to correspond with diferent RAM
+		     base address.
+
+2009-11-18 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/kernel/setup.c:
+		Don't evaluate valure to saved_command_line, because it's not
+		    initialed and well bring in bug when use boodload to load 
+		    kernel. The variable saved_command_line is alloced mem at
+		    the function setup_command_line, so we need not evaluate
+		    valure in function setup_arch.
+
+2009-11-15 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/kernel/time.c:
+		Use new seqlock read_seqbegin and read_seqretry to replace 
+		    read_seqbegin_irqsave and read_seqretry_irqsave. Because 
+		    when call function of mach_gettimeoffset, system will bring
+		     timer interrupt. 
+		If we used old seqlock, ststem well not hander the interrupt to
+		     update wall-time and result in obtain error time.
+
+2009-11-15 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/kernel/setup.c:
+		Optimize the code style, change the MACRO CONFIG_CPU_CK640 to 
+		     CONFIG_CKCORE_MMU and delete some unused function rely on
+		     machine.
+
+2009-11-15 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/include/asm/pgtable-bits.h:
+		Change the MACRO CONFIG_CPU_CK640 to CONFIG_CKCORE_MMU.
+	* arch/ckcore/include/asm/mmu_context.h:
+		Change the MACRO CONFIG_CPU_CK660 to CONFIG_CPU_MMU_CP. 
+	* arch/ckcore/include/asm/entry.h:
+		Optimize the code style and change the MACRO CONFIG_CPU_CK660 t 
+		  CONFIG_CPU_MMU_CP.
+	* arch/ckcore/include/asm/ckcore.h:
+		Optimize the code style and change the MACRO CONFIG_CPU_CK640 t 
+		  CONFIG_CKCORE_MMU.
+
+2009-11-15 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/mm/Makefile:
+		Change the MACRO CONFIG_CPU_CK640 to CONFIG_CPU_MMU.
+	* arch/ckcore/mm/tlb=ck610.c:
+		Change the MACRO CONFIG_CPU_CK660 to CONFIG_CPU_MMU_CP.
+
+2009-11-15 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/Kconfig:
+		Optmize the config menu for our processor.
+
+2009-11-15 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/Makefile:
+		Optmize this file and delete unused codes.
+
+2009-11-13 Hu junshan <junshan_hu@c-sky.com>
+	* drivers/char/csky_serial:
+		Change file name from ck1000evb_serial.c to csky_serial.c and 
+		  ck1000evb_serial.h to csky_serial.h. 
+		Optmize the code style.
+		Change macro ck1000evb-->csky, CK1000EVB-->CSKY.
+	* drivers/char/ckuart.h:
+		Optmize the code style.
+	* drivers/char/Makefile:
+		Change obj filename.
+	* drivers/char/Kconfig:
+		Change config menu.
+
+2009-11-13 Hu junshan <junshan_hu@c-sky.com>
+	* drivers/mtd/maps/csky_norflsah.c:
+		Change filename from ckcore_norflash.c to csky_norflash.c. Add 
+		    norflash address, size and buswidth config entry.
+	* drivers/mtd/maps/Kconfig:
+		Change obj-filename from ckcore_norflash.o to csky_norflash.o.
+	* drivers/mtd/maps/Kconfig:
+		Add nor flash address and size config entry.
+
+2009-11-13 Ye Yun <yun_ye@c-sky.com>
+	* arch/ckcore/kernel/traps.c:
+		In trap_c and buserr_c, replace send_sig with force_sig.
+		Improve functione show_registers.
+
+2009-11-13 Ye Yun <yun_ye@c-sky.com>
+	* arch/ckcore/kernel/head.S:
+	* arch/ckcore/kernel/entry.S:
+		In entry.h, Add assemble macros, used to switch coprocessor 
+		 to MMU, Read and Write MMU registers. So, here use them 
+		 instead of two colections of codes for MMU coperation 
+		 in many places.
+	* arch/ckcore/include/entry_mm.h:
+		Add assemble macros, used to switch coprocessor to MMU, 
+			Read and Write MMU registers.
+
+2009-11-12 Ye Yun <yun_ye@c-sky.com>
+	* drivers/net/Kconfig:
+		Correct CSKYMAC depending, CKCORE --> CK6408EVB.
+
+2009-11-04 Ye Yun <yun_ye@c-sky.com>
+	* arch/ckcore/mm/init.c:
+		Correct variable totalram_pages from type static to extern, 
+			that is because in mm/page_alloc.c has already defined: 
+			EXPORT_SYMBOL(totalram_pages), which is just the one we 
+			wished to use in this file.
+
+2009-11-03 jiang jianyong <jianyong_jiang@c-sky.com>
+	* arch/ckcore/include/asm/ptrace.h:
+		exchange the value of PT_SR and PT_PC
+	* arch/ckcore/kernel/trap.c:
+		modify the handle of single step and breakpoint in trap_c 
+	* arch/ckcore/kernel/ptrace.c:
+		implement ptrace under the struct of ckcore
+	* arch/ckcore/kernel/entry.S:
+		get rid of the handle of do_delay_trace
+
+
+2009-11-03 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/kernel/setup.c:
+		The arg[1] in function reserve_bootmem need a phyaddress, so we
+		 change it to deal with kernel bug when config other RAM base 
+		 address then 0x0.
+
+2009-11-02 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/Kconfig:
+		Add rootfs autoconfig. Now, suport initrd, jffs2 and nfs, you 
+		can choose one of them to be your rootfs.
+		The config-menu	like :
+			Platform dependent setup
+				-->Root File System and Boot Paramete Seting
+					-->initrd
+					-->jffs2
+					-->nfs
+
+2009-11-02 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/kernel/setup.c:
+		Add initrd rootfs autoconfig, it depends on macro 
+		CONFIG_INITRD_START_ADDR and CONFIG_INITRD_SIZE.	
+
+2009-11-02 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/ck6408evb/config.c:
+		Move comdline-setup from setup.c to config.c.
+
+2009-11-02 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcorec/kernel/vmlinux.lds.S:
+		Support config SDRAM base address. The base address rely on 
+		 the macro of CONFIG_RAM_BASE:
+			. = 0x80000000 + CONFIG_RAM_BASE;
+
+2009-11-02 Hu junshan <junshan_hu@c-sky.com>
+	* fs/jffs2/erase.c :
+		Deal ewith the message of"jffs2_scan_eraseblock(): Magic bitmask
+		 0x1985 not found at 0xXXXXXXXX: 0x2003 instead" when use jffs2
+		 file system. It is a bug of GCC and we do sample change.
+
+2009-11-02 Ye Yun <yun_ye@c-sky.com>
+	* arch/ckcore/mm/dma-mapping.c:
+		Realize routine dma_alloc_coherent and dma_free_coherent, 
+			but they are not validated, they maybe validated by USB 
+			driver in the future.
+	* arch/ckcore/mm/tlb-ck610.c:
+		1. Add func show_jtlb_table, it is used to print all the jtlbs;
+		2. In func __update_tlb, delete line "write_mmu_entryhi(pid)" 
+			in the end.
+
+2009-11-02 Ye Yun <yun_ye@c-sky.com>
+	* drivers/net/cskymac.c:
+		1. In interrupt routine, clear ERR bits after handle errors;
+		2. Add statics when tx error hanpens.
+
+2009-10-29 Ye Yun <yun_ye@c-sky.com>
+	* arch/ckcore/lib/checksum.c:
+		The old checksum has bug, replace it , it works ,so do it.
+
+2009-10-27 Ye Yun <yun_ye@c-sky.com>
+	* drivers/net/cskymac.c:
+		In func ckymac_tx: move line "skb= dp->tx_skbs[elem];" beforer. 
+		 Or, skb being used before evaluated. It is quite serious a BUG.
+
+2009-10-27 Ye Yun <yun_ye@c-sky.com>
+	* arch/ckcore/kernel/signal.c:
+		Complete func push_cache, which is called by 
+		 setup_frame/setup_rt_frame after filling the sig frame in 
+		 user stack with sys_sigreturn codes, to avoid codes only 
+		 writed in dcache rather than memory, and CPU reads right 
+		 instructions from the memory.
+
+2009-10-23 Ye Yun <yun_ye@c-sky.com>
+	* driver/net/cskymac.c:
+		1. Add netif_start_queue(dev) in func cskymac_open; 
+			add netif_stop_queue(dev) in func cskymac_close.
+		2. In cskymac_ops, add func cskymac_get_stats, remove 
+			func cksymac_set_macaddr
+		3. In cskymac_ether_init: Remove cskymac_stop() and 
+			replace kfree(dev) with free_netdev(dev), the later 
+			also done in cksymac_cleanup.
+		4. Replace func parameter cskymac* with net_device* 
+			in all funcs if could, expcept in cskymac_cleanup.
+		5. Remove routines below: cskymac_phyr_read, cskymac_phyr_write,
+			try_next_permutation, cskymac_timer.
+		6. Correct parameter of request_irq & free_irq:dp --> dev.
+			#define ARCH_PFN_OFFSET 	PFN_UP(PHY_OFFSET)
+			#define PHY_OFFSET		CK_RAM_BASE
+
+2009-10-22 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/include/asm/page_mm.h :
+		Add 2 macro to deal with kernel error when change RAM base 
+		 phy-address.
+
+2009-10-22 Hu junshan <junshan_hu@c-sky.com>
+	* drivers/mtd/maps/ckcore_norflash.c:
+		Add the file to support ckcore norflash access. This file 
+		 contain all need codes and you can change about hardware.
+	* drivers/mtd/maps/Makefile:
+		Add ckcore norflash access support:
+			obj-$(CONFIG_MTD_CKCORE_NORFLASH)+= ckcore_norflash.o
+	* drivers/mtd/maps/Kconfig:
+		Add ckcore norflash access support:
+			config MTD_CKCORE_NORFLASH
+			tristate "Map driver for ckcore evb norflash"
+			...
+
+2009-10-22 Ye Yun <yun_ye@c-sky.com>
+	* arch/ckcore/include/asm/page_mm.h:
+		Change macro name with part of UNCAC to UNCACHE.
+
+2009-10-22 Ye Yun <yun_ye@c-sky.com>
+	* driver/net/cskymac.h:
+		Add macro:
+			TXBD_ERR_BITS   0x10f and
+			RXBD_ERR_BITS   0xff
+		for tx and rx BD error judge.
+	* driver/net/cskymac.c:
+		1. When init rings, map rx_skb->data to uncachable VM:
+			L247:dp->rx_skbs[i]->data = UNCACHE_ADDR(skb->data);
+		2. Remove func skymac_begin_auto_negotiation and 
+			 cskymac_get_stats they are no use.
+		3. Big change for mac interrupt routine, new way:
+			Return type become irqreturn_t, del third parameter;
+			Int tx and tx err merge to the same routine;  rx, rx err
+			and busy merge to the same routine;
+	 		So, cskymac_rx and cskymac_tx routine quite different.
+		4. Routine cskymac_start_xmit add clear_dcache_all() to make 
+			coherent between data cache and memory.
+
+2009-10-22 Ye Yun <yun_ye@c-sky.com>
+	* arch/ckcore/include/asm/socket.h:
+		1 Undefine macro ARCH_HAS_SOCKET_TYPES, so use the generic 
+			sock_type.
+		2 Correct most of the macro to linux2.4 form.
+		3 Add macros:
+			#define SO_LINGER	13
+			/* To add :#define SO_REUSEPORT 15 */
+			#define SO_PASSCRED	16
+			#define SO_PEERCRED	17
+		  Delete macros:
+			#define SOCK_TYPE_MASK 0xf
+			#define SOCK_CLOEXEC	O_CLOEXEC
+			#define SOCK_NONBLOCK	O_NONBLOCK
+	
+2009-10-22 Ye Yun <yun_ye@c-sky.com>
+	* driver/net/cskymac.c:
+		1 Displace dev->priv with netdev_priv(dev).
+		2 In func cksymac_rx, replace eth_copy_and_sum with 
+			skb_copy_to_linear_data.
+		3 In func cskymac_ether_init:
+	    	    init_ethrdev --> alloc_etherdev;
+		    del SET_MODULE_OWNER(dev);
+		    replace netdev ops evaluating with struct dev->netdev_ops=
+		  	&cskymac_ops, and cskymac_ops define&evaluate just
+			before func cskymac_ether_init;
+		    ether_setup(dev) --> register_netdev(dev);
+		4 In func cskymac_open:
+		    the third parameter of request_irq change to IRQF_DISABLED. 
+
+2009-10-22 Ye Yun <yun_ye@c-sky.com>
+	* drivers/net/Kconfig:
+		Add CSKYMAC config option under if NET_ETHERNET
+	* drivers/net/Makefile:
+		Add line: obj-$(CONFIG_CSKYMAC) += cskymac.oRXBD_ERR_BITS   0xff
+
+2009-10-20 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/include/asm/cacheflush_mm.h:
+		Optimize the function about cache flush.
+
+2009-10-20 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/kernel/trap.c:
+		Let align exception to send SIGBUS signal.	
+
+2009-10-20 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/include/asm/elf.h:
+		Add ckcore relocation fiags such as 
+			#define R_CKCORE_32                 1
+			#define R_CKCORE_NONE               0
+
+2009-10-20 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/include/asm/module.h:
+		Change it to sustain module load.
+
+2009-10-20 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/kernel/module.c:
+		Deal witch module load of ckcore. We perfect the function of 
+		apply_relocate, apply_relocate_add and soon on.
+
+2009-10-20 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/kernel/ckcore_ksyms.c:
+		Add some export symbole for module load.
+
+2009-10-20 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/kernel/Makefile:
+		Add a object to sustain module load.
+
+2009-10-20 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/lib/checksum.c:
+		Add 3 export symbole.
+
+2009-10-20 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/mm/init.c:
+		Add a export symbole.
+	
+2009-10-20 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/mm/dma-maping.c:
+		Add return valure infunction dma_map_single, dma_map_page and 
+		dma_mapping_error to delete compile warring.
+
+2009-9-23 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/kernel/entry.S:
+		1 Rather than keep a global, we dedicate a register r0 to get
+		     current. So delete the variable _current_task and need not 
+		     keeping it.
+		2 Also, optimize the method of getting current->thread_info,
+		     like below:
+			mov     r9, r0
+			bmaski  r10, THREADSIZE_MASK_BIT
+			andn    r9, r10
+
+2009-9-23 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/kernel/head.S:
+	* arch/ckcore/kernel/setup.c:
+		Rather than keep a global, we dedicate a register r0 to get 
+		    current. So delete the variable _current_task and need not
+		    keeping it.
+
+2009-9-23 Ye Yun <yun_ye@c-sky.com>
+	* arch/ckcore/include/asm/pgtable_mm.h:
+		Define Macro PMD_SHIFT 22 instead of (2*PAGE_SHIFT-PTE_T_LOG2).
+	* arch/ckcore/include/asm/bitops_mm.h:
+		Optimize function ffz, use ckcore instructions to implement it.
+
+2009-9-23 Ye Yun <yun_ye@c-sky.com>
+	* arch/ckcore/include/asm/ck610mmu.h:
+		correct each mmu control fuctions, use register "b" instead of
+		     "r" in case of confilction with r5.
+
+2009-9-22 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/kernel/ (all source file):
+		Optimize the codes style. 
+
+2009-9-22 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/kernel/ (asm-offset.c):
+		Change the offset of thread_info in task_struct because the 
+		    thread_struct has no filed info and task_struct.stack point
+		     to the current struct thread_info.
+
+2009-9-22 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/include/asm/processor_mm.h (L102 -109):
+		Delete unused filed-----"struct thread_info info" in struct of 
+		thread_struct.
+
+2009-9-22 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/kernel/ints.c (init_IRQ):
+		Add section attribute "__init" on this function.
+	* arch/ckcore/ck6408evb/config.c (config_BSP):
+		Add section attribute "__init" on this function.
+
+2009-9-18 Hu junshan <junshan_hu@c-sky.com>
+	* arch/ckcore/kernel/process.c (default_idle): 
+		Schedule has bug when config kernel preemption: the idle thread
+		   will output bug information to terminal. So correct the 
+		   function of default_idle and let CPU enter wait mode.
+
+2009-9-18 Hu junshan <junshan_hu@c-sky.com>
+	* drivers/char/ck1000evb_serial.c (receive_chars): 
+		Revise the function of receive_chars() when deal with the 
+		    receive status is overrun.
+
+2009-9-17 Hu junshan <junshan_hu@c-sky.com>
+	* drivers/char/Kconfig (L124 - 168): 
+		Deal with warring when use command "make defconfig".
diff --git a/arch/csky/Kconfig b/arch/csky/Kconfig
new file mode 100644
index 0000000..99f35da
--- /dev/null
+++ b/arch/csky/Kconfig
@@ -0,0 +1,346 @@
+#
+# For a description of the syntax of this configuration file,
+# see Documentation/kbuild/kconfig-language.txt.
+#
+config CSKY
+	bool
+	default y
+	select HAVE_GENERIC_DMA_COHERENT
+	select HAVE_KERNEL_GZIP
+	select HAVE_KERNEL_LZO
+	select HAVE_KERNEL_LZMA
+	select HAVE_OPROFILE
+	select HAVE_PERF_EVENTS
+	select PERF_USE_VMALLOC
+	select HAVE_C_RECORDMCOUNT
+	select HAVE_KPROBES
+	select HAVE_KRETPROBES
+	select HAVE_IRQ_WORK
+	select RTC_LIB
+	select HAVE_DMA_API_DEBUG
+	select HAVE_GENERIC_HARDIRQS
+	select GENERIC_IRQ_SHOW
+	select SYS_SUPPORTS_APM_EMULATION
+	select USB_ARCH_HAS_EHCI
+	select USB_ARCH_HAS_OHCI
+	select GENERIC_ATOMIC64
+	select HAVE_MEMBLOCK
+	select NO_BOOTMEM
+	select OLD_SIGACTION
+	select OLD_SIGSUSPEND3
+	select GENERIC_CPU_DEVICES
+	select MODULES_USE_ELF_REL if MODULES
+	select MODULES_USE_ELF_RELA if MODULES
+	select OF
+	select OF_EARLY_FLATTREE
+	select OF_RESERVED_MEM
+	select COMMON_CLK
+	select GENERIC_CLOCKEVENTS
+	select ARCH_WANT_IPC_PARSE_VERSION
+	select DW_APB_TIMER_OF
+	select GENERIC_SCHED_CLOCK
+	select GENERIC_IRQ_CHIP
+	select MAY_HAVE_SPARSE_IRQ
+
+config NR_CPUS
+	int
+	default "1"
+
+config UID16
+	bool
+	default n
+
+config RWSEM_GENERIC_SPINLOCK
+	bool
+	default y
+
+config RWSEM_XCHGADD_ALGORITHM
+	bool
+
+config ARCH_HAS_ILOG2_U32
+	bool
+	default n
+
+config HIGHMEM
+	bool
+	default n
+
+config GENERIC_FIND_NEXT_BIT
+	bool
+	default n
+
+config GENERIC_HWEIGHT
+	bool
+	default y
+
+config GENERIC_CALIBRATE_DELAY
+	bool
+	default y
+
+config GENERIC_GPIO
+	def_bool y
+
+config TIME_LOW_RES
+	bool
+	default y
+
+config GENERIC_IOMAP
+	bool
+
+config ARCH_MAY_HAVE_PC_FDC
+	bool
+
+config GENERIC_HARDIRQS
+	bool
+	default y
+
+config TRACE_IRQFLAGS_SUPPORT
+	bool
+	default y
+
+config NO_IOPORT
+	def_bool y
+
+config HZ
+	int
+	default 100
+
+config MMU
+	def_bool y
+
+config SYS_SUPPORTS_APM_EMULATION
+	bool
+
+config PGTABLE_LEVELS
+	int
+	default 2
+
+config ARCH_POPULATES_NODE_MAP
+	def_bool y
+
+source "init/Kconfig"
+
+source "kernel/Kconfig.freezer"
+
+menuconfig CSKY_ADDONS
+	bool "Addons for arch csky"
+	default y
+	help
+	  This is easy way to seperate vendor code and kernel code.
+	  It will make merging "kernel csky vendor" easier.
+
+if CSKY_ADDONS
+
+source "addons/Kconfig"
+
+endif
+
+config CSKY_DEBUG_INFO
+	bool "Compile the kernel with debug info, just add -g"
+	depends on !DEBUG_INFO
+	help
+		DEBUG_INFO and COMPILE_TEST is conflict, so we provide
+		another way to support -g.
+		Some drivers eg: DW_MMC need COMPILE_TEST for new cpu
+		arch :(
+
+menu "Processor type and features"
+
+comment "Processor type"
+
+choice
+        prompt "CPU MODEL"
+        default CPU_CK610
+
+config CPU_CK610
+        bool "CSKY CPU ck610"
+
+config CPU_CK810
+        bool "CSKY CPU ck810"
+	select MMU_HARD_REFILL
+	select HIGHMEM
+
+config CPU_CK807
+        bool "CSKY CPU ck807"
+	select MMU_HARD_REFILL
+	select HIGHMEM
+endchoice
+
+config MMU_HARD_REFILL
+	bool "Hard refill TLB miss exception"
+	depends on MMU
+	default n if CPU_MMU_V1
+	default y
+	help
+	   This control whether the hardware refill is enable or not when there
+	     is TLB miss exception
+
+menuconfig CPU_HAS_FPU
+	bool "CPU has FPU coprocessor"
+	depends on CPU_CK810 || CPU_CK807
+	default n
+	---help---
+	  You can say N here if you C-SKY CPU don't have Floating-Point Coprocessor 	  or the user program need not to support FPU.
+
+	  You'll have say N here if you C-SKY CPU have Floating-Point Coprocessor
+	  and the user program need to support FPU. Floating-Point Coprocessor (FPC)
+	  is a coprocessor of CK serial processor. The function of FPC is to provide
+	  low-cost high-speed float point computation, which is full compliance with
+	  ANSI/IEEE Std 754, IEEE Standard for Binary Floating-Point Arithmetic.
+
+	  Generally, the FPU need not to open exception. See also "FPC User Guide"
+	  and " C-SKY CPU Linux-2.6 User Guide" for more details.
+
+if CPU_HAS_FPU
+
+comment "FPU coprocessor exception options"
+
+config OPEN_FPU_IDE
+	bool "Open input denormalized exception"
+	default n
+
+config OPEN_FPU_IXE
+	bool "Open inexact exception"
+	default n
+
+config OPEN_FPU_UFE
+	bool "Open underflow exception"
+	default n
+
+config OPEN_FPU_OFE
+	bool "Open overflow exception"
+	default n
+
+config OPEN_FPU_DZE
+	bool "Open divide by zero exception"
+	default n
+
+config OPEN_FPU_IOE
+	bool "Open invalid operation exception"
+	default n
+
+endif # if CPU_HAS_FPU
+
+config CPU_HAS_DSP
+	bool "CPU support DSP enhanced instruction"
+	default n
+
+config CPU_BIG_ENDIAN
+	bool "Build big-endian kernel"
+	default n
+	---help---
+	  Say Y if you plan on running a kernel in big-endian mode.
+	  Note that your board must be properly built and your board
+	  port must properly enable any big-endian related features
+	   of your chipset/board/processor.
+
+
+config	SOFT_HANDMISSALIGN
+	bool "Software fixup alignment exception."
+	default y
+	depends on CPU_CK610
+	help
+          CSKY CPU cannot fetch/store information which is not
+          naturally aligned on the bus, i.e., a 4 byte fetch must start at an
+          address divisible by 4. On 32-bit CSKY processors, these non-aligned
+          fetch/store instructions will be emulated in software if you say
+          here, which has a severe performance impact. This is necessary for
+          correct operation of some network protocols. With an IP-only
+          configuration it is safe to say N, otherwise say Y.
+
+comment "*****System type*****"
+
+config RAM_BASE
+	hex "(S)DRAM base address(hex)"
+	default 0x08000000
+
+config PHYSICAL_BASE_CHANGE
+	bool "Change physical address of direct mapping"
+	depends on MMU
+	default n
+	help
+	  There are MSA0(cp15_cr30) and MSA1(cp15_cr31) can be used to change
+	  the base physical address of direct mapping. The default base physical
+	  address is 0x0.
+
+	  If unsure, say n.
+
+config SSEG0_BASE
+	hex "SSEG0's physical base(hex)"
+	depends on PHYSICAL_BASE_CHANGE
+	default 0x0
+	help
+	  SSEG0 is usually used as a ram section. set as C(cache), D(dirty) and
+	  V(valid).
+
+config CSKY_NR_IRQS
+	int "NR_IRQS to max virtual interrupt numbers of the whole system"
+	range 64 8192
+	default "128"
+	help
+	  Some platform need more virtual irq numbers the kernel could use, eg: gpio irq.
+	  You find them in /proc/interrupts.
+
+config CSKY_BUILTIN_DTB
+	bool "Use kernel builtin dtb"
+	default n
+
+config CSKY_BUILTIN_DTB_NAME
+	string "kernel builtin dtb name"
+	depends on CSKY_BUILTIN_DTB
+
+menu "irqchip drivers (in csky)"
+
+config NATIONALCHIP_IRQ
+	bool "nationalchip irq"
+	default y
+
+config CSKY_IRQ
+	bool "csky irq"
+	default y
+
+config DAHUA_IRQ
+	bool "dahua irq"
+	default y
+
+endmenu
+
+menu "Clock Source drivers (in csky)"
+
+config NATIONALCHIP_TIMER
+	bool "nationalchip timer"
+	select CLKSRC_MMIO
+	select CLKSRC_OF
+	default y
+endmenu
+
+endmenu
+
+menu "Power management options"
+
+source "kernel/power/Kconfig"
+
+config ARCH_SUSPEND_POSSIBLE
+    def_bool y
+
+endmenu
+
+source "mm/Kconfig"
+
+source "fs/Kconfig.binfmt"
+
+source "kernel/Kconfig.preempt"
+
+source "net/Kconfig"
+
+source "drivers/Kconfig"
+
+source "fs/Kconfig"
+
+source "arch/csky/Kconfig.debug"
+
+source "security/Kconfig"
+
+source "crypto/Kconfig"
+
+source "lib/Kconfig"
diff --git a/arch/csky/Kconfig.debug b/arch/csky/Kconfig.debug
new file mode 100644
index 0000000..f53b6d5
--- /dev/null
+++ b/arch/csky/Kconfig.debug
@@ -0,0 +1,5 @@
+menu "Kernel hacking"
+
+source "lib/Kconfig.debug"
+
+endmenu
diff --git a/arch/csky/Makefile b/arch/csky/Makefile
new file mode 100644
index 0000000..ef655ff
--- /dev/null
+++ b/arch/csky/Makefile
@@ -0,0 +1,89 @@
+OBJCOPYFLAGS	:=-O binary
+GZFLAGS		:=-9
+
+ifdef CONFIG_CPU_HAS_DSP
+DSPEXT =e
+endif
+
+ifdef CONFIG_CPU_HAS_FPU
+FPUEXT =f
+endif
+
+ifdef CONFIG_CPU_CK610
+CPUTYPE	= -Wa,-mcpu=ck610$(DSPEXT)$(FPUEXT)
+CSKYABI	= abiv1
+endif
+
+ifdef CONFIG_CPU_CK810
+CPUTYPE= -mcpu=ck810$(DSPEXT)$(FPUEXT)
+CSKYABI	= abiv2
+endif
+
+ifdef CONFIG_CPU_CK807
+CPUTYPE= -mcpu=ck807$(DSPEXT)$(FPUEXT)
+CSKYABI	= abiv2
+endif
+
+KBUILD_CFLAGS +=	-ffreestanding \
+			-fno-tree-dse \
+			-pipe \
+			-Wno-uninitialized \
+			$(CPUTYPE)
+
+ifeq ($(CONFIG_CSKY_DEBUG_INFO),y)
+KBUILD_CFLAGS += -g
+endif
+
+abidirs := $(patsubst %,arch/csky/%/,$(CSKYABI))
+
+KBUILD_CFLAGS += $(patsubst %,-I$(srctree)/%inc,$(abidirs))
+
+ifeq ($(CONFIG_CPU_BIG_ENDIAN),y)
+KBUILD_CPPFLAGS += -mbig-endian
+LDFLAGS += -EB
+else
+KBUILD_CPPFLAGS += -mlittle-endian
+LDFLAGS += -EL
+endif
+
+KBUILD_AFLAGS += $(KBUILD_CFLAGS)
+
+head-y				:= arch/csky/kernel/head.o
+
+core-y				+= arch/csky/kernel/
+core-y				+= arch/csky/mm/
+libs-y				+= arch/csky/lib/
+core-y				+= arch/csky/$(CSKYABI)/
+
+ifdef CONFIG_CSKY_BUILTIN_DTB
+core-y				+= arch/csky/boot/dts/
+endif
+
+drivers-$(CONFIG_OPROFILE)	+= arch/csky/oprofile/
+drivers-$(CONFIG_CSKY_ADDONS)	+= addons/
+
+all: zImage
+
+boot	:= arch/csky/boot
+
+dtbs: scripts
+	$(Q)$(MAKE) $(build)=$(boot)/dts
+
+%.dtb %.dtb.S %.dtb.o: scripts
+	$(Q)$(MAKE) $(build)=$(boot)/dts $(boot)/dts/$@
+
+zImage Image uImage: vmlinux dtbs
+	$(Q)$(MAKE) $(build)=$(boot) $(boot)/$@
+
+archmrproper:
+
+archclean:
+	$(Q)$(MAKE) $(clean)=$(boot)
+	rm -rf arch/csky/include/generated
+
+define archhelp
+  echo  '* zImage       - Compressed kernel image (arch/$(ARCH)/boot/zImage)'
+  echo  '  Image        - Uncompressed kernel image (arch/$(ARCH)/boot/Image)'
+  echo  '  uImage       - U-Boot wrapped zImage'
+endef
+
diff --git a/arch/csky/abiv1/Makefile b/arch/csky/abiv1/Makefile
new file mode 100644
index 0000000..3f8b88a
--- /dev/null
+++ b/arch/csky/abiv1/Makefile
@@ -0,0 +1,6 @@
+obj-y +=	src/misc.o
+obj-y +=	src/memcpy.o
+obj-y +=	src/tlb.o
+obj-y +=	src/mmap.o
+obj-y +=	src/cacheflush.o
+
diff --git a/arch/csky/abiv1/inc/abi/cacheflush.h b/arch/csky/abiv1/inc/abi/cacheflush.h
new file mode 100644
index 0000000..4f673dc
--- /dev/null
+++ b/arch/csky/abiv1/inc/abi/cacheflush.h
@@ -0,0 +1,38 @@
+#ifndef __ABI_CSKY_CACHEFLUSH_H
+#define __ABI_CSKY_CACHEFLUSH_H
+
+#include <linux/compiler.h>
+#include <asm/string.h>
+#include <asm/cache.h>
+
+#define ARCH_IMPLEMENTS_FLUSH_DCACHE_PAGE 1
+extern void flush_dcache_page(struct page *);
+
+#define flush_cache_mm(mm)		cache_op_all(INS_CACHE|DATA_CACHE|CACHE_CLR|CACHE_INV, 0)
+#define flush_cache_page(vma,page,pfn)	cache_op_all(INS_CACHE|DATA_CACHE|CACHE_CLR|CACHE_INV, 0)
+#define flush_cache_dup_mm(mm)		cache_op_all(INS_CACHE|DATA_CACHE|CACHE_CLR|CACHE_INV, 0)
+#define flush_icache_page(vma, page)	cache_op_all(INS_CACHE|CACHE_INV, 0)
+
+#define flush_cache_range(mm,start,end)	cache_op_range(start, end, INS_CACHE|DATA_CACHE|CACHE_CLR|CACHE_INV, 0)
+#define flush_cache_vmap(start, end)	cache_op_range(start, end, INS_CACHE|DATA_CACHE|CACHE_CLR|CACHE_INV, 0)
+#define flush_cache_vunmap(start, end)  cache_op_range(start, end, INS_CACHE|DATA_CACHE|CACHE_CLR|CACHE_INV, 0)
+#define flush_icache_range(start, end)	cache_op_range(start, end, INS_CACHE|CACHE_INV, 0)
+
+#define copy_from_user_page(vma, page, vaddr, dst, src, len) \
+do{ \
+	cache_op_all(INS_CACHE|DATA_CACHE|CACHE_CLR|CACHE_INV, 0); \
+	memcpy(dst, src, len); \
+	cache_op_all(INS_CACHE|CACHE_INV, 0); \
+}while(0)
+
+#define copy_to_user_page(vma, page, vaddr, dst, src, len) \
+do{ \
+	cache_op_all(INS_CACHE|DATA_CACHE|CACHE_CLR|CACHE_INV, 0); \
+	memcpy(dst, src, len); \
+}while(0)
+
+#define flush_dcache_mmap_lock(mapping)		do{}while(0)
+#define flush_dcache_mmap_unlock(mapping)	do{}while(0)
+
+#endif /* __ABI_CSKY_CACHEFLUSH_H */
+
diff --git a/arch/csky/abiv1/inc/abi/ckmmu.h b/arch/csky/abiv1/inc/abi/ckmmu.h
new file mode 100644
index 0000000..f7ede30
--- /dev/null
+++ b/arch/csky/abiv1/inc/abi/ckmmu.h
@@ -0,0 +1,213 @@
+#ifndef __ASM_CSKY_CKMMUV1_H
+#define __ASM_CSKY_CKMMUV1_H
+
+#define CSKY_TLB_SIZE 128
+
+static inline void select_mmu_cp(void)
+{
+	 __asm__ __volatile__("cpseti cp15\n\t");
+
+}
+
+static inline int read_mmu_index(void)
+{
+	int __res;
+	__asm__ __volatile__(
+			"cprcr %0, cpcr0\n\t"
+			:"=b" (__res));
+	return   __res;
+}
+
+static inline void write_mmu_index(int value)
+{
+
+	__asm__ __volatile__(
+			"cpwcr %0, cpcr0\n\t"
+			::"b"(value));
+}
+
+static inline int read_mmu_entrylo0(void)
+{
+	int __res;
+	__asm__ __volatile__(
+			"cprcr %0, cpcr2\n\t"
+			:"=b" (__res));
+
+	return __res;
+}
+
+static inline void write_mmu_entrylo0(int value)
+{
+	__asm__ __volatile__(
+			"cpwcr %0, cpcr2\n\t"
+			::"b"(value));
+}
+
+
+static inline int read_mmu_entrylo1(void)
+{
+	int __res;
+	__asm__ __volatile__(
+			"cprcr %0, cpcr3\n\t"
+			:"=b" (__res));
+
+	return __res;
+}
+
+static inline void write_mmu_entrylo1(int value)
+{
+	__asm__ __volatile__(
+			"cpwcr %0, cpcr3\n\t"
+			::"b"(value));
+}
+
+
+static inline int read_mmu_context(void)
+{
+	int __res;
+	__asm__ __volatile__(
+			"cprcr %0, cpcr5\n\t"
+			:"=b" (__res));
+
+	return __res;
+}
+
+static inline void write_mmu_context(int value)
+{
+	__asm__ __volatile__(
+			"cpwcr %0, cpcr5\n\t"
+			::"b"(value));
+}
+
+
+static inline int read_mmu_pagemask(void)
+{
+	int __res;
+
+	__asm__ __volatile__(
+			"cprcr %0, cpcr6\n\t"
+			:"=b" (__res));
+
+	return __res;
+}
+
+static inline void write_mmu_pagemask(int value)
+{
+	__asm__ __volatile__(
+			"cpwcr %0, cpcr6\n\t"
+			::"b"(value));
+}
+
+static inline int read_mmu_wired(void)
+{
+	int __res;
+
+	__asm__ __volatile__(
+			"cprcr %0, cpcr7\n\t"
+			:"=b" (__res));
+
+	return __res;
+}
+
+static inline void write_mmu_wired(int value)
+{
+	__asm__ __volatile__(
+			"cpwcr %0, cpcr7\n\t"
+			::"b"(value));
+}
+
+static inline int read_mmu_entryhi(void)
+{
+	int __res;
+	__asm__ __volatile__(
+			"cprcr %0, cpcr4\n\t"
+			:"=b" (__res));
+
+	return __res;
+}
+
+static inline void write_mmu_entryhi(int value)
+{
+
+	__asm__ __volatile__(
+			"cpwcr %0, cpcr4\n\t"
+			::"b"(value));
+}
+
+/*
+ * TLB operations.
+ */
+static inline void tlb_probe(void)
+{
+	int value = 0x80000000;
+
+	__asm__ __volatile__(
+			"cpwcr %0, cpcr8\n\t"
+			::"b"(value));
+}
+
+static inline void tlb_read(void)
+{
+	int value = 0x40000000;
+
+	__asm__ __volatile__(
+			"cpwcr %0, cpcr8\n\t"
+			::"b"(value));
+}
+
+static inline void tlb_write_indexed(void)
+{
+	int value = 0x20000000;
+
+	__asm__ __volatile__(
+			"cpwcr %0, cpcr8\n\t"
+			::"b"(value));
+}
+
+static inline void tlb_write_random(void)
+{
+	int value = 0x10000000;
+
+	__asm__ __volatile__(
+			"cpwcr %0, cpcr8\n\t"
+			::"b"(value));
+}
+
+static inline void tlb_invalid_indexed(void)
+{
+	int value = 0x02000000;
+
+	__asm__ __volatile__(
+			"cpwcr %0, cpcr8\n\t"
+			::"b"(value));
+}
+
+/* misc */
+static inline void tlbmiss_handler_setup_pgd(unsigned long pgd)
+{
+	__asm__ __volatile__(
+		"bseti %0, 0		\n\t"
+		"bclri %0, 31		\n\t"
+		"addu  %0, %1		\n\t"
+		"cpseti cp15		\n\t"
+		"cpwcr %0, cpcr29	\n\t"
+		::"b"(pgd), "r"(PHYS_OFFSET)
+		:);
+}
+
+static inline unsigned long tlb_get_pgd(void)
+{
+	unsigned long pgd;
+	__asm__ __volatile__(
+		"cpseti	cp15		\n\r"
+		"cprcr	%0, cpcr29	\n\r"
+		"bclri	%0, 0		\n\r"
+		"subu	%0, %1		\n\r"
+                "bseti	%0, 31		\n\r"
+                :"=&b"(pgd)
+		:"r"(PHYS_OFFSET)
+                :);
+	return pgd;
+}
+#endif /* __ASM_CSKY_CKMMUV1_H */
+
diff --git a/arch/csky/abiv1/inc/abi/entry.h b/arch/csky/abiv1/inc/abi/entry.h
new file mode 100644
index 0000000..f37a448
--- /dev/null
+++ b/arch/csky/abiv1/inc/abi/entry.h
@@ -0,0 +1,236 @@
+#ifndef __ASM_CSKY_ENTRY_H
+#define __ASM_CSKY_ENTRY_H
+
+#include <asm/setup.h>
+#include <abi/regdef.h>
+
+/*
+ * Stack layout in 'ret_from_exception':
+ *      Below describes the stack layout after initial exception entry.
+ *      All traps, interrupts and exceptions will set up the stack frame
+ *      in this way before starting processing proper.
+ *	This allows access to the syscall arguments in registers r1-r5
+ *
+ *	 0(sp) - pc
+ *	 4(sp) - orig_a0
+ *	 8(sp) - sr
+ *	 C(sp) - a0
+ *	10(sp) - a1
+ *	14(sp) - a2
+ *	18(sp) - a3
+ *	1C(sp) - regs0
+ *	20(sp) - regs1
+ *	24(sp) - regs2
+ *	28(sp) - regs3
+ *	2C(sp) - regs4
+ *	30(sp) - regs5
+ *	34(sp) - regs6
+ *	38(sp) - regs7
+ *	3C(sp) - regs8
+ *	40(sp) - regs9
+ *	44(sp) - r15
+ */
+#define LSAVE_A0       0xc
+#define LSAVE_A1       0x10
+#define LSAVE_A2       0x14
+#define LSAVE_A3       0x18
+#define LSAVE_REGS0    0x1C
+#define LSAVE_REGS1    0x20
+
+/*
+ *      This code creates the normal kernel pt_regs layout on a trap
+ *      or interrupt. The only trick here is that we check whether we
+ *      came from supervisor mode before changing stack pointers.
+ */
+
+.macro	SAVE_ALL
+        mtcr    regs7, ss2    /* save original regs7=r13 */
+        mtcr    a0, ss3/* save original a0 */
+        mfcr    regs7, epsr   /* Get original PSR */
+        btsti   regs7, 31     /* Check if was supervisor */
+        bt      1f
+        mtcr    sp, ss1/* save user stack */
+        mfcr    sp, ss0/* Set kernel stack */
+
+1:
+        subi    sp, 32
+        subi    sp, 32
+        stw     regs7, (sp, 0)  /* original epsr */
+        stw     a0, (sp, 4)
+        stw     a1, (sp, 8)
+        stw     a2, (sp, 12)
+        stw     a3, (sp, 16)
+        stw     regs0, (sp, 20)
+        stw     regs1, (sp, 24)
+        stw     regs2, (sp, 28)
+        stw     regs3, (sp, 32)
+	stw     regs4, (sp, 36)
+        stw     regs5, (sp, 40)
+        stw     regs6, (sp, 44)
+        mfcr    regs7, ss2     /* Save original regs7=r13 on stack */
+        stw     regs7, (sp, 48)
+        stw     regs8, (sp, 52)
+        stw     regs9, (sp, 56)
+        stw     r15, (sp, 60)
+
+	subi    sp, 8        /* Make room for PC/orig_a0 */
+	stw     a0, (sp, 4)      /*Save syscall a0 on stack */
+        mfcr    regs7, epc     /* Save PC on stack */
+        stw     regs7, (sp)
+.endm
+
+.macro	RESTORE_ALL
+        psrclr  ie     /* Disable interrupt */
+	ldw     a0, (sp)        /* Restore PC */
+        mtcr    a0, epc/* Set return PC */
+        ldw     a0, (sp, 8)     /* Get saved PSR */
+        mtcr    a0, epsr        /* Restore PSR */
+	addi    sp, 12
+        btsti   a0, 31 /* Check if returning to user */
+        ldw     a0, (sp, 0)
+        ldw     a1, (sp, 4)
+        ldw     a2, (sp, 8)
+        ldw     a3, (sp, 12)
+        ldw     regs0, (sp, 16)
+        ldw     regs1, (sp, 20)
+        ldw     regs2, (sp, 24)
+        ldw     regs3, (sp, 28)
+        ldw     regs4, (sp, 32)
+        ldw     regs5, (sp, 36)
+        ldw     regs6, (sp, 40)
+        ldw     regs7, (sp, 44)
+	ldw     regs8, (sp, 48)
+        ldw     regs9, (sp, 52)
+        ldw     r15, (sp, 56)
+        addi    sp, 32 /* Increment stack pointer */
+        addi    sp, 28
+        bt      1f
+        mtcr    sp, ss0/* Save kernel stack*/
+        mfcr    sp, ss1/* Set  user stack */
+1:
+        rte
+.endm
+
+#define SAVE_SWITCH_STACK save_switch_stack
+#define RESTORE_SWITCH_STACK restore_switch_stack
+#define GET_CURRENT(tmp)
+
+.macro	save_switch_stack
+	subi    sp, 32
+        stm     r8-r15,(sp)
+.endm
+
+.macro	restore_switch_stack
+        ldm     r8-r15,(sp)
+        addi    sp, 32
+.endm
+
+.macro  PT_REGS_ADJUST  rx   /* abiv2 when argc>5 need push r4 r5 in syscall */
+        mov      \rx, sp
+.endm
+/*
+ * Because kernel don't use FPU and only user program use FPU, we select
+ * coprocessor 15(MMU) when in super-mode. So this macro is called when
+ * CPU enter from user-mode to kernel super-mode except MMU exception.
+ */
+.macro SET_SMOD_MMU_CP15
+	cpseti  cp15
+.endm
+
+/*
+ * Below, are macros for MMU operating, use them to switch cop, read or write
+ * registers of MMU in assemble files. Macro __CSKYABIV1__ means MMU in
+ * coprocessor.
+ */
+/* Coprocessor switch to MMU */
+.macro SET_CP_MMU
+	cpseti  cp15
+.endm
+
+/* MMU registers read operators. */
+.macro RD_MIR	rx
+	cprcr   \rx, cpcr0
+.endm
+
+.macro RD_MRR	rx
+	cprcr   \rx, cpcr1
+.endm
+
+.macro RD_MEL0	rx
+	cprcr   \rx, cpcr2
+.endm
+
+.macro RD_MEL1	rx
+	cprcr   \rx, cpcr3
+.endm
+
+.macro RD_MEH	rx
+	cprcr   \rx, cpcr4
+.endm
+
+.macro RD_MCR	rx
+	cprcr   \rx, cpcr5
+.endm
+
+.macro RD_MPR	rx
+	cprcr   \rx, cpcr6
+.endm
+
+.macro RD_MWR	rx
+	cprcr   \rx, cpcr7
+.endm
+
+.macro RD_MCIR	rx
+	cprcr   \rx, cpcr8
+.endm
+
+.macro RD_PGDR  rx
+        cprcr   \rx, cpcr29
+.endm
+
+/* MMU registers write operators. */
+.macro WR_MIR	rx
+	cpwcr   \rx, cpcr0
+.endm
+
+.macro WR_MRR	rx
+	cpwcr   \rx, cpcr1
+.endm
+
+.macro WR_MEL0	rx
+	cpwcr   \rx, cpcr2
+.endm
+
+.macro WR_MEL1	rx
+	cpwcr   \rx, cpcr3
+.endm
+
+.macro WR_MEH	rx
+	cpwcr   \rx, cpcr4
+.endm
+
+.macro WR_MCR	rx
+	cpwcr   \rx, cpcr5
+.endm
+
+.macro WR_MPR	rx
+	cpwcr   \rx, cpcr6
+.endm
+
+.macro WR_MWR	rx
+	cpwcr   \rx, cpcr7
+.endm
+
+.macro WR_MCIR	rx
+	cpwcr   \rx, cpcr8
+.endm
+
+.macro WR_MSA0	rx
+	cpwcr   \rx, cpcr30
+.endm
+
+.macro WR_MSA1	rx
+	cpwcr   \rx, cpcr31
+.endm
+
+#endif /* __ASM_CSKY_ENTRY_H */
diff --git a/arch/csky/abiv1/inc/abi/page.h b/arch/csky/abiv1/inc/abi/page.h
new file mode 100644
index 0000000..951dc79
--- /dev/null
+++ b/arch/csky/abiv1/inc/abi/page.h
@@ -0,0 +1,24 @@
+extern unsigned long shm_align_mask;
+extern void flush_dcache_page(struct page *);
+
+static inline unsigned long pages_do_alias(unsigned long addr1,
+					   unsigned long addr2)
+{
+	return (addr1 ^ addr2) & shm_align_mask;
+}
+
+static inline void clear_user_page(void *addr, unsigned long vaddr,
+				   struct page *page)
+{
+	clear_page(addr);
+	if (pages_do_alias((unsigned long) addr, vaddr & PAGE_MASK))
+		flush_dcache_page(page);
+}
+
+static inline void copy_user_page(void *to, void *from, unsigned long vaddr,
+				  struct page *page)
+{
+	copy_page(to, from);
+	if (pages_do_alias((unsigned long) to, vaddr & PAGE_MASK))
+		flush_dcache_page(page);
+}
diff --git a/arch/csky/abiv1/inc/abi/pgtable-bits.h b/arch/csky/abiv1/inc/abi/pgtable-bits.h
new file mode 100644
index 0000000..28dc674
--- /dev/null
+++ b/arch/csky/abiv1/inc/abi/pgtable-bits.h
@@ -0,0 +1,25 @@
+#ifndef __ASM_CSKY_PGTABLE_BITS_H
+#define __ASM_CSKY_PGTABLE_BITS_H
+
+#define _PAGE_PRESENT               (1<<0)  /* implemented in software */
+#define _PAGE_READ                  (1<<1)  /* implemented in software */
+#define _PAGE_WRITE                 (1<<2)  /* implemented in software */
+#define _PAGE_ACCESSED              (1<<3)  /* implemented in software */
+#define _PAGE_MODIFIED              (1<<4)  /* implemented in software */
+#define _PAGE_FILE                  (1<<4)  /* set:pagecache unset:swap */
+#define _PAGE_GLOBAL                (1<<6)
+#define _PAGE_VALID                 (1<<7)
+#define _PAGE_SILENT_READ           (1<<7)  /* synonym                 */
+#define _PAGE_DIRTY                 (1<<8)  /* The CSKY dirty bit      */
+#define _PAGE_SILENT_WRITE          (1<<8)
+#define _CACHE_MASK                 (7<<9)
+
+#define _CACHE_UNCACHED             (0x12<<6)
+#define _CACHE_CACHED               (0x1a<<6)
+
+#define pte_to_pgoff(_pte) (pte.pte_low >> 4)
+#define pgoff_to_pte(off) ((pte_t)((off << 4) + _PAGE_FILE))
+
+#define HAVE_ARCH_UNMAPPED_AREA
+
+#endif /* __ASM_CSKY_PGTABLE_BITS_H */
diff --git a/arch/csky/abiv1/inc/abi/reg_ops.h b/arch/csky/abiv1/inc/abi/reg_ops.h
new file mode 100644
index 0000000..6a3a3eb
--- /dev/null
+++ b/arch/csky/abiv1/inc/abi/reg_ops.h
@@ -0,0 +1,70 @@
+#ifndef __ASM_REG_OPS_H
+#define __ASM_REG_OPS_H
+
+static inline unsigned int mfcr_cpuidrr(void)
+{
+	unsigned int ret;
+	__asm__ __volatile__(
+		"mfcr %0, cr13\t\n"
+		:"=r"(ret));
+	return ret;
+}
+
+static inline unsigned int mfcr_hint(void)
+{
+	unsigned int ret;
+	__asm__ __volatile__(
+		"mfcr %0, cr30\t\n"
+		:"=r"(ret));
+	return ret;
+}
+
+static inline unsigned int mfcr_ccr(void)
+{
+	unsigned int ret;
+	__asm__ __volatile__(
+		"mfcr %0, cr18\t\n"
+		:"=r"(ret));
+	return ret;
+}
+
+static inline unsigned int mfcr_msa0(void)
+{
+	unsigned int ret;
+	__asm__ __volatile__(
+		"cprcr %0, cpcr30\t\n"
+		:"=r"(ret));
+	return ret;
+}
+
+static inline void mtcr_msa0(unsigned int value)
+{
+	__asm__ __volatile__(
+		"cpwcr %0, cpcr30\t\n"
+		::"r"(value));
+}
+
+static inline unsigned int mfcr_msa1(void)
+{
+	unsigned int ret;
+	__asm__ __volatile__(
+		"cprcr %0, cpcr31\t\n"
+		:"=r"(ret));
+	return ret;
+}
+
+static inline void mtcr_msa1(unsigned int value)
+{
+	__asm__ __volatile__(
+		"cpwcr %0, cpcr31\t\n"
+		::"r"(value));
+}
+
+static inline unsigned int mfcr_ccr2(void){return 0;}
+
+#define L1_SYNC do{__asm__ __volatile__("sync\t\n");}while(0)
+
+#define CSKYCPU_DEF_NAME "csky,ck610"
+
+#endif /* __ASM_REG_OPS_H */
+
diff --git a/arch/csky/abiv1/inc/abi/regdef.h b/arch/csky/abiv1/inc/abi/regdef.h
new file mode 100644
index 0000000..6d33cd1
--- /dev/null
+++ b/arch/csky/abiv1/inc/abi/regdef.h
@@ -0,0 +1,23 @@
+#ifndef  __ASM_CSKY_REGDEF_H
+#define  __ASM_CSKY_REGDEF_H
+
+#define syscallid	r1
+#define regs0		r6
+#define regs1		r7
+#define regs2		r8
+#define regs3		r9
+#define regs4		r10
+#define regs5		r11
+#define regs6		r12
+#define regs7		r13
+#define regs8		r14
+#define regs9		r1
+
+/*
+ * use as judge restart syscall, see entry.S
+ */
+#define r11_sig		r11
+
+#define DEFAULT_PSR_VALUE	0x8f000000
+
+#endif /* __ASM_CSKY_REGDEF_H */
diff --git a/arch/csky/abiv1/src/cacheflush.c b/arch/csky/abiv1/src/cacheflush.c
new file mode 100644
index 0000000..9b92dc6
--- /dev/null
+++ b/arch/csky/abiv1/src/cacheflush.c
@@ -0,0 +1,31 @@
+#include <linux/kernel.h>
+#include <linux/mm.h>
+#include <linux/fs.h>
+#include <linux/syscalls.h>
+#include <linux/spinlock.h>
+#include <asm/uaccess.h>
+#include <asm/page.h>
+#include <asm/cache.h>
+#include <asm/cacheflush.h>
+#include <asm/cachectl.h>
+#include <abi/reg_ops.h>
+
+void flush_dcache_page(struct page *page)
+{
+	struct address_space *mapping = page_mapping(page);
+	unsigned long addr;
+
+	if (mapping && !mapping_mapped(mapping)) {
+		set_bit(PG_arch_1, &(page)->flags);
+		return;
+	}
+
+	/*
+	 * We could delay the flush for the !page_mapping case too.  But that
+	 * case is for exec env/arg pages and those are %99 certainly going to
+	 * get faulted into the tlb (and thus flushed) anyways.
+	 */
+	addr = (unsigned long) page_address(page);
+	cache_op_range(addr, addr + PAGE_SIZE, CACHE_INV|CACHE_CLR|DATA_CACHE, 0);
+}
+
diff --git a/arch/csky/abiv1/src/memcpy.S b/arch/csky/abiv1/src/memcpy.S
new file mode 100644
index 0000000..620fd72
--- /dev/null
+++ b/arch/csky/abiv1/src/memcpy.S
@@ -0,0 +1,342 @@
+#include <linux/linkage.h>
+
+.macro	GET_FRONT_BITS rx y
+#ifdef	__cskyLE__
+	lsri	\rx, \y
+#else
+	lsli	\rx, \y
+#endif
+.endm
+
+.macro	GET_AFTER_BITS rx y
+#ifdef	__cskyLE__
+	lsli	\rx, \y
+#else
+	lsri	\rx, \y
+#endif
+.endm
+
+/* void *memcpy(void *dest, const void *src, size_t n); */
+ENTRY(memcpy)
+	mov	r7, r2
+	cmplti	r4, 4                                   /* If len less than 4 bytes */
+	bt	.L_copy_by_byte
+	mov	r6, r2
+	andi	r6, 3
+	cmpnei	r6, 0
+	jbt	.L_dest_not_aligned                     /* If dest is not 4 bytes aligned */
+	mov	r6, r3
+	andi	r6, 3
+	cmpnei	r6, 0
+	jbt	.L_dest_aligned_but_src_not_aligned     /* If dest is aligned, but src is not aligned */
+.L0:
+	cmplti	r4, 16
+	jbt	.L_aligned_and_len_less_16bytes         /* If len less than 16 bytes */
+	subi	sp, 8
+	stw	r8, (sp, 0)
+.L_aligned_and_len_larger_16bytes:                      /* src and dst are all aligned, and len > 16 bytes */
+	ldw	r1, (r3, 0)
+	ldw	r5, (r3, 4)
+	ldw	r8, (r3, 8)
+	stw	r1, (r7, 0)
+	ldw	r1, (r3, 12)
+	stw	r5, (r7, 4)
+	stw	r8, (r7, 8)
+	stw	r1, (r7, 12)
+	subi	r4, 16
+	addi	r3, 16
+	addi	r7, 16
+	cmplti	r4, 16
+	jbf	.L_aligned_and_len_larger_16bytes
+	ldw	r8, (sp, 0)
+	addi	sp, 8
+	cmpnei	r4, 0                    /* If len == 0, return, else goto .L_aligned_and_len_less_16bytes  */
+	jbf	.L_return
+
+.L_aligned_and_len_less_16bytes:
+	cmplti	r4, 4
+	bt	.L_copy_by_byte
+.L1:
+	ldw	r1, (r3, 0)
+	stw	r1, (r7, 0)
+	subi	r4, 4
+	addi	r3, 4
+	addi	r7, 4
+	cmplti	r4, 4
+	jbf	.L1
+	br	.L_copy_by_byte
+
+.L_return:
+	rts
+
+.L_copy_by_byte:                      /* len less than 4 bytes */
+	cmpnei	r4, 0
+	jbf	.L_return
+.L4:
+	ldb	r1, (r3, 0)
+	stb	r1, (r7, 0)
+	addi	r3, 1
+	addi	r7, 1
+	decne	r4
+	jbt	.L4
+	rts
+
+/* If dest is not aligned, just copying some bytes makes the dest align.
+   Afther that, we judge whether the src is aligned. */
+.L_dest_not_aligned:
+	mov	r5, r3
+	rsub	r5, r5, r7
+	abs	r5, r5
+	cmplt	r5, r4
+	bt	.L_copy_by_byte
+	mov	r5, r7
+	sub	r5, r3
+	cmphs	r5, r4
+	bf	.L_copy_by_byte
+	mov	r5, r6
+.L5:
+	ldb	r1, (r3, 0)              /* makes the dest align. */
+	stb	r1, (r7, 0)
+	addi	r5, 1
+	subi	r4, 1
+	addi	r3, 1
+	addi	r7, 1
+	cmpnei	r5, 4
+	jbt	.L5
+	cmplti	r4, 4
+	jbt	.L_copy_by_byte
+	mov	r6, r3                   /* judge whether the src is aligned. */
+	andi	r6, 3
+	cmpnei	r6, 0
+	jbf	.L0
+
+/* Judge the number of misaligned, 1, 2, 3? */
+.L_dest_aligned_but_src_not_aligned:
+	mov	r5, r3
+	rsub	r5, r5, r7
+	abs	r5, r5
+	cmplt	r5, r4
+	bt	.L_copy_by_byte
+	bclri	r3, 0
+	bclri	r3, 1
+	ldw	r1, (r3, 0)
+	addi	r3, 4
+	cmpnei	r6, 2
+	bf	.L_dest_aligned_but_src_not_aligned_2bytes
+	cmpnei	r6, 3
+	bf	.L_dest_aligned_but_src_not_aligned_3bytes
+
+.L_dest_aligned_but_src_not_aligned_1byte:
+	mov	r5, r7
+	sub	r5, r3
+	cmphs	r5, r4
+	bf	.L_copy_by_byte
+	cmplti	r4, 16
+	bf	.L11
+.L10:                                     /* If the len is less than 16 bytes */
+	GET_FRONT_BITS r1 8
+	mov	r5, r1
+	ldw	r6, (r3, 0)
+	mov	r1, r6
+	GET_AFTER_BITS r6 24
+	or	r5, r6
+	stw	r5, (r7, 0)
+	subi	r4, 4
+	addi	r3, 4
+	addi	r7, 4
+	cmplti	r4, 4
+	bf	.L10
+	subi	r3, 3
+	br	.L_copy_by_byte
+.L11:
+	subi	sp, 16
+	stw	r8, (sp, 0)
+	stw	r9, (sp, 4)
+	stw	r10, (sp, 8)
+	stw	r11, (sp, 12)
+.L12:
+	ldw	r5, (r3, 0)
+	ldw	r11, (r3, 4)
+	ldw	r8, (r3, 8)
+	ldw	r9, (r3, 12)
+
+	GET_FRONT_BITS r1 8               /* little or big endian? */
+	mov	r10, r5
+	GET_AFTER_BITS r5 24
+	or	r5, r1
+
+	GET_FRONT_BITS r10 8
+	mov	r1, r11
+	GET_AFTER_BITS r11 24
+	or	r11, r10
+
+	GET_FRONT_BITS r1 8
+	mov	r10, r8
+	GET_AFTER_BITS r8 24
+	or	r8, r1
+
+	GET_FRONT_BITS r10 8
+	mov	r1, r9
+	GET_AFTER_BITS r9 24
+	or	r9, r10
+
+	stw	r5, (r7, 0)
+	stw	r11, (r7, 4)
+	stw	r8, (r7, 8)
+	stw	r9, (r7, 12)
+	subi	r4, 16
+	addi	r3, 16
+	addi	r7, 16
+	cmplti	r4, 16
+	jbf	.L12
+	ldw	r8, (sp, 0)
+	ldw	r9, (sp, 4)
+	ldw	r10, (sp, 8)
+	ldw	r11, (sp, 12)
+	addi	sp , 16
+	cmplti	r4, 4
+	bf	.L10
+	subi	r3, 3
+	br	.L_copy_by_byte
+
+.L_dest_aligned_but_src_not_aligned_2bytes:
+	cmplti	r4, 16
+	bf	.L21
+.L20:
+	GET_FRONT_BITS r1 16
+	mov	r5, r1
+	ldw	r6, (r3, 0)
+	mov	r1, r6
+	GET_AFTER_BITS r6 16
+	or	r5, r6
+	stw	r5, (r7, 0)
+	subi	r4, 4
+	addi	r3, 4
+	addi	r7, 4
+	cmplti	r4, 4
+	bf	.L20
+	subi	r3, 2
+	br	.L_copy_by_byte
+	rts
+
+.L21:	/* n > 16 */
+	subi 	sp, 16
+	stw	r8, (sp, 0)
+	stw	r9, (sp, 4)
+	stw	r10, (sp, 8)
+	stw	r11, (sp, 12)
+
+.L22:
+	ldw	r5, (r3, 0)
+	ldw	r11, (r3, 4)
+	ldw	r8, (r3, 8)
+	ldw	r9, (r3, 12)
+
+	GET_FRONT_BITS r1 16
+	mov	r10, r5
+	GET_AFTER_BITS r5 16
+	or	r5, r1
+
+	GET_FRONT_BITS r10 16
+	mov	r1, r11
+	GET_AFTER_BITS r11 16
+	or	r11, r10
+
+	GET_FRONT_BITS r1 16
+	mov	r10, r8
+	GET_AFTER_BITS r8 16
+	or	r8, r1
+
+	GET_FRONT_BITS r10 16
+	mov	r1, r9
+	GET_AFTER_BITS r9 16
+	or	r9, r10
+
+	stw	r5, (r7, 0)
+	stw	r11, (r7, 4)
+	stw	r8, (r7, 8)
+	stw	r9, (r7, 12)
+	subi	r4, 16
+	addi	r3, 16
+	addi	r7, 16
+	cmplti	r4, 16
+	jbf	.L22
+	ldw	r8, (sp, 0)
+	ldw	r9, (sp, 4)
+	ldw	r10, (sp, 8)
+	ldw	r11, (sp, 12)
+	addi	sp, 16
+	cmplti	r4, 4
+	bf	.L20
+	subi	r3, 2
+	br	.L_copy_by_byte
+
+
+.L_dest_aligned_but_src_not_aligned_3bytes:
+	cmplti	r4, 16
+	bf	.L31
+.L30:
+	GET_FRONT_BITS r1 24
+	mov	r5, r1
+	ldw	r6, (r3, 0)
+	mov	r1, r6
+	GET_AFTER_BITS r6 8
+	or	r5, r6
+	stw	r5, (r7, 0)
+	subi	r4, 4
+	addi	r3, 4
+	addi	r7, 4
+	cmplti	r4, 4
+	bf	.L30
+	subi	r3, 1
+	br	.L_copy_by_byte
+.L31:
+	subi	sp, 16
+	stw	r8, (sp, 0)
+	stw	r9, (sp, 4)
+	stw	r10, (sp, 8)
+	stw	r11, (sp, 12)
+.L32:
+	ldw	r5, (r3, 0)
+	ldw	r11, (r3, 4)
+	ldw	r8, (r3, 8)
+	ldw	r9, (r3, 12)
+
+	GET_FRONT_BITS r1 24
+	mov	r10, r5
+	GET_AFTER_BITS r5 8
+	or	r5, r1
+
+	GET_FRONT_BITS r10 24
+	mov	r1, r11
+	GET_AFTER_BITS r11 8
+	or	r11, r10
+
+	GET_FRONT_BITS r1 24
+	mov	r10, r8
+	GET_AFTER_BITS r8 8
+	or	r8, r1
+
+	GET_FRONT_BITS r10 24
+	mov	r1, r9
+	GET_AFTER_BITS r9 8
+	or	r9, r10
+
+	stw	r5, (r7, 0)
+	stw	r11, (r7, 4)
+	stw	r8, (r7, 8)
+	stw	r9, (r7, 12)
+	subi	r4, 16
+	addi	r3, 16
+	addi	r7, 16
+	cmplti	r4, 16
+	jbf	.L32
+	ldw	r8, (sp, 0)
+	ldw	r9, (sp, 4)
+	ldw	r10, (sp, 8)
+	ldw	r11, (sp, 12)
+	addi	sp, 16
+	cmplti	r4, 4
+	bf	.L30
+	subi	r3, 1
+	br	.L_copy_by_byte
diff --git a/arch/csky/abiv1/src/misc.c b/arch/csky/abiv1/src/misc.c
new file mode 100644
index 0000000..30a770a
--- /dev/null
+++ b/arch/csky/abiv1/src/misc.c
@@ -0,0 +1,76 @@
+#include <asm/ptrace.h>
+#include <linux/kernel.h>
+#include <linux/sched.h>
+
+unsigned long os_config_fcr;
+
+inline unsigned int
+read_pt_regs(unsigned int rx, struct pt_regs *regs)
+{
+	unsigned int value;
+
+	if (rx == 0) {
+		if (user_mode(regs)) {
+			__asm__ __volatile__("mfcr %0, ss1 \n\r"
+						:"=r"(value));
+		} else {
+			value = sizeof(struct pt_regs) + ((unsigned int)regs);
+		}
+	} else if (rx == 1){
+		value = regs->regs[9];
+	} else if (rx == 15){
+		value = regs->r15;
+	} else {
+		value = *((int *)regs + rx + 1);
+	}
+
+	return value;
+}
+
+inline void
+write_pt_regs(unsigned int value, unsigned int rx, struct pt_regs *regs)
+{
+	if (rx == 0) {
+		printk("math emulate trying to write sp.\n");
+	} else if (rx == 1) {
+		regs->regs[9] = value;
+	} else if (rx == 15) {
+		regs->r15 = value;
+	} else {
+		*((int *)regs + rx + 1) = value;
+	}
+}
+
+void __init init_fpu(void) {}
+
+inline unsigned int read_fpcr(void)
+{
+	return current->thread.fcr;
+}
+
+inline void write_fpcr(unsigned int val)
+{
+	val |= os_config_fcr;
+	current->thread.fcr = val;
+}
+
+inline unsigned int read_fpsr(void)
+{
+	return current->thread.fsr;
+}
+
+inline void write_fpsr(unsigned int val)
+{
+	current->thread.fsr = val;
+}
+
+inline unsigned int read_fpesr(void)
+{
+	return current->thread.fesr;
+}
+
+inline void write_fpesr(unsigned int val)
+{
+	current->thread.fesr = val;
+}
+
diff --git a/arch/csky/abiv1/src/mmap.c b/arch/csky/abiv1/src/mmap.c
new file mode 100644
index 0000000..c50733b
--- /dev/null
+++ b/arch/csky/abiv1/src/mmap.c
@@ -0,0 +1,63 @@
+#include <linux/fs.h>
+#include <linux/mm.h>
+#include <linux/mman.h>
+#include <linux/shm.h>
+#include <linux/sched.h>
+#include <linux/random.h>
+#include <linux/io.h>
+
+unsigned long shm_align_mask = (0x4000 >> 1) - 1;   /* Sane caches */
+
+#define COLOUR_ALIGN(addr,pgoff)                            \
+	((((addr) + shm_align_mask) & ~shm_align_mask) +        \
+	 (((pgoff) << PAGE_SHIFT) & shm_align_mask))
+
+unsigned long arch_get_unmapped_area(struct file *filp, unsigned long addr,
+		unsigned long len, unsigned long pgoff, unsigned long flags)
+{
+	struct vm_area_struct * vmm;
+	int do_color_align;
+
+	if (flags & MAP_FIXED) {
+		/*
+		 * We do not accept a shared mapping if it would violate
+		 * cache aliasing constraints.
+		 */
+		if ((flags & MAP_SHARED) &&
+				((addr - (pgoff << PAGE_SHIFT)) & shm_align_mask))
+			return -EINVAL;
+		return addr;
+	}
+
+	if (len > TASK_SIZE)
+		return -ENOMEM;
+	do_color_align = 0;
+	if (filp || (flags & MAP_SHARED))
+		do_color_align = 1;
+	if (addr) {
+		if (do_color_align)
+			addr = COLOUR_ALIGN(addr, pgoff);
+		else
+			addr = PAGE_ALIGN(addr);
+		vmm = find_vma(current->mm, addr);
+		if (TASK_SIZE - len >= addr &&
+				(!vmm || addr + len <= vmm->vm_start))
+			return addr;
+	}
+	addr = TASK_UNMAPPED_BASE;
+	if (do_color_align)
+		addr = COLOUR_ALIGN(addr, pgoff);
+	else
+		addr = PAGE_ALIGN(addr);
+
+	for (vmm = find_vma(current->mm, addr); ; vmm = vmm->vm_next) {
+		/* At this point:  (!vmm || addr < vmm->vm_end). */
+		if (TASK_SIZE - len < addr)
+			return -ENOMEM;
+		if (!vmm || addr + len <= vmm->vm_start)
+			return addr;
+		addr = vmm->vm_end;
+		if (do_color_align)
+			addr = COLOUR_ALIGN(addr, pgoff);
+	}
+}
diff --git a/arch/csky/abiv1/src/tlb.c b/arch/csky/abiv1/src/tlb.c
new file mode 100644
index 0000000..1d85d94
--- /dev/null
+++ b/arch/csky/abiv1/src/tlb.c
@@ -0,0 +1,287 @@
+#include <linux/init.h>
+#include <linux/sched.h>
+#include <linux/mm.h>
+
+#include <asm/setup.h>
+#include <asm/mmu_context.h>
+#include <linux/module.h>
+#include <asm/pgtable.h>
+
+#include <abi/ckmmu.h>
+
+#undef DEBUG_TLB
+#undef DEBUG_TLBUPDATE
+
+#define ENTER_CRITICAL(flags) local_irq_save(flags)
+#define EXIT_CRITICAL(flags) local_irq_restore(flags)
+
+void local_flush_tlb_all(void)
+{
+	unsigned long flags;
+	unsigned long old_ctx;
+	int entry;
+
+#ifdef DEBUG_TLB
+	printk("[tlball]");
+#endif
+
+	local_irq_save(flags);
+	/* Save old context and create impossible VPN2 value */
+	old_ctx = read_mmu_entryhi();
+	write_mmu_entrylo0(0);
+	write_mmu_entrylo1(0);
+
+	entry = read_mmu_wired();
+
+	/* Blast 'em all away. */
+	while (entry < CSKY_TLB_SIZE) {
+		/*
+		 * Make sure all entries differ.  If they're not different
+		 * CSKY will take revenge ...
+		 */
+		write_mmu_entryhi(KSEG0 + entry * 0x2000);
+		write_mmu_index(entry);
+		tlb_write_indexed();
+		entry++;
+	}
+	write_mmu_entryhi(old_ctx);
+	local_irq_restore(flags);
+}
+
+void local_flush_tlb_mm(struct mm_struct *mm)
+{
+	int cpu = smp_processor_id();
+
+	if (cpu_context(cpu, mm) != 0) {
+#ifdef DEBUG_TLB
+		printk("[tlbmm<%d>]", cpu_context(cpu, mm));
+#endif
+		drop_mmu_context(mm,cpu);
+	}
+}
+
+void local_flush_tlb_range(struct vm_area_struct *vma, unsigned long start,
+        unsigned long end)
+{
+	struct mm_struct *mm = vma->vm_mm;
+	int cpu = smp_processor_id();
+
+	if (cpu_context(cpu, mm) != 0) {
+		unsigned long size, flags;
+
+		local_irq_save(flags);
+		size = (end - start + (PAGE_SIZE - 1)) >> PAGE_SHIFT;
+		size = (size + 1) >> 1;
+		if (size <= CSKY_TLB_SIZE/2) {
+			int oldpid = read_mmu_entryhi();
+			int newpid = cpu_asid(cpu, mm);
+
+			start &= (PAGE_MASK << 1);
+			end += ((PAGE_SIZE << 1) - 1);
+			end &= (PAGE_MASK << 1);
+			while (start < end) {
+				int idx;
+
+				write_mmu_entryhi(start | newpid);
+				start += (PAGE_SIZE << 1);
+				tlb_probe();
+				idx = read_mmu_index();
+				write_mmu_entrylo0(0);
+				write_mmu_entrylo1(0);
+				if (idx < 0)
+				{
+					write_mmu_entryhi((start | newpid) + 1);
+					continue;
+				}
+				/* Make sure all entries differ. */
+				write_mmu_entryhi(KSEG0 + idx*0x2000);
+				tlb_write_indexed();
+			}
+			write_mmu_entryhi(oldpid);
+		} else {
+			drop_mmu_context(mm, cpu);
+		}
+		local_irq_restore(flags);
+	}
+}
+
+void local_flush_tlb_kernel_range(unsigned long start, unsigned long end)
+{
+	unsigned long size, flags;
+
+#ifdef DEBUG_TLB
+	printk("[tlbrange<0x%08lx,0x%08lx>]\n", start, end);
+#endif
+	local_irq_save(flags);
+	size = (end - start + (PAGE_SIZE - 1)) >> PAGE_SHIFT;
+	size = (size + 1) >> 1;
+	if (size <= CSKY_TLB_SIZE / 2) {
+		int idx;
+		unsigned int page;
+		int pid = read_mmu_entryhi();
+
+		start &= (PAGE_MASK << 1);
+		end += ((PAGE_SIZE << 1) - 1);
+		end &= (PAGE_MASK << 1);
+		for (idx = 0; idx < CSKY_TLB_SIZE; idx++) {
+			write_mmu_index(idx);
+			tlb_read();
+			page = read_mmu_entryhi();
+			page &=(PAGE_MASK << 1);
+			if (page >= start && page < end) {
+				write_mmu_entrylo0(0);
+				write_mmu_entrylo1(0);
+				write_mmu_entryhi(KSEG0 + idx * 0x2000);
+				tlb_write_indexed();
+			}
+		}
+		write_mmu_entryhi(pid);
+	}
+	else {
+		local_flush_tlb_all();
+	}
+	local_irq_restore(flags);
+}
+
+void local_flush_tlb_page(struct vm_area_struct *vma, unsigned long page)
+{
+	int cpu = smp_processor_id();
+
+	if (!vma || cpu_context(cpu, vma->vm_mm) != 0) {
+		unsigned long flags;
+		int oldpid, newpid, idx;
+
+#ifdef DEBUG_TLB
+		printk("[tlbpage<%d,%08lx>]", cpu_context(cpu, vma->vm_mm),
+		       page);
+#endif
+		newpid = cpu_asid(cpu, vma->vm_mm);
+		page &= (PAGE_MASK << 1);
+		local_irq_save(flags);
+		oldpid = read_mmu_entryhi();
+		write_mmu_entryhi(page | newpid);
+		tlb_probe();
+		idx = read_mmu_index();
+		write_mmu_entrylo0(0);
+		write_mmu_entrylo1(0);
+		if(idx < 0)
+		{
+			write_mmu_entryhi((page | newpid) + 1);
+			goto finish;
+		}
+		/* Make sure all entries differ. */
+		write_mmu_entryhi(KSEG0+idx*0x2000);
+		tlb_write_indexed();
+
+	finish:
+		write_mmu_entryhi(oldpid);
+		local_irq_restore(flags);
+	}
+}
+
+/*
+ * Remove one kernel space TLB entry.  This entry is assumed to be marked
+ * global so we don't do the ASID thing.
+ */
+void local_flush_tlb_one(unsigned long page)
+{
+	unsigned long flags;
+	int oldpid, idx;
+
+	page &= (PAGE_MASK << 1);
+	oldpid = read_mmu_entryhi();
+	local_irq_save(flags);
+	page = page | (oldpid & 0xff);
+	write_mmu_entryhi(page);
+	tlb_probe();
+	idx = read_mmu_index();
+	write_mmu_entrylo0(0);
+	write_mmu_entrylo1(0);
+	if (idx >= 0) {
+		/* Make sure all entries differ. */
+		write_mmu_entryhi(KSEG0+idx*0x2000);
+		tlb_write_indexed();
+	}
+	else
+		write_mmu_entryhi(page + 1);
+	write_mmu_entryhi(oldpid);
+	local_irq_restore(flags);
+}
+
+EXPORT_SYMBOL(local_flush_tlb_one);
+
+void __update_tlb(struct vm_area_struct * vma, unsigned long address, pte_t pte)
+{
+	unsigned long flags;
+	pgd_t *pgdp;
+	pud_t *pudp;
+	pmd_t *pmdp;
+	pte_t *ptep;
+	int idx, pid;
+
+	/*
+	 * Handle debugger faulting in for debugee.
+	 */
+	if (current->active_mm != vma->vm_mm)
+		return;
+
+	pid = read_mmu_entryhi() & ASID_MASK;
+
+	local_irq_save(flags);
+	address &= (PAGE_MASK << 1);
+	write_mmu_entryhi(address | pid);
+	pgdp = pgd_offset(vma->vm_mm, address);
+	tlb_probe();
+	pudp = pud_offset(pgdp, address);
+	pmdp = pmd_offset(pudp, address);
+	idx = read_mmu_index();
+	ptep = pte_offset(pmdp, address);
+
+	write_mmu_entrylo0(pte_val(*ptep++) >> 6);
+	write_mmu_entrylo1(pte_val(*ptep) >> 6);
+	write_mmu_entryhi(address | pid);
+	if (idx < 0) {
+		write_mmu_entryhi((address | pid) + 1);
+		write_mmu_entryhi(address | pid);
+		tlb_write_random();
+	} else {
+		tlb_write_indexed();
+	}
+	local_irq_restore(flags);
+}
+
+/* show current 32 jtlbs */
+void show_jtlb_table(void)
+{
+	unsigned long flags;
+	int entryhi, entrylo0, entrylo1;
+	int entry;
+	int oldpid;
+
+	local_irq_save(flags);
+	entry = 0;
+	printk("\n\n\n");
+
+	oldpid = read_mmu_entryhi();
+	while (entry < CSKY_TLB_SIZE)
+	{
+		write_mmu_index(entry);
+		tlb_read();
+		entryhi = read_mmu_entryhi();
+		entrylo0 = read_mmu_entrylo0();
+		entrylo0 = entrylo0 << 6;
+		entrylo1 = read_mmu_entrylo1();
+		entrylo1 = entrylo1 << 6;
+		printk("jtlb[%d]:	entryhi - 0x%x;	entrylo0 - 0x%x;"
+		       "	entrylo1 - 0x%x\n",
+			 entry, entryhi, entrylo0, entrylo1);
+		entry++;
+	}
+	write_mmu_entryhi(oldpid);
+	local_irq_restore(flags);
+}
+
+void __init csky_tlb_init(void)
+{
+	local_flush_tlb_all();
+}
diff --git a/arch/csky/abiv2/Makefile b/arch/csky/abiv2/Makefile
new file mode 100644
index 0000000..fc149d6
--- /dev/null
+++ b/arch/csky/abiv2/Makefile
@@ -0,0 +1,4 @@
+obj-y +=	src/misc.o
+obj-y +=	src/memcpy.o
+obj-y +=	src/tlb.o
+
diff --git a/arch/csky/abiv2/inc/abi/cacheflush.h b/arch/csky/abiv2/inc/abi/cacheflush.h
new file mode 100644
index 0000000..76a0a00
--- /dev/null
+++ b/arch/csky/abiv2/inc/abi/cacheflush.h
@@ -0,0 +1,7 @@
+#ifndef __ABI_CSKY_CACHEFLUSH_H
+#define __ABI_CSKY_CACHEFLUSH_H
+
+#include <asm-generic/cacheflush.h>
+
+#endif /* __ABI_CSKY_CACHEFLUSH_H */
+
diff --git a/arch/csky/abiv2/inc/abi/ckmmu.h b/arch/csky/abiv2/inc/abi/ckmmu.h
new file mode 100644
index 0000000..5f4fb73
--- /dev/null
+++ b/arch/csky/abiv2/inc/abi/ckmmu.h
@@ -0,0 +1,159 @@
+#ifndef __ASM_CSKY_CKMMUV2_H
+#define __ASM_CSKY_CKMMUV2_H
+
+#define CSKY_TLB_SIZE 128
+
+static inline void select_mmu_cp(void)
+{}
+
+static inline int  read_mmu_index(void)
+{
+	int __res;
+	__asm__ __volatile__("mfcr %0,cr<0, 15>\n\t"
+					:"=r" (__res));
+	return   __res;
+}
+
+static inline void  write_mmu_index(int value)
+{
+	__asm__ __volatile__("mtcr %0,cr<0, 15>\n\t"
+					: :"r" (value));
+}
+
+static inline int  read_mmu_entrylo0(void)
+{
+	int __res;
+	__asm__ __volatile__("mfcr %0,cr<2, 15>\n\t"
+					:"=r" (__res));
+	return   __res;
+}
+
+static inline void  write_mmu_entrylo0(int value)
+{
+	__asm__ __volatile__("mtcr %0,cr<2, 15>\n\t"
+					: :"r" (value));
+}
+
+static inline int  read_mmu_entrylo1(void)
+{
+	int __res;
+
+	__asm__ __volatile__("mfcr %0,cr<3, 15>\n\t"
+					:"=r" (__res));
+	return   __res;
+}
+
+static inline void  write_mmu_entrylo1(int value)
+{
+	__asm__ __volatile__("mtcr %0,cr<3, 15>\n\t"
+					: :"r" (value));
+}
+
+static inline int  read_mmu_pagemask(void)
+{
+	int __res;
+
+	__asm__ __volatile__("mfcr %0,cr<6, 15>\n\t"
+					:"=r" (__res));
+	return   __res;
+}
+
+static inline void  write_mmu_pagemask(int value)
+{
+	__asm__ __volatile__("mtcr %0,cr<6, 15>\n\t"
+					: :"r" (value));
+}
+
+static inline int  read_mmu_entryhi(void)
+{
+	int __res;
+
+	__asm__ __volatile__("mfcr %0,cr<4, 15>\n\t"
+					:"=r" (__res));
+	return   __res;
+}
+
+static inline void  write_mmu_entryhi(int value)
+{
+	__asm__ __volatile__("mtcr %0,cr<4, 15>\n\t"
+					: :"r" (value));
+}
+
+/*
+ * TLB operations.
+ */
+static inline void tlb_probe(void)
+{
+	int value = 0x80000000;
+
+	__asm__ __volatile__("mtcr %0,cr<8, 15>\n\t"
+					: :"r" (value));
+}
+
+static inline void tlb_read(void)
+{
+	int value = 0x40000000;
+
+	__asm__ __volatile__("mtcr %0,cr<8, 15>\n\t"
+					: :"r" (value));
+}
+
+static inline void tlb_write_indexed(void)
+{
+	int value = 0x20000000;
+
+	__asm__ __volatile__("mtcr %0,cr<8,15>\n\t"
+					: :"r" (value));
+}
+
+static inline void tlb_write_random(void)
+{
+	int value = 0x10000000;
+
+	__asm__ __volatile__("mtcr %0,cr<8, 15>\n\t"
+					: :"r" (value));
+}
+
+static inline void tlb_invalid_all(void)
+{
+	int value = 0x04000000;
+
+	__asm__ __volatile__("mtcr %0,cr<8, 15>\n\t"
+					: :"r" (value));
+}
+
+static inline void tlb_invalid_indexed(void)
+{
+	int value = 0x02000000;
+
+	__asm__ __volatile__("mtcr %0,cr<8, 15>\n\t"
+					: :"r" (value));
+}
+
+/* misc */
+static inline void tlbmiss_handler_setup_pgd(unsigned long pgd)
+{
+	__asm__ __volatile__(
+		"bseti %0, 0		\n\t"
+		"bclri %0, 31		\n\t"
+		"addu  %0, %1		\n\t"
+		"mtcr  %0, cr<29, 15>	\n\t"
+		::"r"(pgd), "r"(PHYS_OFFSET)
+		:);
+}
+
+static inline unsigned long tlb_get_pgd(void)
+{
+	unsigned long pgd;
+	__asm__ __volatile__(
+		"mfcr %0, cr<29, 15>	\n\r"
+		"bclri	%0, 0		\n\r"
+		"subu	%0, %1		\n\r"
+                "bseti	%0, 31		\n\r"
+                :"=&r"(pgd)
+		:"r"(PHYS_OFFSET)
+                :);
+	return pgd;
+}
+#endif /* __ASM_CSKY_CKMMUV2_H */
+
diff --git a/arch/csky/abiv2/inc/abi/entry.h b/arch/csky/abiv2/inc/abi/entry.h
new file mode 100644
index 0000000..8dba5d8
--- /dev/null
+++ b/arch/csky/abiv2/inc/abi/entry.h
@@ -0,0 +1,247 @@
+#ifndef __ASM_CSKY_ENTRY_H
+#define __ASM_CSKY_ENTRY_H
+
+#include <asm/setup.h>
+#include <abi/regdef.h>
+
+/*
+ * Stack layout in 'ret_from_exception':
+ *      Below describes the stack layout after initial exception entry.
+ *      All traps, interrupts and exceptions will set up the stack frame
+ *      in this way before starting processing proper.
+ *	This allows access to the syscall arguments in registers r1-r5
+ *
+ *	 0(sp) - pc
+ *	 4(sp) - orig_a0
+ *	 8(sp) - sr
+ *	 C(sp) - a0
+ *	10(sp) - a1
+ *	14(sp) - a2
+ *	18(sp) - a3
+ *	1C(sp) - regs0
+ *	20(sp) - regs1
+ *	24(sp) - regs2
+ *	28(sp) - regs3
+ *	2C(sp) - regs4
+ *	30(sp) - regs5
+ *	34(sp) - regs6
+ *	38(sp) - regs7
+ *	3C(sp) - regs8
+ *	40(sp) - regs9
+ *	44(sp) - r15
+ */
+#define LSAVE_A0       0xc
+#define LSAVE_A1       0x10
+#define LSAVE_A2       0x14
+#define LSAVE_A3       0x18
+#define LSAVE_REGS0    0x1C
+#define LSAVE_REGS1    0x20
+
+/*
+ *      This code creates the normal kernel pt_regs layout on a trap
+ *      or interrupt. The only trick here is that we check whether we
+ *      came from supervisor mode before changing stack pointers.
+ */
+
+.macro	SAVE_ALL
+	subi    sp,  144
+        stw     a0, (sp, 4)
+        stw     a0, (sp, 12)
+        stw     a1, (sp, 16)
+        stw     a2, (sp, 20)
+        stw     a3, (sp, 24)
+        stw     regs0, (sp, 28)
+        stw     regs1, (sp, 32)
+        stw     regs2, (sp, 36)
+        stw     regs3, (sp, 40)
+        stw     regs4, (sp, 44)
+        stw     regs5, (sp, 48)
+        stw     regs6, (sp, 52)
+        stw     regs7, (sp, 56)
+        stw     regs8, (sp, 60)
+        stw     regs9, (sp, 64)
+        stw     r15, (sp, 68)
+        addi    sp, 72
+        stm     r16-r31,(sp)
+        mfhi    r22
+        mflo    r23
+	stw     r22, (sp, 64)
+        stw     r23, (sp, 68)
+        subi    sp,  72
+
+	mfcr    r22, epsr        /* Get original PSR */
+        stw     r22, (sp, 8)     /* Save psr on stack */
+        mfcr    r22, epc/* Save PC on stack */
+        stw     r22, (sp)
+.endm
+
+.macro	RESTORE_ALL
+        psrclr  ie     /* Disable interrupt */
+	ldw     a0, (sp)        /* Restore PC */
+        mtcr    a0, epc/* Set return PC */
+        ldw     a0, (sp, 8)     /* Get saved PSR */
+        mtcr    a0, epsr        /* Restore PSR */
+	addi    sp, 12
+	ldw     a0, (sp, 124)
+        ldw     a1, (sp, 128)
+	mthi    a0
+        mtlo    a1
+
+	ldw     a0, (sp, 0)
+        ldw     a1, (sp, 4)
+        ldw     a2, (sp, 8)
+        ldw     a3, (sp, 12)
+        ldw     regs0, (sp, 16)
+        ldw     regs1, (sp, 20)
+        ldw     regs2, (sp, 24)
+	ldw     regs3, (sp, 28)
+        ldw     regs4, (sp, 32)
+        ldw     regs5, (sp, 36)
+        ldw     regs6, (sp, 40)
+        ldw     regs7, (sp, 44)
+        ldw     regs8, (sp, 48)
+        ldw     regs9, (sp, 52)
+        ldw     r15, (sp, 56)
+        addi    sp, 60 /* Increment stack pointer */
+        ldm     r16-r31,(sp)
+        addi    sp,  72
+1:
+        rte
+.endm
+
+#define SAVE_SWITCH_STACK save_switch_stack
+#define RESTORE_SWITCH_STACK restore_switch_stack
+#define GET_CURRENT(tmp)
+
+.macro	save_switch_stack
+        subi    sp, 64
+        stm     r4-r11,(sp)
+        stw     r15, (sp, 32)
+        stw     r16, (sp, 36)
+        stw     r17, (sp, 40)
+        stw     r26, (sp, 44)
+        stw     r27, (sp, 48)
+        stw     r28, (sp, 52)
+        stw     r29, (sp, 56)
+        stw     r30, (sp, 60)
+.endm
+
+.macro	restore_switch_stack
+        ldm     r4-r11,(sp)
+        ldw     r15, (sp, 32)
+        ldw     r16, (sp, 36)
+        ldw     r17, (sp, 40)
+        ldw     r26, (sp, 44)
+        ldw     r27, (sp, 48)
+        ldw     r28, (sp, 52)
+        ldw     r29, (sp, 56)
+        ldw     r30, (sp, 60)
+        addi    sp, 64
+.endm
+
+.macro  PT_REGS_ADJUST  rx   /* abiv2 when argc>5 need push r4 r5 in syscall */
+        addi     \rx, sp, 8
+.endm
+/*
+ * Because kernel don't use FPU and only user program use FPU, we select
+ * coprocessor 15(MMU) when in super-mode. So this macro is called when
+ * CPU enter from user-mode to kernel super-mode except MMU exception.
+ */
+.macro SET_SMOD_MMU_CP15
+.endm
+
+/*
+ * Below, are macros for MMU operating, use them to switch cop, read or write
+ * registers of MMU in assemble files. Macro __CSKYABIV1__ means MMU in
+ * coprocessor.
+ */
+/* Coprocessor switch to MMU */
+.macro SET_CP_MMU
+.endm
+
+/* MMU registers read operators. */
+.macro RD_MIR	rx
+	mfcr    \rx, cr<0, 15>
+.endm
+
+.macro RD_MRR	rx
+	mfcr    \rx, cr<1, 15>
+.endm
+
+.macro RD_MEL0	rx
+	mfcr    \rx, cr<2, 15>
+.endm
+
+.macro RD_MEL1	rx
+	mfcr    \rx, cr<3, 15>
+.endm
+
+.macro RD_MEH	rx
+	mfcr    \rx, cr<4, 15>
+.endm
+
+.macro RD_MCR	rx
+	mfcr    \rx, cr<5, 15>
+.endm
+
+.macro RD_MPR	rx
+	mfcr    \rx, cr<6, 15>
+.endm
+
+.macro RD_MWR	rx
+	mfcr    \rx, cr<7, 15>
+.endm
+
+.macro RD_MCIR	rx
+	mfcr    \rx, cr<8, 15>
+.endm
+
+.macro RD_PGDR  rx
+        mfcr    \rx, cr<29, 15>
+.endm
+
+/* MMU registers write operators. */
+.macro WR_MIR	rx
+	mtcr    \rx, cr<0, 15>
+.endm
+
+.macro WR_MRR	rx
+	mtcr    \rx, cr<1, 15>
+.endm
+
+.macro WR_MEL0	rx
+	mtcr    \rx, cr<2, 15>
+.endm
+.macro WR_MEL1	rx
+	mtcr    \rx, cr<3, 15>
+.endm
+
+.macro WR_MEH	rx
+	mtcr    \rx, cr<4, 15>
+.endm
+
+.macro WR_MCR	rx
+	mtcr    \rx, cr<5, 15>
+.endm
+
+.macro WR_MPR	rx
+	mtcr    \rx, cr<6, 15>
+.endm
+
+.macro WR_MWR	rx
+	mtcr    \rx, cr<7, 15>
+.endm
+
+.macro WR_MCIR	rx
+	mtcr    \rx, cr<8, 15>
+.endm
+
+.macro WR_MSA0	rx
+	mtcr    \rx, cr<30, 15>
+.endm
+
+.macro WR_MSA1	rx
+	mtcr    \rx, cr<31, 15>
+.endm
+
+#endif /* __ASM_CSKY_ENTRY_H */
diff --git a/arch/csky/abiv2/inc/abi/page.h b/arch/csky/abiv2/inc/abi/page.h
new file mode 100644
index 0000000..db4fafa
--- /dev/null
+++ b/arch/csky/abiv2/inc/abi/page.h
@@ -0,0 +1,18 @@
+static inline unsigned long pages_do_alias(unsigned long addr1,
+					   unsigned long addr2)
+{
+	return 0;
+}
+
+static inline void clear_user_page(void *addr, unsigned long vaddr,
+				   struct page *page)
+{
+	clear_page(addr);
+}
+
+static inline void copy_user_page(void *to, void *from, unsigned long vaddr,
+				  struct page *page)
+{
+	copy_page(to, from);
+}
+
diff --git a/arch/csky/abiv2/inc/abi/pgtable-bits.h b/arch/csky/abiv2/inc/abi/pgtable-bits.h
new file mode 100644
index 0000000..47db2f5
--- /dev/null
+++ b/arch/csky/abiv2/inc/abi/pgtable-bits.h
@@ -0,0 +1,25 @@
+#ifndef __ASM_CSKY_PGTABLE_BITS_H
+#define __ASM_CSKY_PGTABLE_BITS_H
+
+#define _PAGE_ACCESSED              (1<<7)  /* implemented in software */
+#define _PAGE_READ                  (1<<8)  /* implemented in software */
+#define _PAGE_WRITE                 (1<<9)  /* implemented in software */
+#define _PAGE_PRESENT               (1<<10)  /* implemented in software */
+#define _PAGE_MODIFIED              (1<<11)  /* implemented in software */
+#define _PAGE_FILE                  (1<<11)  /* set:pagecache unset:swap */
+#define _PAGE_GLOBAL                (1<<0)
+#define _PAGE_VALID                 (1<<1)
+#define _PAGE_SILENT_READ           (1<<1)  /* synonym                 */
+#define _PAGE_DIRTY                 (1<<2)  /* The CSKY dirty bit      */
+#define _PAGE_SILENT_WRITE          (1<<2)
+#define _CACHE_MASK                 (7<<3)
+
+#define _CACHE_UNCACHED             (0x22)
+#define _CACHE_CACHED               (0xa)
+
+#define pte_to_pgoff(_pte) \
+	(((_pte).pte_low & 0x3ff) | (((_pte).pte_low >> 12) << 10))
+#define pgoff_to_pte(off) \
+	((pte_t) {((off) & 0x3ff) | (((off) >> 10) << 12) | _PAGE_FILE})
+
+#endif /* __ASM_CSKY_PGTABLE_BITS_H */
diff --git a/arch/csky/abiv2/inc/abi/reg_ops.h b/arch/csky/abiv2/inc/abi/reg_ops.h
new file mode 100644
index 0000000..443f19c
--- /dev/null
+++ b/arch/csky/abiv2/inc/abi/reg_ops.h
@@ -0,0 +1,83 @@
+#ifndef __ASM_REG_OPS_H
+#define __ASM_REG_OPS_H
+
+static inline unsigned int mfcr_cpuidrr(void)
+{
+	unsigned int ret;
+	__asm__ __volatile__(
+		"mfcr %0, cr13\t\n"
+		:"=r"(ret));
+	return ret;
+}
+
+static inline unsigned int mfcr_hint(void)
+{
+	unsigned int ret;
+	__asm__ __volatile__(
+		"mfcr %0, cr31\t\n"
+		:"=r"(ret));
+	return ret;
+}
+
+static inline unsigned int mfcr_ccr(void)
+{
+	unsigned int ret;
+	__asm__ __volatile__(
+		"mfcr %0, cr18\t\n"
+		:"=r"(ret));
+	return ret;
+}
+
+static inline unsigned int mfcr_ccr2(void)
+{
+	unsigned int ret;
+	__asm__ __volatile__(
+		"mfcr %0, cr23\t\n"
+		:"=r"(ret));
+	return ret;
+}
+
+static inline unsigned int mfcr_msa0(void)
+{
+	unsigned int ret;
+	__asm__ __volatile__(
+		"mfcr %0, cr<30, 15>\t\n"
+		:"=r"(ret));
+	return ret;
+}
+
+static inline void mtcr_msa0(unsigned int value)
+{
+	__asm__ __volatile__(
+		"mtcr %0, cr<30, 15>\t\n"
+		::"r"(value));
+}
+
+static inline unsigned int mfcr_msa1(void)
+{
+	unsigned int ret;
+	__asm__ __volatile__(
+		"mfcr %0, cr<31, 15>\t\n"
+		:"=r"(ret));
+	return ret;
+}
+
+static inline void mtcr_msa1(unsigned int value)
+{
+	__asm__ __volatile__(
+		"mtcr %0, cr<31, 15>\t\n"
+		::"r"(value));
+}
+
+#define L1_SYNC do{__asm__ __volatile__("sync 1\t\n");}while(0)
+
+#ifdef CONFIG_CPU_CK807
+#define CSKYCPU_DEF_NAME "csky,ck807"
+#endif
+
+#ifdef CONFIG_CPU_CK810
+#define CSKYCPU_DEF_NAME "csky,ck810"
+#endif
+
+#endif /* __ASM_REG_OPS_H */
+
diff --git a/arch/csky/abiv2/inc/abi/regdef.h b/arch/csky/abiv2/inc/abi/regdef.h
new file mode 100644
index 0000000..93f8076
--- /dev/null
+++ b/arch/csky/abiv2/inc/abi/regdef.h
@@ -0,0 +1,23 @@
+#ifndef  __ASM_CSKY_REGDEF_H
+#define  __ASM_CSKY_REGDEF_H
+
+#define syscallid	r7
+#define regs0		r4
+#define regs1		r5
+#define regs2		r6
+#define regs3		r7
+#define regs4		r8
+#define regs5		r9
+#define regs6		r10
+#define regs7		r11
+#define regs8		r12
+#define regs9		r13
+
+/*
+ * use as judge restart syscall, see entry.S
+ */
+#define r11_sig		r11
+
+#define DEFAULT_PSR_VALUE	0x8f000200
+
+#endif /* __ASM_CSKY_REGDEF_H */
diff --git a/arch/csky/abiv2/src/memcpy.c b/arch/csky/abiv2/src/memcpy.c
new file mode 100644
index 0000000..170c39e
--- /dev/null
+++ b/arch/csky/abiv2/src/memcpy.c
@@ -0,0 +1,41 @@
+#include <linux/types.h>
+
+/*
+ * memory copy function.
+ */
+void *memcpy (void *to, const void *from, size_t l)
+{
+	char *d = to;
+	const char *s = from;
+
+	if (((long)d | (long)s) & 0x3)
+	{
+		while (l--) *d++ = *s++;
+	}
+	else
+	{
+        	while (l >= 16)
+		{
+			*(((long *)d)) = *(((long *)s));
+			*(((long *)d)+1) = *(((long *)s)+1);
+			*(((long *)d)+2) = *(((long *)s)+2);
+			*(((long *)d)+3) = *(((long *)s)+3);
+			l -= 16;
+			d += 16;
+			s += 16;
+		}
+		while (l > 3)
+		{
+			*(((long *)d)) = *(((long *)s));
+			d = d +4;
+			s = s +4;
+			l -= 4;
+		}
+		while (l)
+		{
+			*d++ = *s++;
+			l--;	
+		}
+	}
+	return to;
+}
diff --git a/arch/csky/abiv2/src/misc.c b/arch/csky/abiv2/src/misc.c
new file mode 100644
index 0000000..d470409
--- /dev/null
+++ b/arch/csky/abiv2/src/misc.c
@@ -0,0 +1,114 @@
+#include <asm/ptrace.h>
+#include <linux/kernel.h>
+#include <linux/sched.h>
+
+unsigned long os_config_fcr;
+
+inline unsigned int
+read_pt_regs(unsigned int rx, struct pt_regs *regs)
+{
+	unsigned int value;
+
+	if(rx < 14){
+		value  = *((int *)regs + rx + 3);
+	}else if(rx == 14){
+		if(user_mode(regs)){
+			__asm__ __volatile__("mfcr %0, cr<14, 1> \n\r"
+						:"=r"(value));
+		}else{
+			value = sizeof(struct pt_regs) + ((unsigned int)regs);
+		}
+	}else{
+		value = *((int *)regs + rx + 2);
+	}
+
+	return value;
+}
+
+inline void
+write_pt_regs(unsigned int value, unsigned int rx, struct pt_regs *regs)
+{
+	if(rx < 14){
+		*((int *)regs + rx + 3) = value;
+	}else if(rx == 14){
+		if(user_mode(regs)){
+			__asm__ __volatile__("mtcr %0, cr<14, 1> \n\r"
+						::"r"(value));
+		}else{
+			printk("math emulate trying to write sp.\n");
+		}
+	}else{
+		*((int *)regs + rx + 2) = value;
+	}
+}
+
+#ifdef CONFIG_CPU_HAS_FPU
+void __init init_fpu(void)
+{
+	unsigned long fcr;
+
+	os_config_fcr = (IDE_STAT | IXE_STAT | UFE_STAT |
+			 OFE_STAT | DZE_STAT | IOE_STAT);
+
+	fcr = os_config_fcr;
+	__asm__ __volatile__(
+			"mtcr	%0, cr<1, 2> \n\t"
+			::"r"(fcr)
+			);
+}
+
+inline unsigned int read_fpcr(void)
+{
+	unsigned int result = 0;
+	__asm__ __volatile__("mfcr %0, cr<1, 2>\n"
+				:"=r"(result));
+	return result;
+}
+
+inline void write_fpcr(unsigned int val)
+{
+	unsigned int result = val | os_config_fcr;
+	__asm__ __volatile__("mtcr %0, cr<1, 2>\n"
+				::"r"(result));
+}
+
+inline unsigned int read_fpesr(void)
+{
+	unsigned int result = 0;
+	__asm__ __volatile__("mfcr %0, cr<2, 2>\n"
+				:"=r"(result));
+	return result;
+}
+
+inline void write_fpesr(unsigned int val)
+{
+	unsigned int result = val;
+	__asm__ __volatile__("mtcr %0, cr<2, 2>\n"
+				::"r"(result));
+}
+
+#else /* CONFIG_CPU_HAS_FPU */
+void __init init_fpu(void) {}
+
+inline unsigned int read_fpcr(void)
+{
+	return current->thread.fcr;
+}
+
+inline void write_fpcr(unsigned int val)
+{
+	val |= os_config_fcr;
+	current->thread.fcr = val;
+}
+
+inline unsigned int read_fpesr(void)
+{
+	return current->thread.fesr;
+}
+
+inline void write_fpesr(unsigned int val)
+{
+	current->thread.fesr = val;
+}
+
+#endif /* CONFIG_CPU_HAS_FPU */
diff --git a/arch/csky/abiv2/src/tlb.c b/arch/csky/abiv2/src/tlb.c
new file mode 100644
index 0000000..e84efb9
--- /dev/null
+++ b/arch/csky/abiv2/src/tlb.c
@@ -0,0 +1,265 @@
+#include <linux/init.h>
+#include <linux/sched.h>
+#include <linux/mm.h>
+
+#include <asm/setup.h>
+#include <asm/mmu_context.h>
+#include <linux/module.h>
+#include <asm/pgtable.h>
+#include <abi/ckmmu.h>
+
+#undef DEBUG_TLB
+#undef DEBUG_TLBUPDATE
+
+#define ENTER_CRITICAL(flags) local_irq_save(flags)
+#define EXIT_CRITICAL(flags) local_irq_restore(flags)
+
+void local_flush_tlb_all(void)
+{
+	unsigned long flags;
+
+	local_irq_save(flags);
+	tlb_invalid_all();
+	local_irq_restore(flags);
+}
+
+void local_flush_tlb_mm(struct mm_struct *mm)
+{
+	int cpu = smp_processor_id();
+
+	if (cpu_context(cpu, mm) != 0) {
+#ifdef DEBUG_TLB
+		printk("[tlbmm<%d>]", cpu_context(cpu, mm));
+#endif
+		drop_mmu_context(mm,cpu);
+	}
+}
+
+void local_flush_tlb_range(struct vm_area_struct *vma, unsigned long start,
+        unsigned long end)
+{
+        struct mm_struct *mm = vma->vm_mm;
+        int cpu = smp_processor_id();
+
+        if (cpu_context(cpu, mm) != 0) {
+                unsigned long size, flags;
+
+                local_irq_save(flags);
+                size = (end - start + (PAGE_SIZE - 1)) >> PAGE_SHIFT;
+                size = (size + 1) >> 1;
+                if (size <= CSKY_TLB_SIZE/2) {
+                        int oldpid = read_mmu_entryhi();
+                        int newpid = cpu_asid(cpu, mm);
+
+                        start &= (PAGE_MASK << 1);
+                        end += ((PAGE_SIZE << 1) - 1);
+                        end &= (PAGE_MASK << 1);
+                        while (start < end) {
+                                int idx;
+
+                                write_mmu_entryhi(start | newpid);
+                                start += (PAGE_SIZE << 1);
+                                tlb_probe();
+                                idx = read_mmu_index();
+                                write_mmu_entrylo0(0);
+                                write_mmu_entrylo1(0);
+                                if (idx < 0)
+				{
+					tlb_invalid_indexed();
+                                        continue;
+				}
+                                /* Make sure all entries differ. */
+                                write_mmu_entryhi(KSEG0 + idx*0x2000);
+                                tlb_write_indexed();
+                        }
+                        write_mmu_entryhi(oldpid);
+                } else {
+                        drop_mmu_context(mm, cpu);
+                }
+                local_irq_restore(flags);
+        }
+}
+
+void local_flush_tlb_kernel_range(unsigned long start, unsigned long end)
+{
+        unsigned long size, flags;
+
+#ifdef DEBUG_TLB
+        printk("[tlbrange<%lu,0x%08lx,0x%08lx>]", start, end);
+#endif
+        local_irq_save(flags);
+        size = (end - start + (PAGE_SIZE - 1)) >> PAGE_SHIFT;
+        if (size <= CSKY_TLB_SIZE) {
+                int pid = read_mmu_entryhi();
+
+                start &= PAGE_MASK;
+                end += PAGE_SIZE - 1;
+                end &= PAGE_MASK;
+
+                while (start < end) {
+                        int idx;
+                        write_mmu_entryhi(start);
+                        start += PAGE_SIZE;             /* BARRIER */
+                        tlb_probe();
+                        idx = read_mmu_index();
+                        write_mmu_entrylo0(0);
+                        write_mmu_entrylo1(0);
+                        if (idx < 0)                    /* BARRIER */
+                        {
+                                tlb_invalid_indexed();
+                                continue;
+                        }
+                        write_mmu_entryhi(KSEG0 + idx*0x2000);
+                        tlb_write_indexed();
+                }
+                write_mmu_entryhi(pid);
+        } else {
+                local_flush_tlb_all();
+        }
+        local_irq_restore(flags);
+}
+
+
+void local_flush_tlb_page(struct vm_area_struct *vma, unsigned long page)
+{
+	int cpu = smp_processor_id();
+
+	if (!vma || cpu_context(cpu, vma->vm_mm) != 0) {
+		unsigned long flags;
+		int oldpid, newpid, idx;
+
+#ifdef DEBUG_TLB
+		printk("[tlbpage<%d,%08lx>]", cpu_context(cpu, vma->vm_mm),
+		       page);
+#endif
+		newpid = cpu_asid(cpu, vma->vm_mm);
+		page &= (PAGE_MASK << 1);
+		local_irq_save(flags);
+		oldpid = read_mmu_entryhi();
+		write_mmu_entryhi(page | newpid);
+		tlb_probe();
+		idx = read_mmu_index();
+		write_mmu_entrylo0(0);
+		write_mmu_entrylo1(0);
+		if(idx < 0)
+		{
+			tlb_invalid_indexed();
+			goto finish;
+		}
+		/* Make sure all entries differ. */
+		write_mmu_entryhi(KSEG0+idx*0x2000);
+		tlb_write_indexed();
+
+	finish:
+		write_mmu_entryhi(oldpid);
+		local_irq_restore(flags);
+	}
+}
+
+/*
+ * Remove one kernel space TLB entry.  This entry is assumed to be marked
+ * global so we don't do the ASID thing.
+ */
+void local_flush_tlb_one(unsigned long page)
+{
+	unsigned long flags;
+	int oldpid, idx;
+
+	page &= (PAGE_MASK << 1);
+	oldpid = read_mmu_entryhi();
+
+	local_irq_save(flags);
+	page = page | (oldpid & 0xff);
+	write_mmu_entryhi(page);
+	tlb_probe();
+	idx = read_mmu_index();
+	write_mmu_entrylo0(0);
+	write_mmu_entrylo1(0);
+	if (idx >= 0) {
+		/* Make sure all entries differ. */
+		write_mmu_entryhi(KSEG0+idx*0x2000);
+		tlb_write_indexed();
+	}
+	else
+		tlb_invalid_indexed();
+
+	write_mmu_entryhi(oldpid);
+	local_irq_restore(flags);
+}
+
+EXPORT_SYMBOL(local_flush_tlb_one);
+
+void __update_tlb(struct vm_area_struct * vma, unsigned long address, pte_t pte)
+{
+	unsigned long flags;
+	pgd_t *pgdp;
+	pud_t *pudp;
+	pmd_t *pmdp;
+	pte_t *ptep;
+	int idx, pid;
+
+	/*
+	 * Handle debugger faulting in for debugee.
+	 */
+	if (current->active_mm != vma->vm_mm)
+		return;
+
+	pid = read_mmu_entryhi() & ASID_MASK;
+
+	local_irq_save(flags);
+	address &= (PAGE_MASK << 1);
+	write_mmu_entryhi(address | pid);
+	pgdp = pgd_offset(vma->vm_mm, address);
+	tlb_probe();
+	pudp = pud_offset(pgdp, address);
+	pmdp = pmd_offset(pudp, address);
+	idx = read_mmu_index();
+	ptep = pte_offset(pmdp, address);
+
+	write_mmu_entrylo0(pte_val(*ptep++));
+	write_mmu_entrylo1(pte_val(*ptep));
+	write_mmu_entryhi(address | pid);
+	if (idx < 0) {
+		tlb_invalid_indexed();
+		tlb_write_random();
+	} else {
+		tlb_write_indexed();
+	}
+	local_irq_restore(flags);
+}
+
+/* show current 32 jtlbs */
+void show_jtlb_table(void)
+{
+	unsigned long flags;
+	int entryhi, entrylo0, entrylo1;
+	int entry;
+	 int oldpid;
+
+	local_irq_save(flags);
+	entry = 0;
+	printk("\n\n\n");
+
+	oldpid = read_mmu_entryhi();
+	while (entry < CSKY_TLB_SIZE)
+	{
+		write_mmu_index(entry);
+		tlb_read();
+		entryhi = read_mmu_entryhi();
+		entrylo0 = read_mmu_entrylo0();
+		entrylo0 = entrylo0;
+		entrylo1 = read_mmu_entrylo1();
+		entrylo1 = entrylo1;
+		printk("jtlb[%d]:	entryhi - 0x%x;	entrylo0 - 0x%x;"
+		       "	entrylo1 - 0x%x\n",
+			 entry, entryhi, entrylo0, entrylo1);
+		entry++;
+	}
+	write_mmu_entryhi(oldpid);
+	local_irq_restore(flags);
+}
+
+void __init csky_tlb_init(void)
+{
+	local_flush_tlb_all();
+}
diff --git a/arch/csky/boot/Makefile b/arch/csky/boot/Makefile
new file mode 100644
index 0000000..c3301a8
--- /dev/null
+++ b/arch/csky/boot/Makefile
@@ -0,0 +1,25 @@
+targets := Image zImage uImage
+targets += $(dtb-y)
+
+$(obj)/Image: vmlinux FORCE
+	$(call if_changed,objcopy)
+	@echo '  Kernel: $@ is ready'
+
+compress-$(CONFIG_KERNEL_GZIP) = gzip
+compress-$(CONFIG_KERNEL_LZO)  = lzo
+compress-$(CONFIG_KERNEL_LZMA) = lzma
+compress-$(CONFIG_KERNEL_XZ)   = xzkern
+compress-$(CONFIG_KERNEL_LZ4)  = lz4
+
+$(obj)/zImage:  $(obj)/Image FORCE
+	$(call if_changed,$(compress-y))
+	@echo '  Kernel: $@ is ready'
+
+UIMAGE_ARCH		= sandbox
+UIMAGE_COMPRESSION	= $(compress-y)
+UIMAGE_LOADADDR		= $(shell $(NM) vmlinux | awk '$$NF == "_start" {print $$1}')
+
+$(obj)/uImage: $(obj)/zImage
+	$(call if_changed,uimage)
+	@echo 'Image: $@ is ready'
+
diff --git a/arch/csky/boot/dts/Makefile b/arch/csky/boot/dts/Makefile
new file mode 100644
index 0000000..9afc954
--- /dev/null
+++ b/arch/csky/boot/dts/Makefile
@@ -0,0 +1,14 @@
+dtstree	:= $(srctree)/$(src)
+
+ifdef CONFIG_CSKY_BUILTIN_DTB
+builtindtb-y := $(patsubst "%",%,$(CONFIG_CSKY_BUILTIN_DTB_NAME))
+dtb-y += $(builtindtb-y).dtb
+obj-y += $(builtindtb-y).dtb.o
+.SECONDARY: $(obj)/$(builtindtb-y).dtb.S
+else
+dtb-y := $(patsubst $(dtstree)/%.dts,%.dtb, $(wildcard $(dtstree)/*.dts))
+endif
+
+always += $(dtb-y)
+clean-files += *.dtb *.dtb.S
+
diff --git a/arch/csky/boot/dts/gx6605s.dts b/arch/csky/boot/dts/gx6605s.dts
new file mode 100644
index 0000000..ce56106
--- /dev/null
+++ b/arch/csky/boot/dts/gx6605s.dts
@@ -0,0 +1,160 @@
+/dts-v1/;
+#include <dt-bindings/gpio/gpio.h>
+#include <dt-bindings/input/input.h>
+
+/ {
+	model = "Nationalchip csky gx6605s";
+	compatible = "csky,nationalchip-gx6605s";
+	#address-cells = <1>;
+	#size-cells = <1>;
+
+	memory {
+		device_type = "memory";
+		reg = <0x10000000 0x04000000>;
+	};
+
+	cpus {
+		#address-cells = <0>;
+		#size-cells = <0>;
+
+		cpu {
+			compatible = "csky,ck610";
+			device_type = "cpu";
+			ccr	= <0x7d>;
+			hint	= <0x1c>;
+		};
+	};
+
+	soc {
+		#address-cells = <1>;
+		#size-cells = <1>;
+		compatible = "simple-bus";
+		ranges;
+
+		intc: interrupt-controller {
+			compatible = "nationalchip,intc-v1,ave";
+			reg = <0x00500000 0x400>;
+			interrupt-controller;
+			#interrupt-cells = <1>;
+		};
+
+		timer0 {
+			compatible = "nationalchip,timer-v1";
+			reg = <0x0020a000 0x400>;
+			clock-frequency = <1000000>;
+			interrupts = <10>;
+			interrupt-parent = <&intc>;
+		};
+
+		ehci: ehci-hcd {
+			compatible = "generic-ehci";
+			reg = <0x00900000 0x400>;
+			interrupt-parent = <&intc>;
+			interrupts = <59>;
+		};
+
+		ohci0: ohci-hcd0 {
+			compatible = "generic-ohci";
+			reg = <0x00a00000 0x400>;
+			interrupt-parent = <&intc>;
+			interrupts = <58>;
+		};
+
+		ohci1: ohci-hcd1 {
+			compatible = "generic-ohci";
+			reg = <0x00b00000 0x400>;
+			interrupt-parent = <&intc>;
+			interrupts = <57>;
+		};
+
+		uart0: serial {
+			compatible = "ns16550a";
+			reg = <0x00403000 0x400>;
+			interrupt-parent = <&intc>;
+			interrupts = <15>;
+			clock-frequency = <29491200>;
+			baud = <115200>;
+			reg-shift = <2>;
+			reg-io-width = <1>;
+		};
+
+		gpio0: gpio {
+			compatible = "wd,mbl-gpio";
+			reg-names = "dirout", "dat", "set", "clr";
+			reg = <0x305000 4>, <0x305004 4>, <0x305008 4>, <0x30500c 4>;
+			bgpio-base = <0>;
+			#gpio-cells = <2>;
+			gpio-controller;
+		};
+
+		gpio_buttons {
+			compatible = "gpio-keys-polled";
+			#address-cells = <1>;
+			#size-cells = <0>;
+			poll-interval = <100>;
+			autorepeat;
+
+			button0 {
+				label = "button8";
+				linux,code = <KEY_LEFT>;
+				gpios = <&gpio0 8 GPIO_ACTIVE_LOW>;
+			};
+
+			button1 {
+				label = "button6";
+				linux,code = <KEY_RIGHT>;
+				gpios = <&gpio0 6 GPIO_ACTIVE_LOW>;
+			};
+
+			button2 {
+				label = "button5";
+				linux,code = <KEY_UP>;
+				gpios = <&gpio0 5 GPIO_ACTIVE_LOW>;
+			};
+
+			button3 {
+				label = "button9";
+				linux,code = <KEY_DOWN>;
+				gpios = <&gpio0 9 GPIO_ACTIVE_LOW>;
+			};
+
+			button4 {
+				label = "button7";
+				linux,code = <KEY_ENTER>;
+				gpios = <&gpio0 7 GPIO_ACTIVE_LOW>;
+			};
+		};
+
+		gpio_leds {
+			compatible = "gpio-leds";
+
+			led0 {
+				label = "led10";
+				gpios = <&gpio0 10 GPIO_ACTIVE_LOW>;
+				linux,default-trigger = "heartbeat";
+			};
+
+			led1 {
+				label = "led11";
+				gpios = <&gpio0 11 GPIO_ACTIVE_LOW>;
+				linux,default-trigger = "timer";
+			};
+
+			led2 {
+				label = "led12";
+				gpios = <&gpio0 12 GPIO_ACTIVE_LOW>;
+				linux,default-trigger = "default-on";
+			};
+
+			led3 {
+				label = "led13";
+				gpios = <&gpio0 13 GPIO_ACTIVE_LOW>;
+				linux,default-trigger = "default-on";
+			};
+		};
+	};
+
+	chosen {
+		bootargs = "console=tty0 init=/sbin/init root=/dev/sda2 rw rootwait";
+	};
+};
diff --git a/arch/csky/boot/dts/gx6622.dts b/arch/csky/boot/dts/gx6622.dts
new file mode 100644
index 0000000..709f66e
--- /dev/null
+++ b/arch/csky/boot/dts/gx6622.dts
@@ -0,0 +1,56 @@
+/dts-v1/;
+/ {
+	model = "Nationalchip csky gx6605s";
+	compatible = "csky,nationalchip-gx6605s";
+	#address-cells = <1>;
+	#size-cells = <1>;
+
+	memory {
+		device_type = "memory";
+		reg = <0x10000000 0x08000000>;
+	};
+
+	soc {
+		#address-cells = <1>;
+		#size-cells = <1>;
+		compatible = "simple-bus";
+		ranges;
+
+		intc: interrupt-controller {
+			compatible = "nationalchip,intc-v1,ave";
+			reg = <0x00500000 0x400>;
+			interrupt-controller;
+			#interrupt-cells = <1>;
+		};
+
+		timer0 {
+			compatible = "nationalchip,timer-v1";
+			reg = <0x0020a000 0x400>;
+			clock-frequency = <1000000>;
+			interrupts = <10>;
+			interrupt-parent = <&intc>;
+		};
+
+		ehci: ehci-hcd {
+			compatible = "generic-ehci";
+			reg = <0x00900000 0x400>;
+			interrupt-parent = <&intc>;
+			interrupts = <59>;
+		};
+
+		uart0: serial@403000 {
+			compatible = "ns16550a";
+			reg = <0x00403000 0x400>;
+			interrupt-parent = <&intc>;
+			interrupts = <15>;
+			clock-frequency = <29491200>;
+			baud = <115200>;
+			reg-shift = <2>;
+			reg-io-width = <1>;
+		};
+	};
+
+	chosen {
+		bootargs = "console=ttyS0,115200 init=/init root=/dev/nfs rw nfsroot=192.168.101.230:/opt/nfs/test,v3,tcp,nolock ip=192.168.101.23";
+	};
+};
diff --git a/arch/csky/boot/dts/include/dt-bindings b/arch/csky/boot/dts/include/dt-bindings
new file mode 120000
index 0000000..08c00e4
--- /dev/null
+++ b/arch/csky/boot/dts/include/dt-bindings
@@ -0,0 +1 @@
+../../../../../include/dt-bindings
\ No newline at end of file
diff --git a/arch/csky/boot/dts/sc8925.dts b/arch/csky/boot/dts/sc8925.dts
new file mode 100644
index 0000000..928e9f3
--- /dev/null
+++ b/arch/csky/boot/dts/sc8925.dts
@@ -0,0 +1,57 @@
+/dts-v1/;
+
+/ {
+	model = "silan sc8925";
+	compatible = "csky,silan-sc8925";
+	#address-cells = <1>;
+	#size-cells = <1>;
+
+	memory {
+		device_type = "memory";
+		reg = <0x00000000 0x08000000>;
+	};
+
+	soc {
+		#address-cells = <1>;
+		#size-cells = <1>;
+		compatible = "simple-bus";
+		ranges;
+
+		silan_clk0: silan-clock0 {
+			compatible = "silan,sc8925-clk";
+			#clock-cells = <1>;
+		};
+
+		intc: interrupt-controller {
+			compatible = "csky,intc-v1";
+			reg = <0x1fcb0000 0x400>;
+			interrupt-controller;
+			#interrupt-cells = <1>;
+		};
+
+		timer0: timer@1fcb1000 {
+			compatible = "arm,sp804";
+			reg = <0x1fbc7000 0x1000>;
+			clocks = <&silan_clk0 34>;
+			interrupts = <17>;
+			interrupt-parent = <&intc>;
+		};
+
+		pinctrl: pinctrl {
+			compatible = "silan,sc8925-pinctrl";
+		};
+
+		uart0: serial@1fbc0000 {
+			compatible = "arm,sbsa-uart";
+			reg = <0x1fbc0000 0x1000>;
+			current-speed = <115200>;
+			clocks = <&silan_clk0 9>;
+			interrupts = <11>;
+			interrupt-parent = <&intc>;
+		};
+	};
+
+	chosen {
+		bootargs = "console=ttyAMA0,115200 init=/sbin/init root=/dev/nfs rw nfsroot=192.168.101.230:/opt/nfs/test_abiv2_new/,v3,tcp,nolock ip=192.168.101.23";
+	};
+};
diff --git a/arch/csky/configs/gx66xx_defconfig b/arch/csky/configs/gx66xx_defconfig
new file mode 100644
index 0000000..7bd9e7f
--- /dev/null
+++ b/arch/csky/configs/gx66xx_defconfig
@@ -0,0 +1,551 @@
+CONFIG_CROSS_COMPILE="csky-linux-"
+# CONFIG_LOCALVERSION_AUTO is not set
+CONFIG_DEFAULT_HOSTNAME="github.com/c-sky"
+# CONFIG_SWAP is not set
+CONFIG_SYSVIPC=y
+CONFIG_POSIX_MQUEUE=y
+# CONFIG_FHANDLE is not set
+CONFIG_USELIB=y
+CONFIG_AUDIT=y
+CONFIG_IRQ_DOMAIN_DEBUG=y
+CONFIG_NO_HZ_IDLE=y
+CONFIG_HIGH_RES_TIMERS=y
+CONFIG_BSD_PROCESS_ACCT=y
+CONFIG_BSD_PROCESS_ACCT_V3=y
+CONFIG_RELAY=y
+CONFIG_SYSCTL_SYSCALL=y
+CONFIG_KALLSYMS_ALL=y
+# CONFIG_AIO is not set
+CONFIG_USERFAULTFD=y
+CONFIG_EMBEDDED=y
+# CONFIG_PERF_EVENTS is not set
+# CONFIG_SLUB_DEBUG is not set
+# CONFIG_COMPAT_BRK is not set
+CONFIG_PROFILING=y
+CONFIG_OPROFILE=y
+CONFIG_MODULES=y
+CONFIG_MODULE_UNLOAD=y
+CONFIG_BLK_DEV_BSGLIB=y
+CONFIG_BLK_DEV_INTEGRITY=y
+CONFIG_PARTITION_ADVANCED=y
+CONFIG_ACORN_PARTITION=y
+CONFIG_ACORN_PARTITION_ICS=y
+CONFIG_ACORN_PARTITION_RISCIX=y
+CONFIG_AIX_PARTITION=y
+CONFIG_OSF_PARTITION=y
+CONFIG_AMIGA_PARTITION=y
+CONFIG_ATARI_PARTITION=y
+CONFIG_MAC_PARTITION=y
+CONFIG_BSD_DISKLABEL=y
+CONFIG_MINIX_SUBPARTITION=y
+CONFIG_SOLARIS_X86_PARTITION=y
+CONFIG_UNIXWARE_DISKLABEL=y
+CONFIG_LDM_PARTITION=y
+CONFIG_SGI_PARTITION=y
+CONFIG_ULTRIX_PARTITION=y
+CONFIG_SUN_PARTITION=y
+CONFIG_KARMA_PARTITION=y
+CONFIG_SYSV68_PARTITION=y
+CONFIG_CMDLINE_PARTITION=y
+CONFIG_DEFAULT_DEADLINE=y
+CONFIG_FB_NATIONALCHIP=y
+# CONFIG_MMU_HARD_REFILL is not set
+CONFIG_RAM_BASE=0x10000000
+# CONFIG_SUSPEND is not set
+# CONFIG_COMPACTION is not set
+CONFIG_NET=y
+CONFIG_PACKET=y
+CONFIG_UNIX=y
+CONFIG_INET=y
+CONFIG_IP_MULTICAST=y
+CONFIG_IP_PNP=y
+CONFIG_IP_PNP_DHCP=y
+CONFIG_IP_PNP_BOOTP=y
+CONFIG_IP_PNP_RARP=y
+# CONFIG_IPV6 is not set
+CONFIG_CFG80211=y
+CONFIG_CFG80211_DEBUGFS=y
+CONFIG_CFG80211_WEXT=y
+CONFIG_MAC80211=y
+CONFIG_MAC80211_DEBUGFS=y
+CONFIG_RFKILL=y
+CONFIG_RFKILL_INPUT=y
+CONFIG_RFKILL_GPIO=y
+CONFIG_DEVTMPFS=y
+CONFIG_DEVTMPFS_MOUNT=y
+# CONFIG_STANDALONE is not set
+CONFIG_BLK_DEV_LOOP=y
+CONFIG_BLK_DEV_RAM=y
+CONFIG_BLK_DEV_RAM_SIZE=65536
+CONFIG_VIRTIO_BLK=y
+CONFIG_AD525X_DPOT=m
+CONFIG_AD525X_DPOT_I2C=m
+CONFIG_DUMMY_IRQ=m
+CONFIG_ICS932S401=m
+CONFIG_ENCLOSURE_SERVICES=m
+CONFIG_APDS9802ALS=m
+CONFIG_ISL29003=m
+CONFIG_ISL29020=m
+CONFIG_SENSORS_TSL2550=m
+CONFIG_SENSORS_BH1770=m
+CONFIG_SENSORS_APDS990X=m
+CONFIG_HMC6352=m
+CONFIG_DS1682=m
+CONFIG_USB_SWITCH_FSA9480=m
+CONFIG_SRAM=y
+CONFIG_C2PORT=m
+CONFIG_EEPROM_AT24=m
+CONFIG_EEPROM_LEGACY=m
+CONFIG_EEPROM_MAX6875=m
+CONFIG_SENSORS_LIS3_I2C=m
+CONFIG_ALTERA_STAPL=m
+CONFIG_ECHO=m
+CONFIG_SCSI=y
+# CONFIG_SCSI_PROC_FS is not set
+CONFIG_BLK_DEV_SD=y
+CONFIG_SCSI_SPI_ATTRS=y
+CONFIG_SCSI_SAS_LIBSAS=m
+CONFIG_SCSI_SRP_ATTRS=m
+# CONFIG_SCSI_LOWLEVEL is not set
+CONFIG_NETDEVICES=y
+CONFIG_USB_RTL8150=y
+CONFIG_USB_RTL8152=y
+CONFIG_USB_USBNET=y
+# CONFIG_WLAN_VENDOR_ADMTEK is not set
+# CONFIG_WLAN_VENDOR_ATH is not set
+# CONFIG_WLAN_VENDOR_ATMEL is not set
+# CONFIG_WLAN_VENDOR_BROADCOM is not set
+# CONFIG_WLAN_VENDOR_CISCO is not set
+# CONFIG_WLAN_VENDOR_INTEL is not set
+# CONFIG_WLAN_VENDOR_INTERSIL is not set
+# CONFIG_WLAN_VENDOR_MARVELL is not set
+CONFIG_MT7601U=m
+# CONFIG_WLAN_VENDOR_RALINK is not set
+CONFIG_RTL8187=y
+CONFIG_RTL8XXXU=y
+CONFIG_RTL8XXXU_UNTESTED=y
+# CONFIG_WLAN_VENDOR_RSI is not set
+# CONFIG_WLAN_VENDOR_ST is not set
+# CONFIG_WLAN_VENDOR_TI is not set
+# CONFIG_WLAN_VENDOR_ZYDAS is not set
+CONFIG_INPUT_SPARSEKMAP=m
+CONFIG_INPUT_EVDEV=y
+CONFIG_KEYBOARD_ADP5588=m
+CONFIG_KEYBOARD_ADP5589=m
+CONFIG_KEYBOARD_QT1070=m
+CONFIG_KEYBOARD_QT2160=m
+CONFIG_KEYBOARD_LKKBD=m
+CONFIG_KEYBOARD_GPIO_POLLED=m
+CONFIG_KEYBOARD_TCA6416=m
+CONFIG_KEYBOARD_TCA8418=m
+CONFIG_KEYBOARD_LM8323=m
+CONFIG_KEYBOARD_LM8333=m
+CONFIG_KEYBOARD_MAX7359=m
+CONFIG_KEYBOARD_MCS=m
+CONFIG_KEYBOARD_MPR121=m
+CONFIG_KEYBOARD_NEWTON=m
+CONFIG_KEYBOARD_OPENCORES=m
+CONFIG_KEYBOARD_STOWAWAY=m
+CONFIG_KEYBOARD_SUNKBD=m
+CONFIG_KEYBOARD_XTKBD=m
+CONFIG_MOUSE_PS2=m
+CONFIG_MOUSE_PS2_ELANTECH=y
+CONFIG_MOUSE_PS2_SENTELIC=y
+CONFIG_MOUSE_PS2_TOUCHKIT=y
+CONFIG_MOUSE_SERIAL=m
+CONFIG_MOUSE_CYAPA=m
+CONFIG_MOUSE_VSXXXAA=m
+CONFIG_MOUSE_SYNAPTICS_I2C=m
+CONFIG_INPUT_JOYSTICK=y
+CONFIG_JOYSTICK_ANALOG=m
+CONFIG_JOYSTICK_A3D=m
+CONFIG_JOYSTICK_ADI=m
+CONFIG_JOYSTICK_COBRA=m
+CONFIG_JOYSTICK_GF2K=m
+CONFIG_JOYSTICK_GRIP=m
+CONFIG_JOYSTICK_GRIP_MP=m
+CONFIG_JOYSTICK_GUILLEMOT=m
+CONFIG_JOYSTICK_INTERACT=m
+CONFIG_JOYSTICK_SIDEWINDER=m
+CONFIG_JOYSTICK_TMDC=m
+CONFIG_JOYSTICK_IFORCE=m
+CONFIG_JOYSTICK_IFORCE_232=y
+CONFIG_JOYSTICK_WARRIOR=m
+CONFIG_JOYSTICK_MAGELLAN=m
+CONFIG_JOYSTICK_SPACEORB=m
+CONFIG_JOYSTICK_SPACEBALL=m
+CONFIG_JOYSTICK_STINGER=m
+CONFIG_JOYSTICK_TWIDJOY=m
+CONFIG_JOYSTICK_ZHENHUA=m
+CONFIG_JOYSTICK_AS5011=m
+CONFIG_JOYSTICK_JOYDUMP=m
+CONFIG_INPUT_TABLET=y
+CONFIG_INPUT_TOUCHSCREEN=y
+CONFIG_TOUCHSCREEN_AD7879=m
+CONFIG_TOUCHSCREEN_AD7879_I2C=m
+CONFIG_TOUCHSCREEN_ATMEL_MXT=m
+CONFIG_TOUCHSCREEN_BU21013=m
+CONFIG_TOUCHSCREEN_CYTTSP_CORE=m
+CONFIG_TOUCHSCREEN_CYTTSP_I2C=m
+CONFIG_TOUCHSCREEN_CYTTSP4_CORE=m
+CONFIG_TOUCHSCREEN_CYTTSP4_I2C=m
+CONFIG_TOUCHSCREEN_DYNAPRO=m
+CONFIG_TOUCHSCREEN_HAMPSHIRE=m
+CONFIG_TOUCHSCREEN_EETI=m
+CONFIG_TOUCHSCREEN_FUJITSU=m
+CONFIG_TOUCHSCREEN_ILI210X=m
+CONFIG_TOUCHSCREEN_GUNZE=m
+CONFIG_TOUCHSCREEN_ELO=m
+CONFIG_TOUCHSCREEN_WACOM_W8001=m
+CONFIG_TOUCHSCREEN_WACOM_I2C=m
+CONFIG_TOUCHSCREEN_MAX11801=m
+CONFIG_TOUCHSCREEN_MCS5000=m
+CONFIG_TOUCHSCREEN_MMS114=m
+CONFIG_TOUCHSCREEN_MTOUCH=m
+CONFIG_TOUCHSCREEN_INEXIO=m
+CONFIG_TOUCHSCREEN_MK712=m
+CONFIG_TOUCHSCREEN_PENMOUNT=m
+CONFIG_TOUCHSCREEN_EDT_FT5X06=m
+CONFIG_TOUCHSCREEN_TOUCHRIGHT=m
+CONFIG_TOUCHSCREEN_TOUCHWIN=m
+CONFIG_TOUCHSCREEN_PIXCIR=m
+CONFIG_TOUCHSCREEN_TOUCHIT213=m
+CONFIG_TOUCHSCREEN_TSC_SERIO=m
+CONFIG_TOUCHSCREEN_TSC2007=m
+CONFIG_TOUCHSCREEN_ST1232=m
+CONFIG_TOUCHSCREEN_TPS6507X=m
+CONFIG_INPUT_MISC=y
+CONFIG_INPUT_AD714X=m
+CONFIG_INPUT_BMA150=m
+CONFIG_INPUT_MMA8450=m
+CONFIG_INPUT_MPU3050=m
+CONFIG_INPUT_KXTJ9=m
+CONFIG_INPUT_UINPUT=y
+CONFIG_INPUT_PCF8574=m
+CONFIG_INPUT_ADXL34X=m
+CONFIG_INPUT_CMA3000=m
+CONFIG_INPUT_CMA3000_I2C=m
+CONFIG_SERIO_SERPORT=m
+CONFIG_SERIO_RAW=m
+CONFIG_SERIO_ALTERA_PS2=m
+CONFIG_SERIO_PS2MULT=m
+CONFIG_SERIO_ARC_PS2=m
+CONFIG_GAMEPORT_NS558=m
+CONFIG_GAMEPORT_L4=m
+CONFIG_SERIAL_NONSTANDARD=y
+# CONFIG_DEVKMEM is not set
+CONFIG_SERIAL_8250=y
+# CONFIG_SERIAL_8250_DEPRECATED_OPTIONS is not set
+CONFIG_SERIAL_8250_CONSOLE=y
+CONFIG_SERIAL_8250_NR_UARTS=2
+CONFIG_SERIAL_8250_RUNTIME_UARTS=2
+CONFIG_SERIAL_8250_DW=y
+CONFIG_SERIAL_OF_PLATFORM=y
+CONFIG_TTY_PRINTK=y
+CONFIG_VIRTIO_CONSOLE=y
+CONFIG_IPMI_HANDLER=y
+CONFIG_IPMI_DEVICE_INTERFACE=m
+CONFIG_IPMI_SI=m
+CONFIG_IPMI_WATCHDOG=m
+CONFIG_IPMI_POWEROFF=m
+CONFIG_HW_RANDOM=y
+CONFIG_HW_RANDOM_TIMERIOMEM=m
+CONFIG_HW_RANDOM_VIRTIO=m
+CONFIG_HW_RANDOM_TPM=m
+CONFIG_TCG_TIS_I2C_ATMEL=m
+CONFIG_TCG_TIS_I2C_INFINEON=m
+CONFIG_TCG_TIS_I2C_NUVOTON=m
+CONFIG_TCG_ATMEL=m
+CONFIG_I2C_CHARDEV=m
+CONFIG_I2C_MUX_PCA9541=m
+CONFIG_I2C_DESIGNWARE_PLATFORM=m
+CONFIG_I2C_OCORES=m
+CONFIG_I2C_PCA_PLATFORM=m
+CONFIG_I2C_SIMTEC=m
+CONFIG_I2C_XILINX=m
+CONFIG_I2C_PARPORT_LIGHT=m
+CONFIG_I2C_TAOS_EVM=m
+CONFIG_I2C_STUB=m
+CONFIG_PPS=m
+CONFIG_PPS_CLIENT_LDISC=m
+CONFIG_PPS_CLIENT_GPIO=m
+CONFIG_GPIOLIB=y
+CONFIG_DEBUG_GPIO=y
+CONFIG_GPIO_SYSFS=y
+CONFIG_GPIO_GENERIC_PLATFORM=y
+CONFIG_POWER_RESET=y
+# CONFIG_HWMON is not set
+CONFIG_SSB=m
+CONFIG_BCMA=m
+CONFIG_BCMA_HOST_SOC=y
+CONFIG_BCMA_DRIVER_GMAC_CMN=y
+CONFIG_MEDIA_SUPPORT=y
+CONFIG_MEDIA_CAMERA_SUPPORT=y
+CONFIG_MEDIA_USB_SUPPORT=y
+CONFIG_USB_VIDEO_CLASS=y
+# CONFIG_USB_GSPCA is not set
+CONFIG_FB=y
+CONFIG_FB_TILEBLITTING=y
+CONFIG_FB_SIMPLE=y
+CONFIG_BACKLIGHT_LCD_SUPPORT=y
+# CONFIG_LCD_CLASS_DEVICE is not set
+# CONFIG_BACKLIGHT_CLASS_DEVICE is not set
+# CONFIG_VGA_CONSOLE is not set
+CONFIG_FRAMEBUFFER_CONSOLE=y
+CONFIG_FRAMEBUFFER_CONSOLE_DETECT_PRIMARY=y
+CONFIG_FRAMEBUFFER_CONSOLE_ROTATION=y
+CONFIG_LOGO=y
+# CONFIG_LOGO_LINUX_MONO is not set
+# CONFIG_LOGO_LINUX_VGA16 is not set
+CONFIG_HID_A4TECH=m
+CONFIG_HID_ACRUX=m
+CONFIG_HID_ACRUX_FF=y
+CONFIG_HID_APPLE=m
+CONFIG_HID_AUREAL=m
+CONFIG_HID_BELKIN=m
+CONFIG_HID_CHERRY=m
+CONFIG_HID_CHICONY=m
+CONFIG_HID_CYPRESS=m
+CONFIG_HID_DRAGONRISE=m
+CONFIG_DRAGONRISE_FF=y
+CONFIG_HID_EMS_FF=m
+CONFIG_HID_ELECOM=m
+CONFIG_HID_EZKEY=m
+CONFIG_HID_KEYTOUCH=m
+CONFIG_HID_KYE=m
+CONFIG_HID_WALTOP=m
+CONFIG_HID_GYRATION=m
+CONFIG_HID_ICADE=m
+CONFIG_HID_TWINHAN=m
+CONFIG_HID_KENSINGTON=m
+CONFIG_HID_LCPOWER=m
+CONFIG_HID_LOGITECH=m
+CONFIG_HID_LOGITECH_HIDPP=m
+CONFIG_LOGITECH_FF=y
+CONFIG_LOGIRUMBLEPAD2_FF=y
+CONFIG_LOGIG940_FF=y
+CONFIG_HID_MAGICMOUSE=m
+CONFIG_HID_MICROSOFT=m
+CONFIG_HID_MONTEREY=m
+CONFIG_HID_MULTITOUCH=m
+CONFIG_HID_ORTEK=m
+CONFIG_HID_PANTHERLORD=m
+CONFIG_PANTHERLORD_FF=y
+CONFIG_HID_PETALYNX=m
+CONFIG_HID_PICOLCD=m
+CONFIG_HID_PICOLCD_LEDS=y
+CONFIG_HID_PRIMAX=m
+CONFIG_HID_SAITEK=m
+CONFIG_HID_SAMSUNG=m
+CONFIG_HID_SPEEDLINK=m
+CONFIG_HID_STEELSERIES=m
+CONFIG_HID_SUNPLUS=m
+CONFIG_HID_RMI=m
+CONFIG_HID_GREENASIA=m
+CONFIG_GREENASIA_FF=y
+CONFIG_HID_SMARTJOYPLUS=m
+CONFIG_SMARTJOYPLUS_FF=y
+CONFIG_HID_TIVO=m
+CONFIG_HID_TOPSEED=m
+CONFIG_HID_THINGM=m
+CONFIG_HID_THRUSTMASTER=m
+CONFIG_THRUSTMASTER_FF=y
+CONFIG_HID_WACOM=m
+CONFIG_HID_WIIMOTE=m
+CONFIG_HID_XINMO=m
+CONFIG_HID_ZEROPLUS=m
+CONFIG_ZEROPLUS_FF=y
+CONFIG_HID_ZYDACRON=m
+CONFIG_HID_SENSOR_HUB=m
+CONFIG_HID_PID=y
+CONFIG_I2C_HID=m
+CONFIG_USB=y
+CONFIG_USB_EHCI_HCD=y
+CONFIG_USB_EHCI_HCD_PLATFORM=y
+CONFIG_USB_OHCI_HCD=y
+CONFIG_USB_OHCI_HCD_PLATFORM=y
+CONFIG_USB_STORAGE=y
+CONFIG_LEDS_CLASS=y
+CONFIG_LEDS_LM3530=m
+CONFIG_LEDS_LM3642=m
+CONFIG_LEDS_PCA9532=m
+CONFIG_LEDS_GPIO=m
+CONFIG_LEDS_LP3944=m
+CONFIG_LEDS_LP5521=m
+CONFIG_LEDS_LP5523=m
+CONFIG_LEDS_LP5562=m
+CONFIG_LEDS_LP8501=m
+CONFIG_LEDS_PCA955X=m
+CONFIG_LEDS_PCA963X=m
+CONFIG_LEDS_BD2802=m
+CONFIG_LEDS_TCA6507=m
+CONFIG_LEDS_LM355x=m
+CONFIG_LEDS_BLINKM=m
+CONFIG_LEDS_TRIGGER_TIMER=y
+CONFIG_LEDS_TRIGGER_ONESHOT=y
+CONFIG_LEDS_TRIGGER_HEARTBEAT=y
+CONFIG_LEDS_TRIGGER_BACKLIGHT=y
+CONFIG_LEDS_TRIGGER_CPU=y
+CONFIG_LEDS_TRIGGER_GPIO=y
+CONFIG_LEDS_TRIGGER_DEFAULT_ON=y
+CONFIG_LEDS_TRIGGER_TRANSIENT=y
+CONFIG_LEDS_TRIGGER_CAMERA=y
+CONFIG_LEDS_TRIGGER_PANIC=y
+CONFIG_VIRTIO_BALLOON=y
+CONFIG_VIRTIO_MMIO=y
+CONFIG_VIRTIO_MMIO_CMDLINE_DEVICES=y
+# CONFIG_IOMMU_SUPPORT is not set
+CONFIG_STE_MODEM_RPROC=m
+CONFIG_PM_DEVFREQ=y
+CONFIG_DEVFREQ_GOV_SIMPLE_ONDEMAND=y
+CONFIG_DEVFREQ_GOV_PERFORMANCE=y
+CONFIG_DEVFREQ_GOV_POWERSAVE=y
+CONFIG_DEVFREQ_GOV_USERSPACE=y
+CONFIG_EXT2_FS=y
+CONFIG_EXT2_FS_XATTR=y
+CONFIG_EXT2_FS_POSIX_ACL=y
+CONFIG_EXT2_FS_SECURITY=y
+CONFIG_EXT3_FS=y
+CONFIG_EXT3_FS_POSIX_ACL=y
+CONFIG_EXT3_FS_SECURITY=y
+CONFIG_FANOTIFY=y
+CONFIG_FANOTIFY_ACCESS_PERMISSIONS=y
+CONFIG_QUOTA=y
+# CONFIG_PRINT_QUOTA_WARNING is not set
+CONFIG_FSCACHE=m
+CONFIG_FSCACHE_STATS=y
+CONFIG_CACHEFILES=m
+CONFIG_MSDOS_FS=y
+CONFIG_VFAT_FS=y
+CONFIG_FAT_DEFAULT_UTF8=y
+CONFIG_NTFS_FS=y
+CONFIG_PROC_KCORE=y
+CONFIG_PROC_CHILDREN=y
+CONFIG_TMPFS=y
+CONFIG_TMPFS_POSIX_ACL=y
+CONFIG_CONFIGFS_FS=y
+CONFIG_CRAMFS=y
+CONFIG_ROMFS_FS=y
+CONFIG_NFS_FS=y
+CONFIG_ROOT_NFS=y
+CONFIG_NLS_DEFAULT="utf8"
+CONFIG_NLS_CODEPAGE_437=y
+CONFIG_NLS_CODEPAGE_737=y
+CONFIG_NLS_CODEPAGE_775=y
+CONFIG_NLS_CODEPAGE_850=y
+CONFIG_NLS_CODEPAGE_852=y
+CONFIG_NLS_CODEPAGE_855=y
+CONFIG_NLS_CODEPAGE_857=y
+CONFIG_NLS_CODEPAGE_860=y
+CONFIG_NLS_CODEPAGE_861=y
+CONFIG_NLS_CODEPAGE_863=y
+CONFIG_NLS_CODEPAGE_864=y
+CONFIG_NLS_CODEPAGE_865=y
+CONFIG_NLS_CODEPAGE_866=y
+CONFIG_NLS_CODEPAGE_869=y
+CONFIG_NLS_CODEPAGE_936=y
+CONFIG_NLS_CODEPAGE_950=y
+CONFIG_NLS_CODEPAGE_932=y
+CONFIG_NLS_CODEPAGE_949=m
+CONFIG_NLS_CODEPAGE_874=m
+CONFIG_NLS_ISO8859_8=m
+CONFIG_NLS_CODEPAGE_1250=y
+CONFIG_NLS_CODEPAGE_1251=y
+CONFIG_NLS_ASCII=m
+CONFIG_NLS_ISO8859_1=y
+CONFIG_NLS_ISO8859_2=m
+CONFIG_NLS_ISO8859_3=m
+CONFIG_NLS_ISO8859_4=m
+CONFIG_NLS_ISO8859_5=m
+CONFIG_NLS_ISO8859_6=m
+CONFIG_NLS_ISO8859_7=m
+CONFIG_NLS_ISO8859_9=m
+CONFIG_NLS_ISO8859_13=m
+CONFIG_NLS_ISO8859_14=m
+CONFIG_NLS_ISO8859_15=m
+CONFIG_NLS_KOI8_R=m
+CONFIG_NLS_KOI8_U=m
+CONFIG_NLS_MAC_ROMAN=m
+CONFIG_NLS_MAC_CELTIC=m
+CONFIG_NLS_MAC_CENTEURO=m
+CONFIG_NLS_MAC_CROATIAN=m
+CONFIG_NLS_MAC_CYRILLIC=m
+CONFIG_NLS_MAC_GAELIC=m
+CONFIG_NLS_MAC_GREEK=m
+CONFIG_NLS_MAC_ICELAND=m
+CONFIG_NLS_MAC_INUIT=m
+CONFIG_NLS_MAC_ROMANIAN=m
+CONFIG_NLS_MAC_TURKISH=m
+CONFIG_NLS_UTF8=y
+CONFIG_PRINTK_TIME=y
+CONFIG_DEBUG_INFO=y
+# CONFIG_ENABLE_WARN_DEPRECATED is not set
+# CONFIG_ENABLE_MUST_CHECK is not set
+CONFIG_UNUSED_SYMBOLS=y
+CONFIG_DEBUG_FS=y
+CONFIG_MAGIC_SYSRQ=y
+CONFIG_LOCKUP_DETECTOR=y
+# CONFIG_SCHED_DEBUG is not set
+CONFIG_RBTREE_TEST=m
+CONFIG_INTERVAL_TREE_TEST=m
+CONFIG_PERCPU_TEST=m
+CONFIG_TEST_STRING_HELPERS=m
+CONFIG_TEST_KSTRTOX=m
+CONFIG_PERSISTENT_KEYRINGS=y
+CONFIG_TRUSTED_KEYS=y
+CONFIG_SECURITY=y
+CONFIG_SECURITY_NETWORK=y
+CONFIG_SECURITY_PATH=y
+CONFIG_SECURITY_YAMA=y
+CONFIG_INTEGRITY_SIGNATURE=y
+CONFIG_INTEGRITY_ASYMMETRIC_KEYS=y
+CONFIG_IMA=y
+CONFIG_IMA_APPRAISE=y
+CONFIG_EVM=y
+CONFIG_CRYPTO_CRYPTD=m
+CONFIG_CRYPTO_AUTHENC=m
+CONFIG_CRYPTO_TEST=m
+CONFIG_CRYPTO_CTS=m
+CONFIG_CRYPTO_ECB=y
+CONFIG_CRYPTO_LRW=m
+CONFIG_CRYPTO_PCBC=m
+CONFIG_CRYPTO_XTS=m
+CONFIG_CRYPTO_CMAC=m
+CONFIG_CRYPTO_XCBC=m
+CONFIG_CRYPTO_VMAC=m
+CONFIG_CRYPTO_CRC32=m
+CONFIG_CRYPTO_MD4=m
+CONFIG_CRYPTO_MICHAEL_MIC=m
+CONFIG_CRYPTO_RMD128=m
+CONFIG_CRYPTO_RMD160=m
+CONFIG_CRYPTO_RMD256=m
+CONFIG_CRYPTO_RMD320=m
+CONFIG_CRYPTO_SHA512=y
+CONFIG_CRYPTO_TGR192=m
+CONFIG_CRYPTO_WP512=m
+CONFIG_CRYPTO_ANUBIS=m
+CONFIG_CRYPTO_BLOWFISH=m
+CONFIG_CRYPTO_CAMELLIA=m
+CONFIG_CRYPTO_CAST5=m
+CONFIG_CRYPTO_CAST6=m
+CONFIG_CRYPTO_DES=m
+CONFIG_CRYPTO_FCRYPT=m
+CONFIG_CRYPTO_KHAZAD=m
+CONFIG_CRYPTO_SALSA20=m
+CONFIG_CRYPTO_SEED=m
+CONFIG_CRYPTO_SERPENT=m
+CONFIG_CRYPTO_TEA=m
+CONFIG_CRYPTO_TWOFISH=m
+CONFIG_CRYPTO_DEFLATE=m
+CONFIG_CRYPTO_LZO=y
+CONFIG_CRYPTO_LZ4=m
+CONFIG_CRYPTO_LZ4HC=m
+CONFIG_CRYPTO_ANSI_CPRNG=m
+CONFIG_CRC_CCITT=m
+CONFIG_CRC7=m
+CONFIG_LIBCRC32C=m
+CONFIG_CRC8=m
+CONFIG_XZ_DEC=y
+CONFIG_XZ_DEC_TEST=m
+CONFIG_CORDIC=m
+CONFIG_DDR=y
diff --git a/arch/csky/configs/sc8925_defconfig b/arch/csky/configs/sc8925_defconfig
new file mode 100644
index 0000000..994e519
--- /dev/null
+++ b/arch/csky/configs/sc8925_defconfig
@@ -0,0 +1,541 @@
+CONFIG_CROSS_COMPILE="csky-abiv2-linux-"
+CONFIG_COMPILE_TEST=y
+CONFIG_DEFAULT_HOSTNAME="github.com/c-sky"
+# CONFIG_SWAP is not set
+CONFIG_SYSVIPC=y
+CONFIG_POSIX_MQUEUE=y
+# CONFIG_FHANDLE is not set
+CONFIG_USELIB=y
+CONFIG_AUDIT=y
+CONFIG_BSD_PROCESS_ACCT=y
+CONFIG_BSD_PROCESS_ACCT_V3=y
+CONFIG_RELAY=y
+CONFIG_BLK_DEV_INITRD=y
+CONFIG_SYSCTL_SYSCALL=y
+CONFIG_KALLSYMS_ALL=y
+# CONFIG_AIO is not set
+CONFIG_USERFAULTFD=y
+CONFIG_EMBEDDED=y
+# CONFIG_PERF_EVENTS is not set
+# CONFIG_SLUB_DEBUG is not set
+# CONFIG_COMPAT_BRK is not set
+CONFIG_PROFILING=y
+CONFIG_OPROFILE=y
+CONFIG_MODULES=y
+CONFIG_MODULE_UNLOAD=y
+CONFIG_BLK_DEV_BSGLIB=y
+CONFIG_BLK_DEV_INTEGRITY=y
+CONFIG_PARTITION_ADVANCED=y
+CONFIG_ACORN_PARTITION=y
+CONFIG_ACORN_PARTITION_ICS=y
+CONFIG_ACORN_PARTITION_RISCIX=y
+CONFIG_AIX_PARTITION=y
+CONFIG_OSF_PARTITION=y
+CONFIG_AMIGA_PARTITION=y
+CONFIG_ATARI_PARTITION=y
+CONFIG_MAC_PARTITION=y
+CONFIG_BSD_DISKLABEL=y
+CONFIG_MINIX_SUBPARTITION=y
+CONFIG_SOLARIS_X86_PARTITION=y
+CONFIG_UNIXWARE_DISKLABEL=y
+CONFIG_LDM_PARTITION=y
+CONFIG_SGI_PARTITION=y
+CONFIG_ULTRIX_PARTITION=y
+CONFIG_SUN_PARTITION=y
+CONFIG_KARMA_PARTITION=y
+CONFIG_SYSV68_PARTITION=y
+CONFIG_CMDLINE_PARTITION=y
+CONFIG_DEFAULT_DEADLINE=y
+CONFIG_PINCTRL_SILAN=y
+CONFIG_CLK_SILAN=y
+CONFIG_SILAN_SC6138A_TIMER=y
+CONFIG_SILAN_STMMAC_ETH=y
+CONFIG_SILAN_ETH0=y
+CONFIG_CSKY_DEBUG_INFO=y
+CONFIG_CPU_CK810=y
+CONFIG_CPU_HAS_FPU=y
+CONFIG_RAM_BASE=0x0
+# CONFIG_SUSPEND is not set
+# CONFIG_COMPACTION is not set
+CONFIG_NET=y
+CONFIG_PACKET=y
+CONFIG_UNIX=y
+CONFIG_INET=y
+CONFIG_IP_MULTICAST=y
+CONFIG_IP_PNP=y
+CONFIG_IP_PNP_DHCP=y
+CONFIG_IP_PNP_BOOTP=y
+CONFIG_IP_PNP_RARP=y
+# CONFIG_IPV6 is not set
+CONFIG_DEVTMPFS=y
+CONFIG_DEVTMPFS_MOUNT=y
+# CONFIG_STANDALONE is not set
+CONFIG_BLK_DEV_LOOP=y
+CONFIG_BLK_DEV_RAM=y
+CONFIG_BLK_DEV_RAM_SIZE=65536
+CONFIG_VIRTIO_BLK=y
+CONFIG_AD525X_DPOT=m
+CONFIG_AD525X_DPOT_I2C=m
+CONFIG_DUMMY_IRQ=m
+CONFIG_ICS932S401=m
+CONFIG_ENCLOSURE_SERVICES=m
+CONFIG_APDS9802ALS=m
+CONFIG_ISL29003=m
+CONFIG_ISL29020=m
+CONFIG_SENSORS_TSL2550=m
+CONFIG_SENSORS_BH1770=m
+CONFIG_SENSORS_APDS990X=m
+CONFIG_HMC6352=m
+CONFIG_DS1682=m
+CONFIG_USB_SWITCH_FSA9480=m
+CONFIG_SRAM=y
+CONFIG_C2PORT=m
+CONFIG_EEPROM_AT24=m
+CONFIG_EEPROM_LEGACY=m
+CONFIG_EEPROM_MAX6875=m
+CONFIG_EEPROM_93CX6=m
+CONFIG_SENSORS_LIS3_I2C=m
+CONFIG_ALTERA_STAPL=m
+CONFIG_ECHO=m
+CONFIG_SCSI=y
+# CONFIG_SCSI_PROC_FS is not set
+CONFIG_BLK_DEV_SD=y
+CONFIG_SCSI_SPI_ATTRS=y
+CONFIG_SCSI_SAS_LIBSAS=m
+CONFIG_SCSI_SRP_ATTRS=m
+# CONFIG_SCSI_LOWLEVEL is not set
+CONFIG_NETDEVICES=y
+# CONFIG_NET_VENDOR_AMAZON is not set
+# CONFIG_NET_VENDOR_ARC is not set
+# CONFIG_NET_CADENCE is not set
+# CONFIG_NET_VENDOR_BROADCOM is not set
+# CONFIG_NET_VENDOR_EZCHIP is not set
+# CONFIG_NET_VENDOR_HISILICON is not set
+# CONFIG_NET_VENDOR_INTEL is not set
+# CONFIG_NET_VENDOR_MARVELL is not set
+# CONFIG_NET_VENDOR_MICREL is not set
+# CONFIG_NET_VENDOR_NATSEMI is not set
+# CONFIG_NET_VENDOR_NETRONOME is not set
+# CONFIG_NET_VENDOR_QUALCOMM is not set
+# CONFIG_NET_VENDOR_RENESAS is not set
+# CONFIG_NET_VENDOR_ROCKER is not set
+# CONFIG_NET_VENDOR_SAMSUNG is not set
+# CONFIG_NET_VENDOR_SEEQ is not set
+# CONFIG_NET_VENDOR_STMICRO is not set
+# CONFIG_NET_VENDOR_SYNOPSYS is not set
+# CONFIG_NET_VENDOR_VIA is not set
+# CONFIG_NET_VENDOR_WIZNET is not set
+CONFIG_INPUT_SPARSEKMAP=m
+CONFIG_INPUT_JOYDEV=m
+CONFIG_INPUT_EVDEV=y
+CONFIG_INPUT_EVBUG=m
+CONFIG_KEYBOARD_ADP5588=m
+CONFIG_KEYBOARD_ADP5589=m
+CONFIG_KEYBOARD_QT1070=m
+CONFIG_KEYBOARD_QT2160=m
+CONFIG_KEYBOARD_LKKBD=m
+CONFIG_KEYBOARD_TCA6416=m
+CONFIG_KEYBOARD_TCA8418=m
+CONFIG_KEYBOARD_LM8323=m
+CONFIG_KEYBOARD_LM8333=m
+CONFIG_KEYBOARD_MAX7359=m
+CONFIG_KEYBOARD_MCS=m
+CONFIG_KEYBOARD_MPR121=m
+CONFIG_KEYBOARD_NEWTON=m
+CONFIG_KEYBOARD_OPENCORES=m
+CONFIG_KEYBOARD_STOWAWAY=m
+CONFIG_KEYBOARD_SUNKBD=m
+CONFIG_KEYBOARD_XTKBD=m
+CONFIG_MOUSE_PS2=m
+CONFIG_MOUSE_PS2_ELANTECH=y
+CONFIG_MOUSE_PS2_SENTELIC=y
+CONFIG_MOUSE_PS2_TOUCHKIT=y
+CONFIG_MOUSE_SERIAL=m
+CONFIG_MOUSE_CYAPA=m
+CONFIG_MOUSE_VSXXXAA=m
+CONFIG_MOUSE_SYNAPTICS_I2C=m
+CONFIG_INPUT_JOYSTICK=y
+CONFIG_JOYSTICK_ANALOG=m
+CONFIG_JOYSTICK_A3D=m
+CONFIG_JOYSTICK_ADI=m
+CONFIG_JOYSTICK_COBRA=m
+CONFIG_JOYSTICK_GF2K=m
+CONFIG_JOYSTICK_GRIP=m
+CONFIG_JOYSTICK_GRIP_MP=m
+CONFIG_JOYSTICK_GUILLEMOT=m
+CONFIG_JOYSTICK_INTERACT=m
+CONFIG_JOYSTICK_SIDEWINDER=m
+CONFIG_JOYSTICK_TMDC=m
+CONFIG_JOYSTICK_IFORCE=m
+CONFIG_JOYSTICK_IFORCE_232=y
+CONFIG_JOYSTICK_WARRIOR=m
+CONFIG_JOYSTICK_MAGELLAN=m
+CONFIG_JOYSTICK_SPACEORB=m
+CONFIG_JOYSTICK_SPACEBALL=m
+CONFIG_JOYSTICK_STINGER=m
+CONFIG_JOYSTICK_TWIDJOY=m
+CONFIG_JOYSTICK_ZHENHUA=m
+CONFIG_JOYSTICK_AS5011=m
+CONFIG_JOYSTICK_JOYDUMP=m
+CONFIG_INPUT_TABLET=y
+CONFIG_INPUT_TOUCHSCREEN=y
+CONFIG_TOUCHSCREEN_AD7879=m
+CONFIG_TOUCHSCREEN_AD7879_I2C=m
+CONFIG_TOUCHSCREEN_ATMEL_MXT=m
+CONFIG_TOUCHSCREEN_BU21013=m
+CONFIG_TOUCHSCREEN_CYTTSP_CORE=m
+CONFIG_TOUCHSCREEN_CYTTSP_I2C=m
+CONFIG_TOUCHSCREEN_CYTTSP4_CORE=m
+CONFIG_TOUCHSCREEN_CYTTSP4_I2C=m
+CONFIG_TOUCHSCREEN_DYNAPRO=m
+CONFIG_TOUCHSCREEN_HAMPSHIRE=m
+CONFIG_TOUCHSCREEN_EETI=m
+CONFIG_TOUCHSCREEN_FUJITSU=m
+CONFIG_TOUCHSCREEN_ILI210X=m
+CONFIG_TOUCHSCREEN_GUNZE=m
+CONFIG_TOUCHSCREEN_ELO=m
+CONFIG_TOUCHSCREEN_WACOM_W8001=m
+CONFIG_TOUCHSCREEN_WACOM_I2C=m
+CONFIG_TOUCHSCREEN_MAX11801=m
+CONFIG_TOUCHSCREEN_MCS5000=m
+CONFIG_TOUCHSCREEN_MMS114=m
+CONFIG_TOUCHSCREEN_MTOUCH=m
+CONFIG_TOUCHSCREEN_INEXIO=m
+CONFIG_TOUCHSCREEN_MK712=m
+CONFIG_TOUCHSCREEN_PENMOUNT=m
+CONFIG_TOUCHSCREEN_EDT_FT5X06=m
+CONFIG_TOUCHSCREEN_TOUCHRIGHT=m
+CONFIG_TOUCHSCREEN_TOUCHWIN=m
+CONFIG_TOUCHSCREEN_PIXCIR=m
+CONFIG_TOUCHSCREEN_TOUCHIT213=m
+CONFIG_TOUCHSCREEN_TSC_SERIO=m
+CONFIG_TOUCHSCREEN_TSC2007=m
+CONFIG_TOUCHSCREEN_ST1232=m
+CONFIG_TOUCHSCREEN_TPS6507X=m
+CONFIG_INPUT_MISC=y
+CONFIG_INPUT_AD714X=m
+CONFIG_INPUT_BMA150=m
+CONFIG_INPUT_MMA8450=m
+CONFIG_INPUT_MPU3050=m
+CONFIG_INPUT_KXTJ9=m
+CONFIG_INPUT_UINPUT=y
+CONFIG_INPUT_PCF8574=m
+CONFIG_INPUT_ADXL34X=m
+CONFIG_INPUT_CMA3000=m
+CONFIG_INPUT_CMA3000_I2C=m
+CONFIG_SERIO_SERPORT=m
+CONFIG_SERIO_RAW=m
+CONFIG_SERIO_ALTERA_PS2=m
+CONFIG_SERIO_PS2MULT=m
+CONFIG_SERIO_ARC_PS2=m
+CONFIG_GAMEPORT_NS558=m
+CONFIG_GAMEPORT_L4=m
+CONFIG_VT_HW_CONSOLE_BINDING=y
+CONFIG_SERIAL_NONSTANDARD=y
+# CONFIG_DEVKMEM is not set
+CONFIG_SERIAL_AMBA_PL011=y
+CONFIG_SERIAL_AMBA_PL011_CONSOLE=y
+CONFIG_TTY_PRINTK=y
+CONFIG_VIRTIO_CONSOLE=y
+CONFIG_IPMI_HANDLER=y
+CONFIG_IPMI_DEVICE_INTERFACE=m
+CONFIG_IPMI_SI=m
+CONFIG_IPMI_WATCHDOG=m
+CONFIG_IPMI_POWEROFF=m
+CONFIG_HW_RANDOM=y
+CONFIG_HW_RANDOM_TIMERIOMEM=m
+CONFIG_HW_RANDOM_VIRTIO=m
+CONFIG_HW_RANDOM_TPM=m
+CONFIG_TCG_TIS_I2C_ATMEL=m
+CONFIG_TCG_TIS_I2C_INFINEON=m
+CONFIG_TCG_TIS_I2C_NUVOTON=m
+CONFIG_TCG_ATMEL=m
+CONFIG_I2C_CHARDEV=m
+CONFIG_I2C_MUX_PCA9541=m
+CONFIG_I2C_DESIGNWARE_PLATFORM=m
+CONFIG_I2C_OCORES=m
+CONFIG_I2C_PCA_PLATFORM=m
+CONFIG_I2C_SIMTEC=m
+CONFIG_I2C_XILINX=m
+CONFIG_I2C_PARPORT_LIGHT=m
+CONFIG_I2C_TAOS_EVM=m
+CONFIG_I2C_STUB=m
+CONFIG_PPS_CLIENT_LDISC=m
+CONFIG_PPS_CLIENT_GPIO=m
+CONFIG_PTP_1588_CLOCK=y
+CONFIG_POWER_RESET=y
+# CONFIG_HWMON is not set
+CONFIG_SSB=m
+CONFIG_BCMA=m
+CONFIG_BCMA_HOST_SOC=y
+CONFIG_BCMA_DRIVER_GMAC_CMN=y
+CONFIG_MFD_SYSCON=y
+CONFIG_MEDIA_SUPPORT=y
+CONFIG_MEDIA_CAMERA_SUPPORT=y
+CONFIG_MEDIA_USB_SUPPORT=y
+CONFIG_USB_VIDEO_CLASS=y
+# CONFIG_USB_GSPCA is not set
+CONFIG_BACKLIGHT_LCD_SUPPORT=y
+CONFIG_LCD_PLATFORM=m
+CONFIG_BACKLIGHT_CLASS_DEVICE=y
+CONFIG_BACKLIGHT_GENERIC=m
+CONFIG_BACKLIGHT_ADP8860=m
+CONFIG_BACKLIGHT_ADP8870=m
+CONFIG_BACKLIGHT_LM3639=m
+CONFIG_BACKLIGHT_LV5207LP=m
+CONFIG_BACKLIGHT_BD6107=m
+# CONFIG_VGA_CONSOLE is not set
+# CONFIG_HID_GENERIC is not set
+CONFIG_HID_A4TECH=m
+CONFIG_HID_ACRUX=m
+CONFIG_HID_ACRUX_FF=y
+CONFIG_HID_APPLE=m
+CONFIG_HID_AUREAL=m
+CONFIG_HID_BELKIN=m
+CONFIG_HID_CHERRY=m
+CONFIG_HID_CHICONY=m
+CONFIG_HID_CYPRESS=m
+CONFIG_HID_DRAGONRISE=m
+CONFIG_DRAGONRISE_FF=y
+CONFIG_HID_EMS_FF=m
+CONFIG_HID_ELECOM=m
+CONFIG_HID_EZKEY=m
+CONFIG_HID_KEYTOUCH=m
+CONFIG_HID_KYE=m
+CONFIG_HID_WALTOP=m
+CONFIG_HID_GYRATION=m
+CONFIG_HID_ICADE=m
+CONFIG_HID_TWINHAN=m
+CONFIG_HID_KENSINGTON=m
+CONFIG_HID_LCPOWER=m
+CONFIG_HID_LOGITECH=m
+CONFIG_HID_LOGITECH_HIDPP=m
+CONFIG_LOGITECH_FF=y
+CONFIG_LOGIRUMBLEPAD2_FF=y
+CONFIG_LOGIG940_FF=y
+CONFIG_HID_MAGICMOUSE=m
+CONFIG_HID_MICROSOFT=m
+CONFIG_HID_MONTEREY=m
+CONFIG_HID_MULTITOUCH=m
+CONFIG_HID_ORTEK=m
+CONFIG_HID_PANTHERLORD=m
+CONFIG_PANTHERLORD_FF=y
+CONFIG_HID_PETALYNX=m
+CONFIG_HID_PICOLCD=m
+CONFIG_HID_PICOLCD_BACKLIGHT=y
+CONFIG_HID_PICOLCD_LCD=y
+CONFIG_HID_PICOLCD_LEDS=y
+CONFIG_HID_PRIMAX=m
+CONFIG_HID_SAITEK=m
+CONFIG_HID_SAMSUNG=m
+CONFIG_HID_SPEEDLINK=m
+CONFIG_HID_STEELSERIES=m
+CONFIG_HID_SUNPLUS=m
+CONFIG_HID_RMI=m
+CONFIG_HID_GREENASIA=m
+CONFIG_GREENASIA_FF=y
+CONFIG_HID_SMARTJOYPLUS=m
+CONFIG_SMARTJOYPLUS_FF=y
+CONFIG_HID_TIVO=m
+CONFIG_HID_TOPSEED=m
+CONFIG_HID_THINGM=m
+CONFIG_HID_THRUSTMASTER=m
+CONFIG_THRUSTMASTER_FF=y
+CONFIG_HID_WACOM=m
+CONFIG_HID_WIIMOTE=m
+CONFIG_HID_XINMO=m
+CONFIG_HID_ZEROPLUS=m
+CONFIG_ZEROPLUS_FF=y
+CONFIG_HID_ZYDACRON=m
+CONFIG_HID_SENSOR_HUB=m
+CONFIG_I2C_HID=m
+CONFIG_USB=y
+CONFIG_USB_EHCI_HCD=y
+CONFIG_USB_EHCI_HCD_PLATFORM=y
+CONFIG_USB_OHCI_HCD=y
+CONFIG_USB_STORAGE=y
+CONFIG_LEDS_CLASS=y
+CONFIG_LEDS_LM3530=m
+CONFIG_LEDS_LM3642=m
+CONFIG_LEDS_PCA9532=m
+CONFIG_LEDS_LP3944=m
+CONFIG_LEDS_LP5521=m
+CONFIG_LEDS_LP5523=m
+CONFIG_LEDS_LP5562=m
+CONFIG_LEDS_LP8501=m
+CONFIG_LEDS_PCA955X=m
+CONFIG_LEDS_PCA963X=m
+CONFIG_LEDS_BD2802=m
+CONFIG_LEDS_TCA6507=m
+CONFIG_LEDS_LM355x=m
+CONFIG_LEDS_BLINKM=m
+CONFIG_LEDS_TRIGGER_TIMER=m
+CONFIG_LEDS_TRIGGER_ONESHOT=m
+CONFIG_LEDS_TRIGGER_HEARTBEAT=m
+CONFIG_LEDS_TRIGGER_BACKLIGHT=m
+CONFIG_LEDS_TRIGGER_CPU=y
+CONFIG_LEDS_TRIGGER_DEFAULT_ON=m
+CONFIG_LEDS_TRIGGER_TRANSIENT=m
+CONFIG_LEDS_TRIGGER_CAMERA=m
+CONFIG_VIRTIO_BALLOON=y
+CONFIG_VIRTIO_MMIO=y
+CONFIG_VIRTIO_MMIO_CMDLINE_DEVICES=y
+CONFIG_ARM_TIMER_SP804=y
+# CONFIG_IOMMU_SUPPORT is not set
+CONFIG_STE_MODEM_RPROC=m
+CONFIG_PM_DEVFREQ=y
+CONFIG_DEVFREQ_GOV_SIMPLE_ONDEMAND=y
+CONFIG_DEVFREQ_GOV_PERFORMANCE=y
+CONFIG_DEVFREQ_GOV_POWERSAVE=y
+CONFIG_DEVFREQ_GOV_USERSPACE=y
+CONFIG_RESET_CONTROLLER=y
+CONFIG_EXT2_FS=y
+CONFIG_EXT2_FS_XATTR=y
+CONFIG_EXT2_FS_POSIX_ACL=y
+CONFIG_EXT2_FS_SECURITY=y
+CONFIG_EXT3_FS=y
+CONFIG_EXT3_FS_POSIX_ACL=y
+CONFIG_EXT3_FS_SECURITY=y
+CONFIG_FANOTIFY=y
+CONFIG_FANOTIFY_ACCESS_PERMISSIONS=y
+CONFIG_QUOTA=y
+CONFIG_QUOTA_NETLINK_INTERFACE=y
+# CONFIG_PRINT_QUOTA_WARNING is not set
+CONFIG_FSCACHE=m
+CONFIG_FSCACHE_STATS=y
+CONFIG_CACHEFILES=m
+CONFIG_MSDOS_FS=y
+CONFIG_VFAT_FS=y
+CONFIG_FAT_DEFAULT_UTF8=y
+CONFIG_NTFS_FS=y
+CONFIG_PROC_KCORE=y
+CONFIG_PROC_CHILDREN=y
+CONFIG_TMPFS=y
+CONFIG_TMPFS_POSIX_ACL=y
+CONFIG_CONFIGFS_FS=y
+CONFIG_CRAMFS=y
+CONFIG_ROMFS_FS=y
+CONFIG_NFS_FS=y
+CONFIG_ROOT_NFS=y
+CONFIG_NLS_DEFAULT="utf8"
+CONFIG_NLS_CODEPAGE_437=y
+CONFIG_NLS_CODEPAGE_737=y
+CONFIG_NLS_CODEPAGE_775=y
+CONFIG_NLS_CODEPAGE_850=y
+CONFIG_NLS_CODEPAGE_852=y
+CONFIG_NLS_CODEPAGE_855=y
+CONFIG_NLS_CODEPAGE_857=y
+CONFIG_NLS_CODEPAGE_860=y
+CONFIG_NLS_CODEPAGE_861=y
+CONFIG_NLS_CODEPAGE_863=y
+CONFIG_NLS_CODEPAGE_864=y
+CONFIG_NLS_CODEPAGE_865=y
+CONFIG_NLS_CODEPAGE_866=y
+CONFIG_NLS_CODEPAGE_869=y
+CONFIG_NLS_CODEPAGE_936=y
+CONFIG_NLS_CODEPAGE_950=y
+CONFIG_NLS_CODEPAGE_932=y
+CONFIG_NLS_CODEPAGE_949=m
+CONFIG_NLS_CODEPAGE_874=m
+CONFIG_NLS_ISO8859_8=m
+CONFIG_NLS_CODEPAGE_1250=y
+CONFIG_NLS_CODEPAGE_1251=y
+CONFIG_NLS_ASCII=m
+CONFIG_NLS_ISO8859_1=y
+CONFIG_NLS_ISO8859_2=m
+CONFIG_NLS_ISO8859_3=m
+CONFIG_NLS_ISO8859_4=m
+CONFIG_NLS_ISO8859_5=m
+CONFIG_NLS_ISO8859_6=m
+CONFIG_NLS_ISO8859_7=m
+CONFIG_NLS_ISO8859_9=m
+CONFIG_NLS_ISO8859_13=m
+CONFIG_NLS_ISO8859_14=m
+CONFIG_NLS_ISO8859_15=m
+CONFIG_NLS_KOI8_R=m
+CONFIG_NLS_KOI8_U=m
+CONFIG_NLS_MAC_ROMAN=m
+CONFIG_NLS_MAC_CELTIC=m
+CONFIG_NLS_MAC_CENTEURO=m
+CONFIG_NLS_MAC_CROATIAN=m
+CONFIG_NLS_MAC_CYRILLIC=m
+CONFIG_NLS_MAC_GAELIC=m
+CONFIG_NLS_MAC_GREEK=m
+CONFIG_NLS_MAC_ICELAND=m
+CONFIG_NLS_MAC_INUIT=m
+CONFIG_NLS_MAC_ROMANIAN=m
+CONFIG_NLS_MAC_TURKISH=m
+CONFIG_NLS_UTF8=y
+CONFIG_PRINTK_TIME=y
+# CONFIG_ENABLE_WARN_DEPRECATED is not set
+# CONFIG_ENABLE_MUST_CHECK is not set
+CONFIG_UNUSED_SYMBOLS=y
+CONFIG_DEBUG_FS=y
+CONFIG_MAGIC_SYSRQ=y
+CONFIG_LOCKUP_DETECTOR=y
+# CONFIG_SCHED_DEBUG is not set
+CONFIG_RBTREE_TEST=m
+CONFIG_INTERVAL_TREE_TEST=m
+CONFIG_PERCPU_TEST=m
+CONFIG_TEST_STRING_HELPERS=m
+CONFIG_TEST_KSTRTOX=m
+CONFIG_PERSISTENT_KEYRINGS=y
+CONFIG_TRUSTED_KEYS=y
+CONFIG_SECURITY=y
+CONFIG_SECURITY_NETWORK=y
+CONFIG_SECURITY_PATH=y
+CONFIG_SECURITY_YAMA=y
+CONFIG_INTEGRITY_SIGNATURE=y
+CONFIG_INTEGRITY_ASYMMETRIC_KEYS=y
+CONFIG_IMA=y
+CONFIG_IMA_APPRAISE=y
+CONFIG_EVM=y
+CONFIG_CRYPTO_CRYPTD=m
+CONFIG_CRYPTO_AUTHENC=m
+CONFIG_CRYPTO_TEST=m
+CONFIG_CRYPTO_CCM=m
+CONFIG_CRYPTO_GCM=m
+CONFIG_CRYPTO_CTS=m
+CONFIG_CRYPTO_ECB=y
+CONFIG_CRYPTO_LRW=m
+CONFIG_CRYPTO_PCBC=m
+CONFIG_CRYPTO_XTS=m
+CONFIG_CRYPTO_CMAC=m
+CONFIG_CRYPTO_XCBC=m
+CONFIG_CRYPTO_VMAC=m
+CONFIG_CRYPTO_CRC32=m
+CONFIG_CRYPTO_MD4=m
+CONFIG_CRYPTO_MICHAEL_MIC=m
+CONFIG_CRYPTO_RMD128=m
+CONFIG_CRYPTO_RMD160=m
+CONFIG_CRYPTO_RMD256=m
+CONFIG_CRYPTO_RMD320=m
+CONFIG_CRYPTO_SHA512=y
+CONFIG_CRYPTO_TGR192=m
+CONFIG_CRYPTO_WP512=m
+CONFIG_CRYPTO_ANUBIS=m
+CONFIG_CRYPTO_ARC4=m
+CONFIG_CRYPTO_BLOWFISH=m
+CONFIG_CRYPTO_CAMELLIA=m
+CONFIG_CRYPTO_CAST5=m
+CONFIG_CRYPTO_CAST6=m
+CONFIG_CRYPTO_DES=m
+CONFIG_CRYPTO_FCRYPT=m
+CONFIG_CRYPTO_KHAZAD=m
+CONFIG_CRYPTO_SALSA20=m
+CONFIG_CRYPTO_SEED=m
+CONFIG_CRYPTO_SERPENT=m
+CONFIG_CRYPTO_TEA=m
+CONFIG_CRYPTO_TWOFISH=m
+CONFIG_CRYPTO_DEFLATE=m
+CONFIG_CRYPTO_LZO=y
+CONFIG_CRYPTO_LZ4=m
+CONFIG_CRYPTO_LZ4HC=m
+CONFIG_CRYPTO_ANSI_CPRNG=m
+CONFIG_CRC_CCITT=m
+CONFIG_CRC7=m
+CONFIG_LIBCRC32C=m
+CONFIG_CRC8=m
+CONFIG_XZ_DEC_TEST=m
+CONFIG_CORDIC=m
+CONFIG_DDR=y
diff --git a/arch/csky/include/asm/Kbuild b/arch/csky/include/asm/Kbuild
new file mode 100644
index 0000000..82e4621
--- /dev/null
+++ b/arch/csky/include/asm/Kbuild
@@ -0,0 +1,68 @@
+generic-y += asm-offsets.h
+generic-y += atomic.h
+generic-y += auxvec.h
+generic-y += bitsperlong.h
+generic-y += bug.h
+generic-y += bugs.h
+generic-y += clkdev.h
+generic-y += cmpxchg.h
+generic-y += cputime.h
+generic-y += current.h
+generic-y += delay.h
+generic-y += device.h
+generic-y += div64.h
+generic-y += dma.h
+generic-y += emergency-restart.h
+generic-y += errno.h
+generic-y += exec.h
+generic-y += fb.h
+generic-y += ftrace.h
+generic-y += futex.h
+generic-y += gpio.h
+generic-y += hardirq.h
+generic-y += hw_irq.h
+generic-y += ioctl.h
+generic-y += ioctls.h
+generic-y += irq_regs.h
+generic-y += ipcbuf.h
+generic-y += irq_work.h
+generic-y += kdebug.h
+generic-y += kmap_types.h
+generic-y += kvm_para.h
+generic-y += linkage.h
+generic-y += local.h
+generic-y += local64.h
+generic-y += mman.h
+generic-y += mm-arch-hooks.h
+generic-y += module.h
+generic-y += msgbuf.h
+generic-y += mutex.h
+generic-y += param.h
+generic-y += pci.h
+generic-y += percpu.h
+generic-y += posix_types.h
+generic-y += poll.h
+generic-y += preempt.h
+generic-y += resource.h
+generic-y += scatterlist.h
+generic-y += sections.h
+generic-y += sembuf.h
+generic-y += serial.h
+generic-y += shmbuf.h
+generic-y += shm.h
+generic-y += siginfo.h
+generic-y += sizes.h
+generic-y += socket.h
+generic-y += sockios.h
+generic-y += statfs.h
+generic-y += termbits.h
+generic-y += termios.h
+generic-y += timex.h
+generic-y += topology.h
+generic-y += trace_clock.h
+generic-y += types.h
+generic-y += ucontext.h
+generic-y += unaligned.h
+generic-y += vga.h
+generic-y += vmlinux.lds.h
+generic-y += word-at-a-time.h
diff --git a/arch/csky/include/asm/addrspace.h b/arch/csky/include/asm/addrspace.h
new file mode 100644
index 0000000..69699f3
--- /dev/null
+++ b/arch/csky/include/asm/addrspace.h
@@ -0,0 +1,9 @@
+#ifndef __ASM_CSKY_ADDRSPACE_H
+#define __ASM_CSKY_ADDRSPACE_H
+
+/* Cached for ram */
+#define KSEG0		0x80000000ul
+#define KSEG0ADDR(a)	(((unsigned long)a & 0x1fffffff) | KSEG0)
+
+#endif /* __ASM_CSKY_ADDRSPACE_H */
+
diff --git a/arch/csky/include/asm/barrier.h b/arch/csky/include/asm/barrier.h
new file mode 100644
index 0000000..9c12f7e
--- /dev/null
+++ b/arch/csky/include/asm/barrier.h
@@ -0,0 +1,12 @@
+#ifndef __ASM_CSKY_BARRIER_H
+#define __ASM_CSKY_BARRIER_H
+
+#ifndef __ASSEMBLY__
+
+#define nop()	__asm__ __volatile__ ("nop")
+#define mb()	__asm__ __volatile__ ("sync" :::"memory")
+
+#include <asm-generic/barrier.h>
+
+#endif /* __ASSEMBLY__ */
+#endif /* __ASM_CSKY_BARRIER_H */
diff --git a/arch/csky/include/asm/bitops.h b/arch/csky/include/asm/bitops.h
new file mode 100644
index 0000000..3e4c7c5
--- /dev/null
+++ b/arch/csky/include/asm/bitops.h
@@ -0,0 +1,81 @@
+#ifndef __ASM_CSKY_BITOPS_H
+#define __ASM_CSKY_BITOPS_H
+
+#include <linux/irqflags.h>
+#include <linux/compiler.h>
+#include <asm/barrier.h>
+
+/*
+ * asm-generic/bitops/ffs.h
+ */
+static inline int ffs(int x)
+{
+	if(!x) return 0;
+
+	__asm__ __volatile__ (
+			"brev %0\n\t"
+			"ff1  %0\n\t"
+			"addi %0, 1\n\t"
+			: "=r"(x)
+			: "0"(x));
+	return x;
+}
+
+/*
+ * asm-generic/bitops/__ffs.h
+ */
+static __always_inline unsigned long __ffs(unsigned long x)
+{
+	__asm__ __volatile__ (
+			"brev %0\n\t"
+			"ff1  %0\n\t"
+			: "=r"(x)
+			: "0"(x));
+	return x;
+}
+
+/*
+ * asm-generic/bitops/fls.h
+ */
+static __always_inline int fls(int x)
+{
+	__asm__ __volatile__(
+			"ff1 %0\n\t"
+			:"=r" (x)
+			:"0" (x));
+
+	return (32 - x);
+}
+
+/*
+ * asm-generic/bitops/__fls.h
+ */
+static __always_inline unsigned long __fls(unsigned long x)
+{
+	return fls(x) - 1;
+}
+
+#include <asm-generic/bitops/ffz.h>
+#include <asm-generic/bitops/fls64.h>
+#include <asm-generic/bitops/find.h>
+
+#ifndef _LINUX_BITOPS_H
+#error only <linux/bitops.h> can be included directly
+#endif
+
+#include <asm-generic/bitops/sched.h>
+#include <asm-generic/bitops/hweight.h>
+#include <asm-generic/bitops/lock.h>
+
+#include <asm-generic/bitops/atomic.h>
+
+/*
+ * bug fix, why only could use atomic!!!!
+ */
+#include <asm-generic/bitops/non-atomic.h>
+#define __clear_bit(nr,vaddr) clear_bit(nr,vaddr)
+
+#include <asm-generic/bitops/le.h>
+#include <asm-generic/bitops/ext2-atomic.h>
+#endif /* __ASM_CSKY_BITOPS_H */
+
diff --git a/arch/csky/include/asm/byteorder.h b/arch/csky/include/asm/byteorder.h
new file mode 100644
index 0000000..077fd0a
--- /dev/null
+++ b/arch/csky/include/asm/byteorder.h
@@ -0,0 +1,12 @@
+#ifndef __ASM_CSKY_BYTEORDER_H
+#define __ASM_CSKY_BYTEORDER_H
+
+#if defined(__cskyBE__)
+#include <linux/byteorder/big_endian.h>
+#elif defined(__cskyLE__)
+#include <linux/byteorder/little_endian.h>
+#else
+# error "csky, but neither __cskyBE__, nor __cskyLE__???"
+#endif
+
+#endif /* __ASM_CSKY_BYTEORDER_H */
diff --git a/arch/csky/include/asm/cache.h b/arch/csky/include/asm/cache.h
new file mode 100644
index 0000000..c4ed5db
--- /dev/null
+++ b/arch/csky/include/asm/cache.h
@@ -0,0 +1,51 @@
+#ifndef __ASM_CSKY_CACHE_H
+#define __ASM_CSKY_CACHE_H
+
+/* bytes per L1 cache line */
+#ifdef	__CSKYABIV1__
+#define L1_CACHE_SHIFT	4
+#else
+#define L1_CACHE_SHIFT	5
+#endif
+#define L1_CACHE_BYTES		(1 << L1_CACHE_SHIFT)
+
+/* for cr17 */
+#define INS_CACHE		(1 << 0)
+#define DATA_CACHE		(1 << 1)
+#define CACHE_INV		(1 << 4)
+#define CACHE_CLR		(1 << 5)
+#define CACHE_OMS		(1 << 6)
+#define CACHE_ITS		(1 << 7)
+#define CACHE_LICF		(1 << 31)
+
+/* for cr22 */
+#define CR22_LEVEL_SHIFT        (1)
+#define CR22_SET_SHIFT		(7)
+#define CR22_WAY_SHIFT          (30)
+#define CR22_WAY_SHIFT_L2	(29)
+
+#define ARCH_DMA_MINALIGN	L1_CACHE_BYTES
+
+#ifndef __ASSEMBLY__
+
+void cache_op_l2enable(void);
+
+void cache_op_line(
+	unsigned int i,
+	unsigned int value
+	);
+
+void cache_op_all(
+	unsigned int value,
+	unsigned int l2
+	);
+
+void cache_op_range(
+	unsigned int start,
+	unsigned int end,
+	unsigned int value,
+	unsigned int l2
+	);
+#endif
+
+#endif  /* __ASM_CSKY_CACHE_H */
diff --git a/arch/csky/include/asm/cacheflush.h b/arch/csky/include/asm/cacheflush.h
new file mode 100644
index 0000000..a94f369
--- /dev/null
+++ b/arch/csky/include/asm/cacheflush.h
@@ -0,0 +1,7 @@
+#ifndef __ASM_CSKY_CACHEFLUSH_H
+#define __ASM_CSKY_CACHEFLUSH_H
+
+#include <abi/cacheflush.h>
+
+#endif /* __ASM_CSKY_CACHEFLUSH_H */
+
diff --git a/arch/csky/include/asm/checksum.h b/arch/csky/include/asm/checksum.h
new file mode 100644
index 0000000..8b9d2bb
--- /dev/null
+++ b/arch/csky/include/asm/checksum.h
@@ -0,0 +1,73 @@
+#ifndef __ASM_CSKY_CHECKSUM_H
+#define __ASM_CSKY_CHECKSUM_H
+
+#include <linux/in6.h>
+#include <asm/byteorder.h>
+
+static inline __sum16 csum_fold(__wsum csum)
+{
+	u32 tmp;
+	__asm__ __volatile__("mov     %1, %0 \n\t"
+			"rori    %0, 16 \n\t"
+			"addu    %0, %1 \n\t"
+			"lsri    %0, 16 \n\t"
+			:"=r"(csum), "=r"(tmp)
+			:"0"(csum));
+	return (__force __sum16)~csum;
+}
+#define csum_fold csum_fold
+
+static inline __wsum
+csum_tcpudp_nofold(
+	__be32 saddr,
+	__be32 daddr,
+	unsigned short len,
+	unsigned short proto,
+	__wsum sum
+	)
+{
+	__asm__ __volatile__("clrc  \n\t"
+			"addc    %0, %1 \n\t"
+			"addc    %0, %2 \n\t"
+			"addc    %0, %3 \n\t"
+			"inct    %0 \n\t"
+			:"=r"(sum)
+			:"r"((__force u32)saddr),
+			"r"((__force u32)daddr),
+#ifdef __BIG_ENDIAN
+			"r"(proto + len),
+#else
+			"r"((proto + len) << 8),
+#endif
+			"0" ((__force unsigned long)sum)
+			:"cc");
+	return sum;
+}
+#define csum_tcpudp_nofold csum_tcpudp_nofold
+
+static __inline__ __sum16
+csum_ipv6_magic(
+	const struct in6_addr *saddr,
+	const struct in6_addr *daddr,
+	__u32 len,
+	unsigned short proto,
+	__wsum sum
+	)
+{
+	sum += saddr->in6_u.u6_addr32[0];
+	sum += saddr->in6_u.u6_addr32[1];
+	sum += saddr->in6_u.u6_addr32[2];
+	sum += saddr->in6_u.u6_addr32[3];
+	sum += daddr->in6_u.u6_addr32[0];
+	sum += daddr->in6_u.u6_addr32[1];
+	sum += daddr->in6_u.u6_addr32[2];
+	sum += daddr->in6_u.u6_addr32[3];
+	sum += (len + proto);
+
+	return csum_fold(sum);
+}
+#define _HAVE_ARCH_IPV6_CSUM
+
+#include <asm-generic/checksum.h>
+
+#endif /* __ASM_CSKY_CHECKSUM_H */
diff --git a/arch/csky/include/asm/cpu.h b/arch/csky/include/asm/cpu.h
new file mode 100644
index 0000000..2d06a24
--- /dev/null
+++ b/arch/csky/include/asm/cpu.h
@@ -0,0 +1,55 @@
+#ifndef __ASM_CSKY_CPU_H
+#define __ASM_CSKY_CPU_H
+
+/* 
+  Rev2
+  +--------+-------+---------+------------+----------+----------------+
+  | Family | Model | Foundry |   Process  | Revision |  Version
+  +--------+-------+---------+------------+----------+----------------+
+   31    28 27   16 15     12 11         8 7        4 3
+
+  Rev3
+  +--------+-------+---------+--------+---------+----------+----------+
+  | Index0 | Arch  | Family  | Class  |  Model  | Revision |  Version
+  +--------+-------+---------+--------+---------+----------+----------+
+   31    28 27   26 25     22 21    18 17      8 7        4 3
+*/
+
+#define CPUPID_UNKNOWN            0x0000
+
+#define CPUID_VER_2               0x0002
+#define CPUID_VER_3               0x0003
+
+/* V2 */
+#define	CPU_UNKNOWN               0x0000
+#define CPU_CK600                 0x0002
+#define CPU_CK800                 0x0003
+
+#define CPUID_FPU_NONE            0x0000
+#define CPUID_FPU_V2              0x0002
+
+#define CPUID_V2_FAMILY_CK500     0x00000000
+#define CPUID_V2_FAMILY_CK600     0x10000000
+
+#define CPUID_V2_MODEL_MMU        0x00080000
+#define CPUID_V2_MODEL_FPU        0x00100000
+#define CPUID_V2_MODEL_AXI        0x00200000
+
+/* V3 */
+#define CPUID_V3_FAMILY_CK500     0x00000000
+#define CPUID_V3_FAMILY_CK600     0x00400000
+#define CPUID_V3_FAMILY_CK800     0x00800000
+
+#define CPUID_V3_CLASS_CK810      0x00040000
+#define CPUID_V3_CLASS_CK807      0x000c0000
+
+#define CPUID_V3_MODEL_DM         0x00000100
+#define CPUID_V3_MODEL_MMU        0x00000200
+#define CPUID_V3_MODEL_FPU        0x00000400
+#define CPUID_V3_MODEL_SPM        0x00000800
+#define CPUID_V3_MODEL_MGU        0x00001000
+#define CPUID_V3_MODEL_BCTM       0x00002000
+#define CPUID_V3_MODEL_VDSP       0x00004000
+
+#endif /* __ASM_CSKY_CPU_H */
+
diff --git a/arch/csky/include/asm/dma-mapping.h b/arch/csky/include/asm/dma-mapping.h
new file mode 100644
index 0000000..3831516
--- /dev/null
+++ b/arch/csky/include/asm/dma-mapping.h
@@ -0,0 +1,11 @@
+#ifndef __ASM_DMA_MAPPING_H
+#define __ASM_DMA_MAPPING_H
+
+extern struct dma_map_ops csky_dma_map_ops;
+
+static inline struct dma_map_ops *get_dma_ops(struct device *dev)
+{
+	return &csky_dma_map_ops;
+}
+
+#endif /* __ASM_DMA_MAPPING_H */
diff --git a/arch/csky/include/asm/elf.h b/arch/csky/include/asm/elf.h
new file mode 100644
index 0000000..fe3edd2
--- /dev/null
+++ b/arch/csky/include/asm/elf.h
@@ -0,0 +1,149 @@
+#ifndef __ASMCSKY_ELF_H
+#define __ASMCSKY_ELF_H
+
+/*
+ * ELF register definitions..
+ */
+
+#include <asm/ptrace.h>
+#include <asm/user.h>
+#include <abi/regdef.h>
+
+#define ELF_ARCH 39
+
+/* CSKY Relocations */
+#define R_CSKY_NONE               0
+#define R_CSKY_32                 1
+#define R_CSKY_PCIMM8BY4          2
+#define R_CSKY_PCIMM11BY2         3
+#define R_CSKY_PCIMM4BY2          4
+#define R_CSKY_PC32               5
+#define R_CSKY_PCRELJSR_IMM11BY2  6
+#define R_CSKY_GNU_VTINHERIT      7
+#define R_CSKY_GNU_VTENTRY        8
+#define R_CSKY_RELATIVE           9
+#define R_CSKY_COPY               10
+#define R_CSKY_GLOB_DAT           11
+#define R_CSKY_JUMP_SLOT          12
+#define R_CSKY_ADDR_HI16          24
+#define R_CSKY_ADDR_LO16          25
+#define R_CSKY_PCRELJSR_IMM26BY2  40
+
+typedef unsigned long elf_greg_t;
+
+
+#define ELF_NGREG (sizeof(struct pt_regs) / sizeof(elf_greg_t))
+
+typedef elf_greg_t elf_gregset_t[ELF_NGREG];
+
+typedef struct user_cskyfp_struct elf_fpregset_t;
+
+/*
+ * This is used to ensure we don't load something for the wrong architecture.
+ */
+#define elf_check_arch(x) ((x)->e_machine == ELF_ARCH)
+
+/*
+ * These are used to set parameters in the core dumps.
+ */
+#define USE_ELF_CORE_DUMP
+#define ELF_EXEC_PAGESIZE		4096
+#define ELF_CLASS			ELFCLASS32
+#define ELF_PLAT_INIT(_r, load_addr)	_r->a0 = 0
+
+#ifdef  __cskyBE__
+#define ELF_DATA	ELFDATA2MSB
+#else
+#define ELF_DATA	ELFDATA2LSB
+#endif
+
+/* This is the location that an ET_DYN program is loaded if exec'ed.  Typical
+   use of this is to invoke "./ld.so someprog" to test out a new version of
+   the loader.  We need to make sure that it is out of the way of the program
+   that it will "exec", and that there is sufficient room for the brk.  */
+
+#define ELF_ET_DYN_BASE	0x0UL
+
+/* The member sort in array pr_reg[x] is pc, r1, r0, psr, r2, r3,r4,
+   r5, r6...... Because GDB difine */
+#if defined(__CSKYABIV2__)
+   #define ELF_CORE_COPY_REGS(pr_reg, regs)     \
+        pr_reg[0] = regs->pc;                   \
+        pr_reg[1] = regs->a1;                   \
+        pr_reg[2] = regs->a0;                   \
+        pr_reg[3] = regs->sr;                   \
+        pr_reg[4] = regs->a2;                   \
+        pr_reg[5] = regs->a3;                   \
+        pr_reg[6] = regs->regs[0];              \
+        pr_reg[7] = regs->regs[1];              \
+        pr_reg[8] = regs->regs[2];              \
+        pr_reg[9] = regs->regs[3];              \
+        pr_reg[10] = regs->regs[4];             \
+        pr_reg[11] = regs->regs[5];             \
+        pr_reg[12] = regs->regs[6];             \
+        pr_reg[13] = regs->regs[7];             \
+        pr_reg[14] = regs->regs[8];             \
+        pr_reg[15] = regs->regs[9];             \
+        pr_reg[16] = rdusp();		        \
+        pr_reg[17] = regs->r15;                 \
+        pr_reg[18] = regs->exregs[0];           \
+        pr_reg[19] = regs->exregs[1];           \
+        pr_reg[20] = regs->exregs[2];           \
+        pr_reg[21] = regs->exregs[3];           \
+        pr_reg[22] = regs->exregs[4];           \
+        pr_reg[23] = regs->exregs[5];           \
+        pr_reg[24] = regs->exregs[6];           \
+        pr_reg[25] = regs->exregs[7];           \
+        pr_reg[26] = regs->exregs[8];           \
+        pr_reg[27] = regs->exregs[9];           \
+        pr_reg[28] = regs->exregs[10];          \
+        pr_reg[29] = regs->exregs[11];          \
+        pr_reg[30] = regs->exregs[12];          \
+        pr_reg[31] = regs->exregs[13];          \
+        pr_reg[32] = regs->exregs[14];          \
+        pr_reg[33] = regs->exregs[15];
+#else
+     #define ELF_CORE_COPY_REGS(pr_reg, regs)   \
+        pr_reg[0] = regs->pc;                   \
+        pr_reg[1] = regs->regs[9];              \
+        pr_reg[2] = rdusp();                    \
+        pr_reg[3] = regs->sr;                   \
+        pr_reg[4] = regs->a0;                   \
+        pr_reg[5] = regs->a1;                   \
+        pr_reg[6] = regs->a2;                   \
+        pr_reg[7] = regs->a3;                   \
+        pr_reg[8] = regs->regs[0];              \
+        pr_reg[9] = regs->regs[1];              \
+        pr_reg[10] = regs->regs[2];             \
+        pr_reg[11] = regs->regs[3];             \
+        pr_reg[12] = regs->regs[4];             \
+        pr_reg[13] = regs->regs[5];             \
+        pr_reg[14] = regs->regs[6];             \
+        pr_reg[15] = regs->regs[7];             \
+        pr_reg[16] = regs->regs[8];             \
+        pr_reg[17] = regs->r15;
+#endif
+
+/* Similar, but for a thread other than current. */
+struct task_struct;
+extern int dump_task_regs(struct task_struct *, elf_gregset_t *);
+#define ELF_CORE_COPY_TASK_REGS(tsk, elf_regs) dump_task_regs(tsk, elf_regs)
+
+/* This yields a mask that user programs can use to figure out what
+   instruction set this cpu supports.  */
+
+#define ELF_HWCAP	(0)
+
+/* This yields a string that ld.so will use to load implementation
+   specific libraries for optimization.  This is more specific in
+   intent than poking at uname or /proc/cpuinfo.  */
+
+#define ELF_PLATFORM	(NULL)
+#define SET_PERSONALITY(ex) set_personality(PER_LINUX)
+#define ARCH_HAS_SETUP_ADDITIONAL_PAGES 1
+struct linux_binprm;
+extern int arch_setup_additional_pages(
+		struct linux_binprm *bprm,
+		int uses_interp);
+
+#endif
diff --git a/arch/csky/include/asm/fcntl.h b/arch/csky/include/asm/fcntl.h
new file mode 100644
index 0000000..5e52b66
--- /dev/null
+++ b/arch/csky/include/asm/fcntl.h
@@ -0,0 +1,11 @@
+#ifndef __ASM_CSKY_FCNTL_H
+#define __ASM_CSKY_FCNTL_H
+
+#define O_DIRECTORY	040000
+#define O_NOFOLLOW	0100000
+#define O_DIRECT	0200000
+#define O_LARGEFILE	0400000
+
+#include <asm-generic/fcntl.h>
+
+#endif /* __ASM_CSKY_FCNTL_H */
diff --git a/arch/csky/include/asm/fixmap.h b/arch/csky/include/asm/fixmap.h
new file mode 100644
index 0000000..7649a73
--- /dev/null
+++ b/arch/csky/include/asm/fixmap.h
@@ -0,0 +1,63 @@
+#ifndef __ASM_CSKY_FIXMAP_H
+#define __ASM_CSKY_FIXMAP_H
+
+#include <asm/page.h>
+#ifdef CONFIG_HIGHMEM
+#include <linux/threads.h>
+#include <asm/kmap_types.h>
+#endif
+
+/*
+ * Here we define all the compile-time 'special' virtual
+ * addresses. The point is to have a constant address at
+ * compile time, but to set the physical address only
+ * in the boot process. We allocate these special  addresses
+ * from the end of virtual memory (0xfffff000) backwards.
+ * Also this lets us do fail-safe vmalloc(), we
+ * can guarantee that these special addresses and
+ * vmalloc()-ed addresses never overlap.
+ *
+ * these 'compile-time allocated' memory buffers are
+ * fixed-size 4k pages. (or larger if used with an increment
+ * highger than 1) use fixmap_set(idx,phys) to associate
+ * physical memory with fixmap indices.
+ *
+ * TLB entries of such buffers will not be flushed across
+ * task switches.
+ */
+
+/*
+ * on UP currently we will have no trace of the fixmap mechanizm,
+ * no page table allocations, etc. This might change in the
+ * future, say framebuffers for the console driver(s) could be
+ * fix-mapped?
+ */
+enum fixed_addresses {
+#define FIX_N_COLOURS 8
+	FIX_CMAP_BEGIN,
+	FIX_CMAP_END = FIX_CMAP_BEGIN + (FIX_N_COLOURS * 2),
+#ifdef CONFIG_HIGHMEM
+	/* reserved pte's for temporary kernel mappings */
+	FIX_KMAP_BEGIN = FIX_CMAP_END + 1,
+	FIX_KMAP_END = FIX_KMAP_BEGIN+(KM_TYPE_NR*NR_CPUS)-1,
+#endif
+	__end_of_fixed_addresses
+};
+
+/*
+ * used by vmalloc.c.
+ *
+ * Leave one empty page between vmalloc'ed areas and
+ * the start of the fixmap, and leave one page empty
+ * at the top of mem..
+ */
+#define FIXADDR_TOP	((unsigned long)(long)(int)0xfffe0000)
+#define FIXADDR_SIZE	(__end_of_fixed_addresses << PAGE_SHIFT)
+#define FIXADDR_START	(FIXADDR_TOP - FIXADDR_SIZE)
+
+#include <asm-generic/fixmap.h>
+
+#define kmap_get_fixmap_pte(vaddr) \
+	pte_offset_kernel(pmd_offset(pud_offset(pgd_offset_k(vaddr), (vaddr)), (vaddr)), (vaddr))
+
+#endif /* __ASM_CSKY_FIXMAP_H */
diff --git a/arch/csky/include/asm/flat.h b/arch/csky/include/asm/flat.h
new file mode 100644
index 0000000..554e775
--- /dev/null
+++ b/arch/csky/include/asm/flat.h
@@ -0,0 +1,16 @@
+/*
+ * uClinux
+ */
+
+#ifndef __ASM_CSKY_FLAT_H__
+#define __ASM_CSKY_FLAT_H__
+
+#define	flat_argvp_envp_on_stack()		1
+#define	flat_old_ram_flag(flags)		(flags)
+#define	flat_reloc_valid(reloc, size)		((reloc) <= (size))
+#define flat_get_addr_from_rp(rp, relval, flags, persistent) get_unaligned(rp)
+#define	flat_put_addr_at_rp(rp, val, relval)	put_unaligned(val,rp)
+#define	flat_get_relocate_addr(rel)		(rel)
+#define	flat_set_persistent(relval, p)		0
+
+#endif /* __ASM_CSKY_FLAT_H__ */
diff --git a/arch/csky/include/asm/fpu.h b/arch/csky/include/asm/fpu.h
new file mode 100644
index 0000000..7caf04c
--- /dev/null
+++ b/arch/csky/include/asm/fpu.h
@@ -0,0 +1,284 @@
+#ifndef __ASM_CSKY_FPU_H
+#define __ASM_CSKY_FPU_H
+
+#ifndef __ASSEMBLY__ /* C source */
+
+#include <linux/irqflags.h>
+
+/*
+ * Define the fesr bit for fpe handle.
+ */
+#define  FPE_ILLE  (1 << 16)    /* Illegal instruction  */
+#define  FPE_FEC   (1 << 7)     /* Input float-point arithmetic exception */
+#define  FPE_IDC   (1 << 5)     /* Input denormalized exception */
+#define  FPE_IXC   (1 << 4)     /* Inexact exception */
+#define  FPE_UFC   (1 << 3)     /* Underflow exception */
+#define  FPE_OFC   (1 << 2)     /* Overflow exception */
+#define  FPE_DZC   (1 << 1)     /* Divide by zero exception */
+#define  FPE_IOC   (1 << 0)     /* Invalid operation exception */
+#define  FPE_REGULAR_EXCEPTION (FPE_IXC | FPE_UFC | FPE_OFC | FPE_DZC | FPE_IOC)
+
+#ifdef CONFIG_OPEN_FPU_IDE
+#define IDE_STAT   (1 << 5)
+#else
+#define IDE_STAT   0
+#endif
+
+#ifdef CONFIG_OPEN_FPU_IXE
+#define IXE_STAT   (1 << 4)
+#else
+#define IXE_STAT   0
+#endif
+
+#ifdef CONFIG_OPEN_FPU_UFE
+#define UFE_STAT   (1 << 3)
+#else
+#define UFE_STAT   0
+#endif
+
+#ifdef CONFIG_OPEN_FPU_OFE
+#define OFE_STAT   (1 << 2)
+#else
+#define OFE_STAT   0
+#endif
+
+#ifdef CONFIG_OPEN_FPU_DZE
+#define DZE_STAT   (1 << 1)
+#else
+#define DZE_STAT   0
+#endif
+
+#ifdef CONFIG_OPEN_FPU_IOE
+#define IOE_STAT   (1 << 0)
+#else
+#define IOE_STAT   0
+#endif
+
+#define FMFS_FPU_REGS(frw, frx, fry, frz)       \
+	"fmfs   %0, "#frw" \n\r"        \
+	"fmfs   %1, "#frx" \n\r"        \
+	"fmfs   %2, "#fry" \n\r"        \
+	"fmfs   %3, "#frz" \n\r"
+
+#define FMTS_FPU_REGS(frw, frx, fry, frz)       \
+	"fmts   %0, "#frw" \n\r"        \
+	"fmts   %1, "#frx" \n\r"        \
+	"fmts   %2, "#fry" \n\r"        \
+	"fmts   %3, "#frz" \n\r"
+
+#define FMFVR_FPU_REGS(vrx, vry)        \
+	"fmfvrl %0, "#vrx" \n\r"        \
+	"fmfvrh %1, "#vrx" \n\r"        \
+	"fmfvrl %2, "#vry" \n\r"        \
+	"fmfvrh %3, "#vry" \n\r"
+
+#define FMTVR_FPU_REGS(vrx, vry)        \
+	"fmtvrl "#vrx", %0 \n\r"        \
+	"fmtvrh "#vrx", %1 \n\r"        \
+	"fmtvrl "#vry", %2 \n\r"        \
+	"fmtvrh "#vry", %3 \n\r"
+
+#define STW_FPU_REGS(a, b, c, d)        \
+	"stw    %0, (%4, "#a") \n\r"    \
+	"stw    %1, (%4, "#b") \n\r"    \
+	"stw    %2, (%4, "#c") \n\r"    \
+	"stw    %3, (%4, "#d") \n\r"
+
+#define LDW_FPU_REGS(a, b, c, d)        \
+	"ldw    %0, (%4, "#a") \n\r"    \
+	"ldw    %1, (%4, "#b") \n\r"    \
+	"ldw    %2, (%4, "#c") \n\r"    \
+	"ldw    %3, (%4, "#d") \n\r"
+
+static inline void save_fp_to_thread(unsigned long  * fpregs,
+	   unsigned long * fcr, unsigned long * fsr, unsigned long * fesr)
+{
+#if defined(__CSKYABIV2__)
+	unsigned long flg;
+	unsigned long tmp1, tmp2, tmp3, tmp4;
+
+	local_save_flags(flg);
+
+	__asm__ __volatile__("mfcr    %0, cr<1, 2> \n\r"
+	                     "mfcr    %1, cr<2, 2> \n\r"
+	                     :"+r"(tmp1), "+r"(tmp2) : );
+	*fcr = tmp1;
+	*fsr = 0;      // not use in fpuv2
+	*fesr = tmp2;
+	__asm__ __volatile__(FMFVR_FPU_REGS(vr0, vr1)
+	                     STW_FPU_REGS(0, 4, 8, 12)
+	                     FMFVR_FPU_REGS(vr2, vr3)
+	                     STW_FPU_REGS(16, 20, 24, 28)
+	                     FMFVR_FPU_REGS(vr4, vr5)
+	                     STW_FPU_REGS(32, 36, 40, 44)
+	                     FMFVR_FPU_REGS(vr6, vr7)
+	                     STW_FPU_REGS(48, 52, 56, 60)
+	                     "addi    %4, 32 \n\r"
+	                     "addi    %4, 32 \n\r"
+	                     FMFVR_FPU_REGS(vr8, vr9)
+	                     STW_FPU_REGS(0, 4, 8, 12)
+	                     FMFVR_FPU_REGS(vr10, vr11)
+	                     STW_FPU_REGS(16, 20, 24, 28)
+	                     FMFVR_FPU_REGS(vr12, vr13)
+	                     STW_FPU_REGS(32, 36, 40, 44)
+	                     FMFVR_FPU_REGS(vr14, vr15)
+	                     STW_FPU_REGS(48, 52, 56, 60)
+	                     :"=a"(tmp1), "=a"(tmp2), "=a"(tmp3), "=a"(tmp4),
+	                       "+a"(fpregs));
+	local_irq_restore(flg);
+#endif
+}
+
+#else  /* __ASSEMBLY__ */
+
+#include <asm/asm-offsets.h>
+
+.macro  FPU_SAVE_REGS
+	/* Save FPU control regs task struct */
+	mfcr     r7, cr<1, 2>
+	mfcr     r6, cr<2, 2>
+	stw      r7, (a3, THREAD_FCR)
+	stw      r6, (a3, THREAD_FESR)
+	/* Save FPU general regs task struct */
+	fmfvrl   r6, vr0
+	fmfvrh   r7, vr0
+	fmfvrl   r8, vr1
+	fmfvrh   r9, vr1
+	stw      r6, (a3, THREAD_FPREG + 0)  /* In aviv2: stw can load longer */
+	stw      r7, (a3, THREAD_FPREG + 4)
+	stw      r8, (a3, THREAD_FPREG + 8)
+	stw      r9, (a3, THREAD_FPREG + 12)
+	fmfvrl   r6, vr2
+	fmfvrh   r7, vr2
+	fmfvrl   r8, vr3
+	fmfvrh   r9, vr3
+	stw      r6, (a3, THREAD_FPREG + 16)
+	stw      r7, (a3, THREAD_FPREG + 20)
+	stw      r8, (a3, THREAD_FPREG + 24)
+	stw      r9, (a3, THREAD_FPREG + 28)
+	fmfvrl   r6, vr4
+	fmfvrh   r7, vr4
+	fmfvrl   r8, vr5
+	fmfvrh   r9, vr5
+	stw      r6, (a3, THREAD_FPREG + 32)
+	stw      r7, (a3, THREAD_FPREG + 36)
+	stw      r8, (a3, THREAD_FPREG + 40)
+	stw      r9, (a3, THREAD_FPREG + 44)
+	fmfvrl   r6, vr6
+	fmfvrh   r7, vr6
+	fmfvrl   r8, vr7
+	fmfvrh   r9, vr7
+	stw      r6, (a3, THREAD_FPREG + 48)
+	stw      r7, (a3, THREAD_FPREG + 52)
+	stw      r8, (a3, THREAD_FPREG + 56)
+	stw      r9, (a3, THREAD_FPREG + 60)
+	fmfvrl   r6, vr8
+	fmfvrh   r7, vr8
+	fmfvrl   r8, vr9
+	fmfvrh   r9, vr9
+	stw      r6, (a3, THREAD_FPREG + 64)
+	stw      r7, (a3, THREAD_FPREG + 68)
+	stw      r8, (a3, THREAD_FPREG + 72)
+	stw      r9, (a3, THREAD_FPREG + 76)
+	fmfvrl   r6, vr10
+	fmfvrh   r7, vr10
+	fmfvrl   r8, vr11
+	fmfvrh   r9, vr11
+	stw      r6, (a3, THREAD_FPREG + 80)
+	stw      r7, (a3, THREAD_FPREG + 84)
+	stw      r8, (a3, THREAD_FPREG + 88)
+	stw      r9, (a3, THREAD_FPREG + 92)
+	fmfvrl   r6, vr12
+	fmfvrh   r7, vr12
+	fmfvrl   r8, vr13
+	fmfvrh   r9, vr13
+	stw      r6, (a3, THREAD_FPREG + 96)
+	stw      r7, (a3, THREAD_FPREG + 100)
+	stw      r8, (a3, THREAD_FPREG + 104)
+	stw      r9, (a3, THREAD_FPREG + 108)
+	fmfvrl   r6, vr14
+	fmfvrh   r7, vr14
+	fmfvrl   r8, vr15
+	fmfvrh   r9, vr15
+	stw      r6, (a3, THREAD_FPREG + 112)
+	stw      r7, (a3, THREAD_FPREG + 116)
+	stw      r8, (a3, THREAD_FPREG + 120)
+	stw      r9, (a3, THREAD_FPREG + 124)
+.endm
+
+.macro  FPU_RESTORE_REGS
+	/* Save FPU control regs task struct */
+	ldw      r6, (a3, THREAD_FCR)
+	ldw      r7, (a3, THREAD_FESR)
+	mtcr     r6, cr<1, 2>
+	mtcr     r7, cr<2, 2>
+	/* restore FPU general regs task struct */
+	ldw      r6, (a3, THREAD_FPREG + 0)
+	ldw      r7, (a3, THREAD_FPREG + 4)
+	ldw      r8, (a3, THREAD_FPREG + 8)
+	ldw      r9, (a3, THREAD_FPREG + 12)
+	fmtvrl   vr0, r6
+	fmtvrh   vr0, r7
+	fmtvrl   vr1, r8
+	fmtvrh   vr1, r9
+	ldw      r6, (a3, THREAD_FPREG + 16)
+	ldw      r7, (a3, THREAD_FPREG + 20)
+	ldw      r8, (a3, THREAD_FPREG + 24)
+	ldw      r9, (a3, THREAD_FPREG + 28)
+	fmtvrl   vr2, r6
+	fmtvrh   vr2, r7
+	fmtvrl   vr3, r8
+	fmtvrh   vr3, r9
+	ldw      r6, (a3, THREAD_FPREG + 32)
+	ldw      r7, (a3, THREAD_FPREG + 36)
+	ldw      r8, (a3, THREAD_FPREG + 40)
+	ldw      r9, (a3, THREAD_FPREG + 44)
+	fmtvrl   vr4, r6
+	fmtvrh   vr4, r7
+	fmtvrl   vr5, r8
+	fmtvrh   vr5, r9
+	ldw      r6, (a3, THREAD_FPREG + 48)
+	ldw      r7, (a3, THREAD_FPREG + 52)
+	ldw      r8, (a3, THREAD_FPREG + 56)
+	ldw      r9, (a3, THREAD_FPREG + 60)
+	fmtvrl   vr6, r6
+	fmtvrh   vr6, r7
+	fmtvrl   vr7, r8
+	fmtvrh   vr7, r9
+	ldw      r6, (a3, THREAD_FPREG + 64)
+	ldw      r7, (a3, THREAD_FPREG + 68)
+	ldw      r8, (a3, THREAD_FPREG + 72)
+	ldw      r9, (a3, THREAD_FPREG + 76)
+	fmtvrl   vr8, r6
+	fmtvrh   vr8, r7
+	fmtvrl   vr9, r8
+	fmtvrh   vr9, r9
+	ldw      r6, (a3, THREAD_FPREG + 80)
+	ldw      r7, (a3, THREAD_FPREG + 84)
+	ldw      r8, (a3, THREAD_FPREG + 88)
+	ldw      r9, (a3, THREAD_FPREG + 92)
+	fmtvrl   vr10, r6
+	fmtvrh   vr10, r7
+	fmtvrl   vr11, r8
+	fmtvrh   vr11, r9
+	ldw      r6, (a3, THREAD_FPREG + 96)
+	ldw      r7, (a3, THREAD_FPREG + 100)
+	ldw      r8, (a3, THREAD_FPREG + 104)
+	ldw      r9, (a3, THREAD_FPREG + 108)
+	fmtvrl   vr12, r6
+	fmtvrh   vr12, r7
+	fmtvrl   vr13, r8
+	fmtvrh   vr13, r9
+	ldw      r6, (a3, THREAD_FPREG + 112)
+	ldw      r7, (a3, THREAD_FPREG + 116)
+	ldw      r8, (a3, THREAD_FPREG + 120)
+	ldw      r9, (a3, THREAD_FPREG + 124)
+	fmtvrl   vr14, r6
+	fmtvrh   vr14, r7
+	fmtvrl   vr15, r8
+	fmtvrh   vr15, r9
+.endm
+
+#endif /* __ASSEMBLY__ */
+
+#endif /* __ASM_CSKY_FPU_H */
diff --git a/arch/csky/include/asm/highmem.h b/arch/csky/include/asm/highmem.h
new file mode 100644
index 0000000..9b459f6
--- /dev/null
+++ b/arch/csky/include/asm/highmem.h
@@ -0,0 +1,48 @@
+#ifndef __ASM_CSKY_HIGHMEM_H
+#define __ASM_CSKY_HIGHMEM_H
+
+#ifdef __KERNEL__
+
+#include <linux/init.h>
+#include <linux/interrupt.h>
+#include <linux/uaccess.h>
+#include <asm/kmap_types.h>
+#include <asm/cache.h>
+
+/* undef for production */
+#define HIGHMEM_DEBUG 1
+
+/* declarations for highmem.c */
+extern unsigned long highstart_pfn, highend_pfn;
+
+extern pte_t *pkmap_page_table;
+
+/*
+ * Right now we initialize only a single pte table. It can be extended
+ * easily, subsequent pte tables have to be allocated in one physical
+ * chunk of RAM.
+ */
+#define LAST_PKMAP 1024
+#define LAST_PKMAP_MASK (LAST_PKMAP-1)
+#define PKMAP_NR(virt)  ((virt-PKMAP_BASE) >> PAGE_SHIFT)
+#define PKMAP_ADDR(nr)  (PKMAP_BASE + ((nr) << PAGE_SHIFT))
+
+extern void * kmap_high(struct page *page);
+extern void kunmap_high(struct page *page);
+
+extern void *kmap(struct page *page);
+extern void kunmap(struct page *page);
+extern void *kmap_atomic(struct page *page);
+extern void __kunmap_atomic(void *kvaddr);
+extern void *kmap_atomic_pfn(unsigned long pfn);
+extern struct page *kmap_atomic_to_page(void *ptr);
+
+#define flush_cache_kmaps() cache_op_all(INS_CACHE|DATA_CACHE|CACHE_CLR|CACHE_INV, 0)
+
+extern void kmap_init(void);
+
+#define kmap_prot PAGE_KERNEL
+
+#endif /* __KERNEL__ */
+
+#endif /* __ASM_CSKY_HIGHMEM_H */
diff --git a/arch/csky/include/asm/io.h b/arch/csky/include/asm/io.h
new file mode 100644
index 0000000..3a35b8c
--- /dev/null
+++ b/arch/csky/include/asm/io.h
@@ -0,0 +1,24 @@
+#ifndef __ASM_CSKY_IO_H
+#define __ASM_CSKY_IO_H
+
+#include <abi/pgtable-bits.h>
+#include <linux/types.h>
+
+extern void __iomem *ioremap(phys_addr_t offset, size_t size);
+
+extern inline void *ioremap_nocache(phys_addr_t physaddr, unsigned long size)
+{
+	return ioremap(physaddr, size);
+}
+
+extern void iounmap(void *addr);
+
+extern int remap_area_pages(unsigned long address, phys_addr_t phys_addr,
+		size_t size, unsigned long flags);
+
+#define ioremap_wc ioremap_nocache
+#define ioremap_wt ioremap_nocache
+
+#include <asm-generic/io.h>
+
+#endif /* __ASM_CSKY_IO_H */
diff --git a/arch/csky/include/asm/irq.h b/arch/csky/include/asm/irq.h
new file mode 100644
index 0000000..db98701
--- /dev/null
+++ b/arch/csky/include/asm/irq.h
@@ -0,0 +1,10 @@
+#ifndef __ASM_CSKY_IRQ_H
+#define __ASM_CSKY_IRQ_H
+
+#define NR_IRQS CONFIG_CSKY_NR_IRQS
+
+#include <asm-generic/irq.h>
+
+extern unsigned int (*csky_get_auto_irqno) (void);
+
+#endif /* __ASM_CSKY_IRQ_H */
diff --git a/arch/csky/include/asm/irqflags.h b/arch/csky/include/asm/irqflags.h
new file mode 100644
index 0000000..9c59c0e
--- /dev/null
+++ b/arch/csky/include/asm/irqflags.h
@@ -0,0 +1,72 @@
+#ifndef __ASM_CSKY_IRQFLAGS_H
+#define __ASM_CSKY_IRQFLAGS_H
+
+static inline unsigned long arch_local_irq_save(void)
+{
+	unsigned long flags;
+	__asm__ __volatile__(
+		"mfcr	%0, psr	\n"
+		"psrclr	ie	\n"
+		:"=r"(flags)
+		:
+		:
+		);
+	return flags;
+}
+#define arch_local_irq_save arch_local_irq_save
+
+static inline void arch_local_irq_enable(void)
+{
+	__asm__ __volatile__(
+		"psrset ee, ie \n"
+		:
+		:
+		:
+		);
+}
+#define arch_local_irq_enable arch_local_irq_enable
+
+static inline void arch_local_irq_disable(void)
+{
+	__asm__ __volatile__(
+		"psrclr ie \n"
+		:
+		:
+		:
+		);
+}
+#define arch_local_irq_disable arch_local_irq_disable
+
+static inline unsigned long arch_local_save_flags(void)
+{
+	unsigned long flags;
+	__asm__ __volatile__(
+		"mfcr	%0, psr	\n"
+		:"=r"(flags)
+		:
+		:
+		);
+	return flags;
+}
+#define arch_local_save_flags arch_local_save_flags
+
+static inline void arch_local_irq_restore(unsigned long flags)
+{
+	__asm__ __volatile__(
+		"mtcr 	%0, psr \n"
+		:
+		:"r" (flags)
+		:"memory"
+		);
+}
+#define arch_local_irq_restore arch_local_irq_restore
+
+static inline int arch_irqs_disabled_flags(unsigned long flags)
+{
+	return !(flags & (1<<6));
+}
+#define arch_irqs_disabled_flags arch_irqs_disabled_flags
+
+#include <asm-generic/irqflags.h>
+
+#endif /* __ASM_CSKY_IRQFLAGS_H */
diff --git a/arch/csky/include/asm/misc_csky.h b/arch/csky/include/asm/misc_csky.h
new file mode 100644
index 0000000..77c8fff
--- /dev/null
+++ b/arch/csky/include/asm/misc_csky.h
@@ -0,0 +1,14 @@
+#ifndef __ASM_CSKY_MISC_H
+#define __ASM_CSKY_MISC_H
+#include <asm/ptrace.h>
+unsigned int read_pt_regs(unsigned int rx, struct pt_regs *regs);
+void write_pt_regs(unsigned int value, unsigned int rx, struct pt_regs *regs);
+unsigned int read_fpcr(void);
+void write_fpcr(unsigned int val);
+unsigned int read_fpesr(void);
+void write_fpesr(unsigned int val);
+#ifdef __CSKYABIV1__
+unsigned int read_fpsr(void);
+void write_fpsr(unsigned int val);
+#endif
+#endif /* __CSKY_MISC_H__ */
diff --git a/arch/csky/include/asm/mmu.h b/arch/csky/include/asm/mmu.h
new file mode 100644
index 0000000..a01c8bf
--- /dev/null
+++ b/arch/csky/include/asm/mmu.h
@@ -0,0 +1,9 @@
+#ifndef __ASM_CSKY_MMU_H
+#define __ASM_CSKY_MMU_H
+
+typedef struct {
+	unsigned long asid[NR_CPUS];
+	void *vdso;
+} mm_context_t;
+
+#endif /* __ASM_CSKY_MMU_H */
diff --git a/arch/csky/include/asm/mmu_context.h b/arch/csky/include/asm/mmu_context.h
new file mode 100644
index 0000000..43223bb
--- /dev/null
+++ b/arch/csky/include/asm/mmu_context.h
@@ -0,0 +1,154 @@
+#ifndef __ASM_CSKY_MMU_CONTEXT_H
+#define __ASM_CSKY_MMU_CONTEXT_H
+
+#include <asm-generic/mm_hooks.h>
+#include <asm/setup.h>
+#include <asm/page.h>
+#include <asm/cacheflush.h>
+#include <asm/tlbflush.h>
+
+#include <linux/errno.h>
+#include <linux/sched.h>
+#include <abi/ckmmu.h>
+
+/*
+ * For the fast tlb miss handlers, we currently keep a per cpu array
+ * of pointers to the current pgd for each processor. Also, the proc.
+ * id is stuffed into the context register. This should be changed to
+ * use the processor id via current->processor, where current is stored
+ * in watch hi/lo. The context register should be used to contiguously
+ * map the page tables.
+ */
+#ifdef CONFIG_MMU_HARD_REFILL
+#define TLBMISS_HANDLER_SETUP_PGD(pgd) tlbmiss_handler_setup_pgd((unsigned long)pgd)
+#else
+#define TLBMISS_HANDLER_SETUP_PGD(pgd) \
+	pgd_current[smp_processor_id()] = (unsigned long)(pgd)
+extern unsigned long pgd_current[];
+#endif /* CONFIG_MMU_HARD_REFILL */
+
+#define cpu_context(cpu, mm)	((mm)->context.asid[cpu])
+#define cpu_asid(cpu, mm)	(cpu_context((cpu), (mm)) & ASID_MASK)
+#define asid_cache(cpu)		(cpu_data[cpu].asid_cache)
+
+#define ASID_INC		0x1
+#define ASID_MASK		0xff
+#define ASID_VERSION_MASK	0xffffff00
+#define ASID_FIRST_VERSION	0x100
+
+static inline void enter_lazy_tlb(struct mm_struct *mm, struct task_struct *tsk)
+{
+}
+
+/*
+ *  All unused by hardware upper bits will be considered
+ *  as a software asid extension.
+ */
+static inline void
+get_new_mmu_context(struct mm_struct *mm, unsigned long cpu)
+{
+	unsigned long asid = asid_cache(cpu);
+
+	if (! ((asid += ASID_INC) & ASID_MASK) ) {
+//		cache_op_all(INS_CACHE|DATA_CACHE|CACHE_CLR|CACHE_INV);
+		local_flush_tlb_all();	/* start new asid cycle */
+		if (!asid)		/* fix version if needed */
+			asid = ASID_FIRST_VERSION;
+	}
+	cpu_context(cpu, mm) = asid_cache(cpu) = asid;
+}
+
+/*
+ * Initialize the context related info for a new mm_struct
+ * instance.
+ */
+static inline int
+init_new_context(struct task_struct *tsk, struct mm_struct *mm)
+{
+	int i;
+
+	for_each_online_cpu(i)
+		cpu_context(i, mm) = 0;
+	return 0;
+}
+
+static inline void switch_mm(struct mm_struct *prev, struct mm_struct *next,
+                             struct task_struct *tsk)
+{
+	unsigned int cpu = smp_processor_id();
+	unsigned long flags;
+
+	local_irq_save(flags);
+	/* Check if our ASID is of an older version and thus invalid */
+	if ((cpu_context(cpu, next) ^ asid_cache(cpu)) & ASID_VERSION_MASK)
+		get_new_mmu_context(next, cpu);
+	write_mmu_entryhi(cpu_context(cpu, next));
+	TLBMISS_HANDLER_SETUP_PGD(next->pgd);
+
+	/*
+	 * Mark current->active_mm as not "active" anymore.
+	 * We don't want to mislead possible IPI tlb flush routines.
+	 */
+	cpumask_clear_cpu(cpu, mm_cpumask(prev));
+	cpumask_set_cpu(cpu, mm_cpumask(next));
+
+	local_irq_restore(flags);
+}
+
+/*
+ * Destroy context related info for an mm_struct that is about
+ * to be put to rest.
+ */
+static inline void destroy_context(struct mm_struct *mm)
+{
+}
+
+/*
+ * After we have set current->mm to a new value, this activates
+ * the context for the new mm so we see the new mappings.
+ */
+static inline void
+activate_mm(struct mm_struct *prev, struct mm_struct *next)
+{
+	unsigned long flags;
+	int cpu = smp_processor_id();
+
+	local_irq_save(flags);
+
+	/* Unconditionally get a new ASID.  */
+	get_new_mmu_context(next, cpu);
+
+	write_mmu_entryhi(cpu_context(cpu, next));
+	TLBMISS_HANDLER_SETUP_PGD(next->pgd);
+
+	/* mark mmu ownership change */
+	cpumask_clear_cpu(cpu, mm_cpumask(prev));
+	cpumask_set_cpu(cpu, mm_cpumask(next));
+
+	local_irq_restore(flags);
+}
+#define deactivate_mm(tsk,mm)	do {} while (0)
+
+/*
+ * If mm is currently active_mm, we can't really drop it. Instead,
+ * we will get a new one for it.
+ */
+static inline void
+drop_mmu_context(struct mm_struct *mm, unsigned cpu)
+{
+	unsigned long flags;
+
+	local_irq_save(flags);
+
+	if (cpumask_test_cpu(cpu, mm_cpumask(mm)))  {
+		get_new_mmu_context(mm, cpu);
+		write_mmu_entryhi(cpu_asid(cpu, mm));
+	} else {
+		/* will get a new context next time */
+		cpu_context(cpu, mm) = 0;
+	}
+
+	local_irq_restore(flags);
+}
+
+#endif /* __ASM_CSKY_MMU_CONTEXT_H */
diff --git a/arch/csky/include/asm/page.h b/arch/csky/include/asm/page.h
new file mode 100644
index 0000000..0814127
--- /dev/null
+++ b/arch/csky/include/asm/page.h
@@ -0,0 +1,110 @@
+#ifndef __ASM_CSKY_PAGE_H
+#define __ASM_CSKY_PAGE_H
+
+#include <asm/setup.h>
+#include <asm/cache.h>
+#include <linux/const.h>
+
+/*
+ * PAGE_SHIFT determines the page size
+ */
+#define PAGE_SHIFT	12
+#define PAGE_SIZE	(_AC(1, UL) << PAGE_SHIFT)
+#define PAGE_MASK	(~(PAGE_SIZE - 1))
+#define THREAD_SIZE	(PAGE_SIZE * 2)
+
+/*
+ * NOTE: virtual isn't really correct, actually it should be the offset into the
+ * memory node, but we have no highmem, so that works for now.
+ * TODO: implement (fast) pfn<->pgdat_idx conversion functions, this makes lots
+ * of the shifts unnecessary.
+ */
+
+#ifndef __ASSEMBLY__
+
+#include <linux/pfn.h>
+
+#define virt_to_pfn(kaddr)      (__pa(kaddr) >> PAGE_SHIFT)
+#define pfn_to_virt(pfn)        __va((pfn) << PAGE_SHIFT)
+
+#define virt_addr_valid(kaddr)  ((void *)(kaddr) >= (void *)PAGE_OFFSET && \
+                                 (void *)(kaddr) < high_memory)
+extern unsigned long min_low_pfn, max_pfn;
+#define pfn_valid(pfn)		((pfn >= min_low_pfn) && (pfn < max_pfn))
+
+extern void *memset(void *dest, int c, size_t l);
+extern void *memcpy (void *to, const void *from, size_t l);
+
+#define clear_page(page)        memset((page), 0, PAGE_SIZE)
+#define copy_page(to,from)      memcpy((to), (from), PAGE_SIZE)
+
+#define page_to_phys(page)	(page_to_pfn(page) << PAGE_SHIFT)
+
+struct page;
+
+#include <abi/page.h>
+
+struct vm_area_struct;
+
+/*
+ * These are used to make use of C type-checking..
+ */
+typedef struct { unsigned long pte_low; } pte_t;
+#define pte_val(x)    ((x).pte_low)
+
+typedef struct { unsigned long pgd; } pgd_t;
+typedef struct { unsigned long pgprot; } pgprot_t;
+typedef struct page *pgtable_t;
+
+#define pgd_val(x)	((x).pgd)
+#define pgprot_val(x)	((x).pgprot)
+
+#define ptep_buddy(x)	((pte_t *)((unsigned long)(x) ^ sizeof(pte_t)))
+
+#define __pte(x)	((pte_t) { (x) } )
+#define __pgd(x)	((pgd_t) { (x) } )
+#define __pgprot(x)	((pgprot_t) { (x) } )
+
+#endif /* !__ASSEMBLY__ */
+
+/*
+ * This handles the memory map.
+ * We handle pages at KSEG0 for kernels with 32 bit address space.
+ */
+
+#define	PAGE_OFFSET	0x80000000
+#define LOWMEM_LIMIT	0x20000000
+
+#ifdef CONFIG_PHYSICAL_BASE_CHANGE
+#define PHYS_OFFSET	CONFIG_SSEG0_BASE
+#else
+#define PHYS_OFFSET     0x0
+#endif
+#define ARCH_PFN_OFFSET	PFN_DOWN(CONFIG_RAM_BASE + PHYS_OFFSET)
+
+#define MASK_SSEG1(x) ((unsigned long)(x) & (~LOWMEM_LIMIT))
+
+#define __pa(x)		(MASK_SSEG1(x) - PAGE_OFFSET + PHYS_OFFSET)
+#define __va(x)		((void *)((unsigned long)(x) + PAGE_OFFSET - PHYS_OFFSET))
+#define __pa_symbol(x)  __pa(RELOC_HIDE(MASK_SSEG1(x), 0))
+
+#define MAP_NR(x)	PFN_DOWN(MASK_SSEG1(x) - PAGE_OFFSET - CONFIG_RAM_BASE)
+#define virt_to_page(x)		(mem_map + MAP_NR(x))
+
+#define VM_DATA_DEFAULT_FLAGS	(VM_READ | VM_WRITE | VM_EXEC | \
+				 VM_MAYREAD | VM_MAYWRITE | VM_MAYEXEC)
+
+#define UNCACHE_ADDR(x)		((unsigned long)(x) | LOWMEM_LIMIT)
+
+/*
+ * main RAM and kernel working space are coincident at 0x80000000, but to make
+ * life more interesting, there's also an uncached virtual shadow at 0xb0000000
+ * - these mappings are fixed in the MMU
+ */
+
+#define pfn_to_kaddr(x)       __va(PFN_PHYS(x))
+
+#include <asm-generic/memory_model.h>
+#include <asm-generic/getorder.h>
+
+#endif /* __ASM_CSKY_PAGE_H */
diff --git a/arch/csky/include/asm/pgalloc.h b/arch/csky/include/asm/pgalloc.h
new file mode 100644
index 0000000..dc0d6a5
--- /dev/null
+++ b/arch/csky/include/asm/pgalloc.h
@@ -0,0 +1,124 @@
+#ifndef __ASM_CSKY_PGALLOC_H
+#define __ASM_CSKY_PGALLOC_H
+
+#include <linux/highmem.h>
+#include <linux/mm.h>
+#include <linux/sched.h>
+
+#ifdef CONFIG_MMU_HARD_REFILL
+/* hard refill need fill PA. */
+static inline void pmd_populate_kernel(struct mm_struct *mm, pmd_t *pmd,
+        pte_t *pte)
+{
+        set_pmd(pmd, __pmd(__pa(pte)));
+}
+
+static inline void pmd_populate(struct mm_struct *mm, pmd_t *pmd,
+        pgtable_t pte)
+{
+        set_pmd(pmd, __pmd(__pa(page_address(pte))));
+}
+#else
+static inline void pmd_populate_kernel(struct mm_struct *mm, pmd_t *pmd,
+        pte_t *pte)
+{
+        set_pmd(pmd, __pmd((unsigned long)pte));
+}
+
+static inline void pmd_populate(struct mm_struct *mm, pmd_t *pmd,
+        pgtable_t pte)
+{
+        set_pmd(pmd, __pmd((unsigned long)page_address(pte)));
+}
+#endif
+
+#define pmd_pgtable(pmd) pmd_page(pmd)
+
+extern void pgd_init(unsigned long *p);
+
+static inline pte_t *pte_alloc_one_kernel(struct mm_struct *mm,
+        unsigned long address)
+{
+        pte_t *pte;
+	unsigned long *kaddr, i;
+
+	pte = (pte_t *) __get_free_pages(GFP_KERNEL | __GFP_REPEAT, PTE_ORDER);
+	kaddr = (unsigned long *)pte;
+	if (address & 0x80000000)
+		for(i=0; i<(PAGE_SIZE/4); i++)
+			*(kaddr + i) = 0x1;
+	else
+		clear_page(kaddr);
+
+        return pte;
+}
+
+static inline struct page *pte_alloc_one(struct mm_struct *mm,
+                                            unsigned long address)
+{
+	struct page *pte;
+	unsigned long *kaddr, i;
+
+        pte = alloc_pages(GFP_KERNEL | __GFP_REPEAT, PTE_ORDER);
+        if (pte) {
+		kaddr = kmap_atomic(pte);
+		if (address & 0x80000000) {
+			for(i=0; i<(PAGE_SIZE/4); i++)
+				*(kaddr + i) = 0x1;
+		} else
+			clear_page(kaddr);
+		kunmap_atomic(kaddr);
+		pgtable_page_ctor(pte);
+        }
+        return pte;
+}
+
+
+static inline void pte_free_kernel(struct mm_struct *mm, pte_t *pte)
+{
+        free_pages((unsigned long)pte, PTE_ORDER);
+}
+
+
+static inline void pte_free(struct mm_struct *mm, pgtable_t pte)
+{
+        pgtable_page_dtor(pte);
+        __free_pages(pte, PTE_ORDER);
+}
+
+static inline void pgd_free(struct mm_struct *mm, pgd_t *pgd)
+{
+        free_pages((unsigned long)pgd, PGD_ORDER);
+}
+
+static inline pgd_t *pgd_alloc(struct mm_struct *mm)
+{
+        pgd_t *ret, *init;
+
+        ret = (pgd_t *) __get_free_pages(GFP_KERNEL, PGD_ORDER);
+        if (ret) {
+                init = pgd_offset(&init_mm, 0UL);
+                pgd_init((unsigned long *)ret);
+                memcpy(ret + USER_PTRS_PER_PGD, init + USER_PTRS_PER_PGD,
+                       (PTRS_PER_PGD - USER_PTRS_PER_PGD) * sizeof(pgd_t));
+#if defined(CONFIG_MMU_HARD_REFILL) && !defined(__ck807__)
+		cache_op_range((unsigned int)ret, (unsigned int)(ret + PTRS_PER_PGD)
+			,DATA_CACHE|CACHE_CLR, 0);
+#endif
+        }
+
+        return ret;
+}
+
+#define __pte_free_tlb(tlb,pte,address)                 \
+do {                                                    \
+        pgtable_page_dtor(pte);                         \
+        tlb_remove_page((tlb), pte);                    \
+} while (0)
+
+#define check_pgt_cache()               do {} while(0)
+
+extern void pagetable_init(void);
+
+#endif /* __ASM_CSKY_PGALLOC_H */
+
diff --git a/arch/csky/include/asm/pgtable.h b/arch/csky/include/asm/pgtable.h
new file mode 100644
index 0000000..57aaab3
--- /dev/null
+++ b/arch/csky/include/asm/pgtable.h
@@ -0,0 +1,378 @@
+#ifndef __ASM_CSKY_PGTABLE_H
+#define __ASM_CSKY_PGTABLE_H
+
+#include <asm/fixmap.h>
+#include <asm/addrspace.h>
+#include <abi/pgtable-bits.h>
+#include <asm-generic/pgtable-nopmd.h>
+
+/* PGDIR_SHIFT determines what a third-level page table entry can map */
+#define PGDIR_SHIFT		22
+#define PGDIR_SIZE		(1UL << PGDIR_SHIFT)
+#define PGDIR_MASK		(~(PGDIR_SIZE-1))
+
+#define USER_PTRS_PER_PGD	(0x80000000UL/PGDIR_SIZE)
+#define FIRST_USER_ADDRESS	0UL
+
+#ifdef CONFIG_HIGHMEM
+#define PKMAP_BASE		(0xfe000000UL)
+#define VMALLOC_START		(0xc0008000)
+#define VMALLOC_END		(PKMAP_BASE - 2*PAGE_SIZE)
+#else
+#define VMALLOC_START		(0xc0008000)
+#define VMALLOC_END		(FIXADDR_START - 2*PAGE_SIZE)
+#endif
+
+/*
+ * traditional two-level paging structure:
+ */
+#define PGD_ORDER	0
+#define PTE_ORDER	0
+
+#define PTRS_PER_PGD	((PAGE_SIZE << PGD_ORDER) / sizeof(pgd_t))
+#define PTRS_PER_PMD	1
+#define PTRS_PER_PTE	((PAGE_SIZE << PTE_ORDER) / sizeof(pte_t))
+
+#define pte_ERROR(e) \
+	printk("%s:%d: bad pte %08lx.\n", __FILE__, __LINE__, (e).pte_low)
+#define pgd_ERROR(e) \
+	printk("%s:%d: bad pgd %08lx.\n", __FILE__, __LINE__, pgd_val(e))
+
+/* Find an entry in the third-level page table.. */
+#define __pte_offset_t(address) \
+	(((address) >> PAGE_SHIFT) & (PTRS_PER_PTE - 1))
+#define pte_offset_kernel(dir, address) \
+	(pmd_page_vaddr(*(dir)) + __pte_offset_t(address))
+#define pte_offset_map(dir, address) \
+	((pte_t *)page_address(pmd_page(*(dir))) + __pte_offset_t(address))
+#define pmd_page(pmd)			(pfn_to_page(pmd_phys(pmd) >> PAGE_SHIFT))
+#define pte_clear(mm,addr,ptep)		set_pte((ptep), (((unsigned int)addr&0x80000000)?__pte(1):__pte(0)))
+#define pte_none(pte)			(!(pte_val(pte)&0xfffffffe))
+#define pte_present(pte)		(pte_val(pte) & _PAGE_PRESENT )
+#define pte_pfn(x)			((unsigned long)((x).pte_low >> PAGE_SHIFT))
+#define pfn_pte(pfn, prot)		__pte(((unsigned long long)(pfn) << PAGE_SHIFT) \
+						| pgprot_val(prot))
+
+#define __READABLE	(_PAGE_READ | _PAGE_SILENT_READ | _PAGE_ACCESSED)
+#define __WRITEABLE	(_PAGE_WRITE | _PAGE_SILENT_WRITE | _PAGE_MODIFIED)
+
+#define _PAGE_CHG_MASK  (PAGE_MASK | _PAGE_ACCESSED | _PAGE_MODIFIED | _CACHE_MASK)
+
+#define PTE_FILE_MAX_BITS 28
+
+#define pte_unmap(pte) ((void)(pte))
+
+#define __swp_type(x)			(((x).val >> 4) & 0xff)
+#define __swp_offset(x)			((x).val >> 12)
+#define __swp_entry(type, offset)	((swp_entry_t) {((type) << 4) | ((offset) << 12) })
+#define __pte_to_swp_entry(pte)		((swp_entry_t) { pte_val(pte) })
+#define __swp_entry_to_pte(x)		((pte_t) { (x).val })
+
+#define pte_page(x)			pfn_to_page(pte_pfn(x))
+#define __mk_pte(page_nr,pgprot)	__pte(((page_nr) << PAGE_SHIFT) | pgprot_val(pgprot))
+
+/*
+ * CSKY can't do page protection for execute, and considers that the same like
+ * read. Also, write permissions imply read permissions. This is the closest
+ * we can get by reasonable means..
+ */
+#define PAGE_NONE	__pgprot(_PAGE_PRESENT | _CACHE_CACHED)
+#define PAGE_SHARED	__pgprot(_PAGE_PRESENT | _PAGE_READ | _PAGE_WRITE | \
+				_CACHE_CACHED)
+#define PAGE_COPY	__pgprot(_PAGE_PRESENT | _PAGE_READ | _CACHE_CACHED)
+#define PAGE_READONLY	__pgprot(_PAGE_PRESENT | _PAGE_READ | _CACHE_CACHED)
+#define PAGE_KERNEL	__pgprot(_PAGE_PRESENT | __READABLE | __WRITEABLE | \
+				_PAGE_GLOBAL | _CACHE_CACHED)
+#define PAGE_USERIO	__pgprot(_PAGE_PRESENT | _PAGE_READ | _PAGE_WRITE | \
+				_CACHE_CACHED)
+
+#define __P000	PAGE_NONE
+#define __P001	PAGE_READONLY
+#define __P010	PAGE_COPY
+#define __P011	PAGE_COPY
+#define __P100	PAGE_READONLY
+#define __P101	PAGE_READONLY
+#define __P110	PAGE_COPY
+#define __P111	PAGE_COPY
+
+#define __S000	PAGE_NONE
+#define __S001	PAGE_READONLY
+#define __S010	PAGE_SHARED
+#define __S011	PAGE_SHARED
+#define __S100	PAGE_READONLY
+#define __S101	PAGE_READONLY
+#define __S110	PAGE_SHARED
+#define __S111	PAGE_SHARED
+
+extern unsigned long empty_zero_page[PAGE_SIZE / sizeof(unsigned long)];
+#define ZERO_PAGE(vaddr)	(virt_to_page(empty_zero_page))
+
+extern void load_pgd(unsigned long pg_dir);
+extern pte_t invalid_pte_table[PTRS_PER_PTE];
+
+static inline int pte_special(pte_t pte) { return 0; }
+static inline pte_t pte_mkspecial(pte_t pte) { return pte; }
+
+/*
+ * Empty pgd/pmd entries point to the invalid_pte_table.
+ */
+#ifdef CONFIG_MMU_HARD_REFILL
+
+#define __dcache_flush_line(x) \
+	cache_op_line((u32)x, DATA_CACHE|CACHE_CLR);
+
+#if !defined(__ck807__)
+#define set_pte(pteptr, pteval)			\
+        do{					\
+                *(pteptr) = (pteval);		\
+                __dcache_flush_line(pteptr)	\
+        } while(0)
+#define set_pte_at(mm,addr,ptep,pteval) set_pte(ptep,pteval)
+#else
+#define set_pte(pteptr, pteval)			\
+        do{					\
+                *(pteptr) = (pteval);		\
+        } while(0)
+#define set_pte_at(mm,addr,ptep,pteval) set_pte(ptep,pteval)
+#endif
+
+static inline pte_t *pmd_page_vaddr(pmd_t pmd)
+{
+	unsigned long ptr;
+
+	ptr = pmd_val(pmd);
+
+	return __va(ptr);
+}
+
+#define pmd_phys(pmd) pmd_val(pmd)
+
+static inline void set_pmd(pmd_t *pmdptr, pmd_t pmdval)
+{
+	pmdptr->pud.pgd.pgd = pmdval.pud.pgd.pgd;
+#if !defined(__ck807__)
+	__dcache_flush_line(&pmdptr->pud.pgd.pgd);
+#endif
+}
+
+
+static inline int pmd_none(pmd_t pmd)
+{
+	return pmd_val(pmd) == __pa(invalid_pte_table);
+}
+
+#define pmd_bad(pmd)        (pmd_val(pmd) & ~PAGE_MASK)
+
+static inline int pmd_present(pmd_t pmd)
+{
+        return (pmd_val(pmd) != __pa(invalid_pte_table));
+}
+
+static inline void pmd_clear(pmd_t *pmdp)
+{
+        pmd_val(*pmdp) = (__pa(invalid_pte_table));
+#if !defined(__ck807__)
+	__dcache_flush_line(pmdp);
+#endif
+}
+#else /* CONFIG_MMU_HARD_REFILL */
+
+#define set_pte(pteptr, pteval)                                 \
+        do{                                                     \
+                *(pteptr) = (pteval);                           \
+        } while(0)
+#define set_pte_at(mm,addr,ptep,pteval) set_pte(ptep,pteval)
+
+static inline pte_t *pmd_page_vaddr(pmd_t pmd)
+{
+	unsigned long ptr;
+
+	ptr = pmd_val(pmd);
+
+	return (pte_t *)ptr;
+}
+
+#define pmd_phys(pmd)	virt_to_phys((void *)pmd_val(pmd))
+
+/*
+ * (pmds are folded into pgds so this doesn't get actually called,
+ * but the define is needed for a generic inline function.)
+ */
+#define set_pmd(pmdptr, pmdval)	(*(pmdptr) = pmdval)
+
+static inline int pmd_none(pmd_t pmd)
+{
+	return pmd_val(pmd) == (unsigned long) invalid_pte_table;
+}
+
+#define pmd_bad(pmd)	(pmd_val(pmd) & ~PAGE_MASK)
+
+static inline int pmd_present(pmd_t pmd)
+{
+	return (pmd_val(pmd) != (unsigned long) invalid_pte_table);
+}
+
+static inline void pmd_clear(pmd_t *pmdp)
+{
+	pmd_val(*pmdp) = ((unsigned long) invalid_pte_table);
+}
+#endif
+
+/*
+ * The following only work if pte_present() is true.
+ * Undefined behaviour if not..
+ */
+static inline int pte_read(pte_t pte)
+{
+	return (pte).pte_low & _PAGE_READ;
+}
+
+static inline int pte_write(pte_t pte)
+{
+	return (pte).pte_low & _PAGE_WRITE;
+}
+
+static inline int pte_dirty(pte_t pte)
+{
+	return (pte).pte_low & _PAGE_MODIFIED;
+}
+
+static inline int pte_young(pte_t pte)
+{
+	return (pte).pte_low & _PAGE_ACCESSED;
+}
+
+static inline int pte_file(pte_t pte)
+{
+	return pte_val(pte) & _PAGE_FILE;
+}
+
+static inline pte_t pte_wrprotect(pte_t pte)
+{
+	pte_val(pte) &= ~(_PAGE_WRITE | _PAGE_SILENT_WRITE);
+	return pte;
+}
+
+static inline pte_t pte_mkclean(pte_t pte)
+{
+	pte_val(pte) &= ~(_PAGE_MODIFIED|_PAGE_SILENT_WRITE);
+	return pte;
+}
+
+static inline pte_t pte_mkold(pte_t pte)
+{
+	pte_val(pte) &= ~(_PAGE_ACCESSED|_PAGE_SILENT_READ);
+	return pte;
+}
+
+static inline pte_t pte_mkwrite(pte_t pte)
+{
+	pte_val(pte) |= _PAGE_WRITE;
+	if (pte_val(pte) & _PAGE_MODIFIED)
+		pte_val(pte) |= _PAGE_SILENT_WRITE;
+	return pte;
+}
+
+static inline pte_t pte_mkdirty(pte_t pte)
+{
+	pte_val(pte) |= _PAGE_MODIFIED;
+	if (pte_val(pte) & _PAGE_WRITE)
+		pte_val(pte) |= _PAGE_SILENT_WRITE;
+	return pte;
+}
+
+static inline pte_t pte_mkyoung(pte_t pte)
+{
+	pte_val(pte) |= _PAGE_ACCESSED;
+	if (pte_val(pte) & _PAGE_READ)
+		pte_val(pte) |= _PAGE_SILENT_READ;
+	return pte;
+}
+
+#define PGD_T_LOG2	ffz(~sizeof(pgd_t))
+#define PMD_T_LOG2	ffz(~sizeof(pmd_t))
+#define PTE_T_LOG2	ffz(~sizeof(pte_t))
+
+#define page_pte(page)	page_pte_prot(page, __pgprot(0))
+
+#define __pgd_offset(address)	pgd_index(address)
+#define __pud_offset(address)	(((address) >> PUD_SHIFT) & (PTRS_PER_PUD-1))
+#define __pmd_offset(address)	(((address) >> PMD_SHIFT) & (PTRS_PER_PMD-1))
+
+/* to find an entry in a kernel page-table-directory */
+#define pgd_offset_k(address)	pgd_offset(&init_mm, address)
+
+#define pgd_index(address)	((address) >> PGDIR_SHIFT)
+
+/*
+ * Macro to make mark a page protection value as "uncacheable".  Note
+ * that "protection" is really a misnomer here as the protection value
+ * contains the memory attribute bits, dirty bits, and various other
+ * bits as well.
+ */
+#define pgprot_noncached pgprot_noncached
+
+static inline pgprot_t pgprot_noncached(pgprot_t _prot)
+{
+	unsigned long prot = pgprot_val(_prot);
+
+	prot = (prot & ~_CACHE_MASK) | _CACHE_UNCACHED;
+
+	return __pgprot(prot);
+}
+
+/*
+ * Conversion functions: convert a page and protection to a page entry,
+ * and a page entry and page directory to the page they refer to.
+ */
+#define mk_pte(page, pgprot)    pfn_pte(page_to_pfn(page), (pgprot))
+static inline pte_t pte_modify(pte_t pte, pgprot_t newprot)
+{
+	return __pte((pte_val(pte) & _PAGE_CHG_MASK) | pgprot_val(newprot));
+}
+
+/* to find an entry in a page-table-directory */
+static inline pgd_t *pgd_offset(struct mm_struct *mm, unsigned long address)
+{
+	return mm->pgd + pgd_index(address);
+}
+
+/* Find an entry in the third-level page table.. */
+static inline pte_t *pte_offset(pmd_t * dir, unsigned long address)
+{
+	return (pte_t *) (pmd_page_vaddr(*dir)) +
+		((address >> PAGE_SHIFT) & (PTRS_PER_PTE - 1));
+}
+
+extern pgd_t swapper_pg_dir[PTRS_PER_PGD];
+extern void paging_init(void);
+
+extern void __update_tlb(struct vm_area_struct *vma, unsigned long address,
+		pte_t pte);
+extern void __update_cache(struct vm_area_struct *vma, unsigned long address,
+		pte_t pte);
+extern void show_jtlb_table(void);
+
+static inline void update_mmu_cache(struct vm_area_struct *vma,
+		unsigned long address, pte_t *ptep)
+{
+	pte_t pte = *ptep;
+	__update_tlb(vma, address, pte);
+	__update_cache(vma, address, pte);
+}
+
+/* Needs to be defined here and not in linux/mm.h, as it is arch dependent */
+#define PageSkip(page)		(0)
+#define kern_addr_valid(addr)	(1)
+
+/*
+ * No page table caches to initialise
+ */
+#define pgtable_cache_init()	do{}while(0)
+
+#define io_remap_pfn_range(vma, vaddr, pfn, size, prot) \
+	remap_pfn_range(vma, vaddr, pfn, size, prot)
+
+#include <asm-generic/pgtable.h>
+
+#endif /* __ASM_CSKY_PGTABLE_H */
diff --git a/arch/csky/include/asm/processor.h b/arch/csky/include/asm/processor.h
new file mode 100644
index 0000000..bb158cd
--- /dev/null
+++ b/arch/csky/include/asm/processor.h
@@ -0,0 +1,163 @@
+#ifndef __ASM_CSKY_PROCESSOR_H
+#define __ASM_CSKY_PROCESSOR_H
+
+/*
+ * Default implementation of macro that returns current
+ * instruction pointer ("program counter").
+ */
+#define current_text_addr() ({ __label__ _l; _l: &&_l;})
+
+#include <linux/bitops.h>
+#include <asm/segment.h>
+#include <asm/fpu.h>
+#include <asm/ptrace.h>
+#include <asm/current.h>
+#include <asm/cache.h>
+#include <abi/regdef.h>
+
+struct cpuinfo_csky {
+	unsigned long udelay_val;
+	unsigned long asid_cache;
+	/*
+	 * Capability and feature descriptor structure for CSKY CPU
+	 */
+	unsigned long options;
+	unsigned int processor_id[4];
+	unsigned int fpu_id;
+} __attribute__((aligned(SMP_CACHE_BYTES)));
+
+extern struct cpuinfo_csky cpu_data[];
+#define current_cpu_data cpu_data[smp_processor_id()]
+
+
+/* read user stack pointer */
+extern inline unsigned long rdusp(void) {
+	register unsigned long usp;
+#if defined(__CSKYABIV2__)
+        __asm__ __volatile__("mfcr %0, cr<14, 1> \n\r" : "=r" (usp));
+#else
+        __asm__ __volatile__("mfcr %0, ss1\n\r" : "=r" (usp));
+#endif
+	return usp;
+}
+
+/* write user stack pointer
+   Fix me: should not only update user stack pointer in ss1,
+   the user stack pointer saved in stack frame should be update
+   either.*/
+extern inline void wrusp(unsigned long usp) {
+#if defined(__CSKYABIV2__)
+        __asm__ __volatile__("mtcr %0, cr<14, 1> \n\r" : : "r" (usp));
+#else
+        __asm__ __volatile__("mtcr %0, ss1\n\r" : : "r" (usp));
+#endif
+}
+
+/*
+ * User space process size: 2GB. This is hardcoded into a few places,
+ * so don't change it unless you know what you are doing.  TASK_SIZE
+ * for a 64 bit kernel expandable to 8192EB, of which the current CSKY
+ * implementations will "only" be able to use 1TB ...
+ */
+#define TASK_SIZE       0x7fff8000UL
+
+#ifdef __KERNEL__
+#define STACK_TOP       TASK_SIZE
+#define STACK_TOP_MAX   STACK_TOP
+#endif
+
+/* This decides where the kernel will search for a free chunk of vm
+ * space during mmap's.
+ */
+#define TASK_UNMAPPED_BASE      (TASK_SIZE / 3)
+
+struct thread_struct {
+	unsigned long  ksp;       /* kernel stack pointer */
+	unsigned long  usp;       /* user stack pointer */
+	unsigned long  sr;        /* saved status register */
+	unsigned long  esp0;      /* points to SR of stack frame */
+	/* FPU regs */
+	unsigned long  fcr;       /* fpu control reg */
+	unsigned long  fsr;       /* fpu status reg, nothing in CPU_CSKYV2 */
+	unsigned long  fesr;      /* fpu exception status reg */
+	unsigned long  fp[32];    /* fpu general regs.
+ 				      In CPU_CSKYV1(FPU): 32 regs of 32 bits
+ 				        fp[0] store fr0,
+				        fp[1] store fr1...
+ 				      In CPU_CSKYV2(VFP): 16 regs of 64 bits
+				        fp[0] store vr0 low 32 bits,
+				        fp[1] store vr0 high 32 bits... */
+	/* DSP regs */
+	unsigned long  hi;        /* Nothing in CPU_CSKYV2 */
+	unsigned long  lo;        /* Nothing in CPU_CSKYV2 */
+	unsigned long  dspcsr;    /* DSP control and stats reg(cr14) */
+
+	/* Other stuff associated with the thread. */
+	unsigned long address;      /* Last user fault */
+	unsigned long baduaddr;     /* Last kernel fault accessing USEG  */
+	unsigned long error_code;
+	unsigned long trap_no;
+};
+
+#define INIT_THREAD  { \
+	.ksp = (unsigned long) init_thread_union.stack + THREAD_SIZE, \
+	.sr = DEFAULT_PSR_VALUE, \
+}
+
+/*
+ * Do necessary setup to start up a newly executed thread.
+ *
+ * pass the data segment into user programs if it exists,
+ * it can't hurt anything as far as I can tell
+ */
+#define PS_USE_MODE  0x7fffffff
+
+#define start_thread(_regs, _pc, _usp)					\
+do {									\
+	set_fs(USER_DS); /* reads from user space */			\
+	(_regs)->pc = (_pc);						\
+	(_regs)->regs[1] = 0; /* ABIV1 is R7, uClibc_main rtdl arg */	\
+	(_regs)->regs[2] = 0;						\
+	(_regs)->regs[3] = 0; /* ABIV2 is R7, use it? */		\
+	(_regs)->sr &= PS_USE_MODE;					\
+	wrusp(_usp);							\
+} while(0)
+
+/* Forward declaration, a strange C thing */
+struct task_struct;
+
+/* Free all resources held by a thread. */
+static inline void release_thread(struct task_struct *dead_task)
+{
+}
+
+/* Prepare to copy thread state - unlazy all lazy status */
+#define prepare_to_copy(tsk)    do { } while (0)
+
+extern int kernel_thread(int (*fn)(void *), void * arg, unsigned long flags);
+
+#define copy_segments(tsk, mm)		do { } while (0)
+#define release_segments(mm)		do { } while (0)
+#define forget_segments()		do { } while (0)
+
+extern unsigned long thread_saved_pc(struct task_struct *tsk);
+
+unsigned long get_wchan(struct task_struct *p);
+
+#define	KSTK_EIP(tsk)							\
+({									\
+	unsigned long eip = 0;						\
+	if ((tsk)->thread.esp0 > PAGE_SIZE &&				\
+	     MAP_NR((tsk)->thread.esp0) < max_mapnr)			\
+		eip = ((struct pt_regs *) (tsk)->thread.esp0)->pc;	\
+		eip;							\
+})
+
+#define	KSTK_ESP(tsk) ((tsk) == current ? rdusp() : (tsk)->thread.usp)
+
+#define task_pt_regs(p) \
+	((struct pt_regs *)(THREAD_SIZE + task_stack_page(p)) - 1)
+
+#define cpu_relax() barrier()
+
+#endif /* __ASM_CSKY_PROCESSOR_H */
diff --git a/arch/csky/include/asm/ptrace.h b/arch/csky/include/asm/ptrace.h
new file mode 100644
index 0000000..5426e3d
--- /dev/null
+++ b/arch/csky/include/asm/ptrace.h
@@ -0,0 +1,149 @@
+#ifndef _CSKY_PTRACE_H
+#define _CSKY_PTRACE_H
+
+#define REGNO_R0   	0
+#define REGNO_R1   	1
+#define REGNO_R2   	2
+#define REGNO_R3   	3
+#define REGNO_R4   	4
+#define REGNO_R5   	5
+#define REGNO_R6   	6
+#define REGNO_R7   	7
+#define REGNO_R8   	8
+#define REGNO_R9   	9
+#define REGNO_R10  	10
+#define REGNO_R11  	11
+#define REGNO_R12  	12
+#define REGNO_R13  	13
+#define REGNO_R14  	14
+#define REGNO_R15  	15
+#define REGNO_SR   	32
+#define REGNO_PC   	33
+
+#if (__CSKY__ == 2) 
+#define REGNO_R16  	16
+#define REGNO_R17  	17
+#define REGNO_R18  	18
+#define REGNO_R19  	19
+#define REGNO_R20  	20
+#define REGNO_R21  	21
+#define REGNO_R22  	22
+#define REGNO_R23  	23
+#define REGNO_R24  	24
+#define REGNO_R25  	25
+#define REGNO_R26  	26
+#define REGNO_R27  	27
+#define REGNO_R28  	28
+#define REGNO_R29  	29
+#define REGNO_R30  	30
+#define REGNO_R31  	31
+#define REGNO_RHI  	34
+#define REGNO_RLO  	35
+#endif/* (__CSKY__ == 2) */
+
+#if defined(__CSKYABIV2__)
+	#define REGNO_USP  REGNO_R14
+#else
+	#define REGNO_USP  REGNO_R0
+#endif
+
+#ifndef __ASSEMBLY__
+
+/* this struct defines the way the registers are stored on the
+   stack during a system call. */
+struct  pt_regs {
+	unsigned long    pc;
+	long             orig_a0;
+	unsigned long    sr;
+	long             a0;  // ABIV2: r0, ABIV1: r2
+	long             a1;  // ABIV2: r1, ABIV1: r3
+	long             a2;  // ABIV2: r2, ABIV1: r4
+	long             a3;  // ABIV2: r3, ABIV1: r5
+	// ABIV2: r4 ~ r13,  ABIV1: r6 ~ r14, r1.
+	long             regs[10];
+	long             r15;
+#if (__CSKY__ == 2)
+	// r16~r31;
+	long             exregs[16];
+	long             rhi;
+	long             rlo;
+#endif
+};
+
+/*
+ * This is the extended stack used by the context
+ * switcher: it's pushed after the normal "struct pt_regs".
+ *
+ * ABI_CSKYV2: r4 ~ r11,r16 ~ r17, r26 ~ r30;
+ * ABI_CSKYV1: r8 ~ r14,r16 ~ r19, r26 ~ r30.
+ */
+struct  switch_stack {
+#if defined(__CSKYABIV2__)
+	unsigned long   r4;
+        unsigned long   r5;
+        unsigned long   r6;
+        unsigned long   r7;
+#endif
+        unsigned long   r8;
+        unsigned long   r9;
+        unsigned long   r10;
+        unsigned long   r11;
+#if !defined(__CSKYABIV2__)    // ABIV1
+        unsigned long   r12;
+        unsigned long   r13;
+        unsigned long   r14;
+#endif
+        unsigned long   r15;
+#if (__CSKY__ == 2)
+        unsigned long   r16;
+        unsigned long   r17;
+#if !defined(__CSKYABIV2__)    // ABIV1
+        unsigned long   r18;
+        unsigned long   r19;
+#endif
+        unsigned long   r26;
+        unsigned long   r27;
+        unsigned long   r28;
+        unsigned long   r29;
+        unsigned long   r30;
+#endif
+};
+
+/* Arbitrarily choose the same ptrace numbers as used by the Sparc code. */
+#define PTRACE_GETREGS            12
+#define PTRACE_SETREGS            13
+#define PTRACE_GETFPREGS          14
+#define PTRACE_SETFPREGS          15
+#define PTRACE_GET_THREAD_AREA    25
+
+#ifdef __CSKYABIV2__
+#define CSKY_HI_NUM               0xcccccccc
+#define CSKY_LO_NUM               0xcccccccc
+#else
+#define CSKY_HI_NUM               34
+#define CSKY_LO_NUM               35
+#endif
+#define CSKY_GREG_NUM             35
+#define CSKY_FREG_NUM_HI          72
+#define CSKY_FREG_NUM_LO          40
+#define CSKY_FCR_NUM              74
+
+#ifdef __KERNEL__
+
+#ifndef PS_S
+#define PS_S            0x80000000              /* Supervisor Mode */
+#define PS_TM           0x0000c000              /* Trace mode */
+#endif
+#define arch_has_single_step() (1)
+#define current_pt_regs() \
+	(struct pt_regs *)((char *)current_thread_info() + THREAD_SIZE) - 1
+#define current_user_stack_pointer() rdusp()
+
+#define user_mode(regs) (!((regs)->sr & PS_S))
+#define instruction_pointer(regs) ((regs)->pc)
+#define profile_pc(regs) instruction_pointer(regs)
+#define user_stack(regs) (sw_usp)
+extern void show_regs(struct pt_regs *);
+#endif /* __KERNEL__ */
+#endif /* __ASSEMBLY__ */
+#endif /* _CSKY_PTRACE_H */
diff --git a/arch/csky/include/asm/readreg.h b/arch/csky/include/asm/readreg.h
new file mode 100644
index 0000000..ad89f01
--- /dev/null
+++ b/arch/csky/include/asm/readreg.h
@@ -0,0 +1,38 @@
+#ifndef __CSKY_READREG_H
+#define __CSKY_READREG_H
+
+#ifdef __CSKYABIV1__
+static inline unsigned long csky_get_sp(void)
+{
+        int __res;
+        __asm__ __volatile__("mov %0, r0\n\t"
+                             :"=b" (__res));
+        return   __res;
+}
+
+static inline unsigned long read_cpu_ss1(void)
+{
+        int __res;
+        __asm__ __volatile__("mfcr %0, ss1\n\t"
+                             :"=b" (__res));
+        return   __res;
+}
+#else
+static inline unsigned long csky_get_sp(void)
+{
+        int __res;
+        __asm__ __volatile__("mov %0, sp\n\t"
+                             :"=r" (__res));
+        return   __res;
+}
+
+static inline unsigned long read_cpu_usp(void)
+{
+        int __res;
+        __asm__ __volatile__("mfcr %0, cr<14,1>\n\t"
+                                        :"=r" (__res));
+        return   __res;
+}
+#endif
+
+#endif
diff --git a/arch/csky/include/asm/segment.h b/arch/csky/include/asm/segment.h
new file mode 100644
index 0000000..6d19429
--- /dev/null
+++ b/arch/csky/include/asm/segment.h
@@ -0,0 +1,16 @@
+#ifndef __ASM_CSKY_SEGMENT_H
+#define __ASM_CSKY_SEGMENT_H
+
+typedef struct {
+	unsigned long seg;
+} mm_segment_t;
+
+#define KERNEL_DS		((mm_segment_t) { 0xFFFFFFFF })
+#define get_ds()		KERNEL_DS
+
+#define USER_DS			((mm_segment_t) { 0x80000000UL })
+#define get_fs()		(current_thread_info()->addr_limit)
+#define set_fs(x)		(current_thread_info()->addr_limit = (x))
+#define segment_eq(a,b)		((a).seg == (b).seg)
+
+#endif /* __ASM_CSKY_SEGMENT_H */
diff --git a/arch/csky/include/asm/setup.h b/arch/csky/include/asm/setup.h
new file mode 100644
index 0000000..ce56dbf
--- /dev/null
+++ b/arch/csky/include/asm/setup.h
@@ -0,0 +1,38 @@
+#ifndef __ASM_CSKY_SETUP_H
+#define __ASM_CSKY_SETUP_H
+
+#include <linux/types.h>
+#define BOOT_MEM_MAP_MAX        8
+#define BOOT_MEM_RAM            1
+#define BOOT_MEM_ROM_DATA       2
+#define BOOT_MEM_RESERVED       3
+
+#ifdef __KERNEL__
+
+/* Magic number indicating that a tag table is present */
+#define ATAG_MAGIC	0xa2a25441
+
+#include <uapi/asm-generic/setup.h>
+
+#ifndef __ASSEMBLY__
+
+/*
+ * A memory map that's built upon what was determined
+ * or specified on the command line.
+ */
+struct boot_mem_map {
+        int nr_map;
+        struct boot_mem_map_entry {
+                phys_addr_t addr;	/* start of memory segment */
+                phys_addr_t size;	/* size of memory segment */
+                long type;	/* type of memory segment */
+        } map[BOOT_MEM_MAP_MAX];
+};
+
+extern struct boot_mem_map boot_mem_map;
+
+extern void add_memory_region(phys_addr_t start, phys_addr_t size, long type);
+
+#endif /* !__ASSEMBLY__ */
+#endif  /* __KERNEL__ */
+#endif /* __ASM_CSKY_SETUP_H */
diff --git a/arch/csky/include/asm/shmparam.h b/arch/csky/include/asm/shmparam.h
new file mode 100644
index 0000000..273f423
--- /dev/null
+++ b/arch/csky/include/asm/shmparam.h
@@ -0,0 +1,8 @@
+#ifndef __ASM_CSKY_SHMPARAM_H
+#define __ASM_CSKY_SHMPARAM_H
+
+#define SHMLBA	(4 * PAGE_SIZE)
+
+#define __ARCH_FORCE_SHMLBA
+
+#endif /* __ASM_CSKY_SHMPARAM_H */
diff --git a/arch/csky/include/asm/sigcontext.h b/arch/csky/include/asm/sigcontext.h
new file mode 100644
index 0000000..6f6cf5f
--- /dev/null
+++ b/arch/csky/include/asm/sigcontext.h
@@ -0,0 +1,31 @@
+#ifndef _ASM_CSKY_SIGCONTEXT_H
+#define _ASM_CSKY_SIGCONTEXT_H
+
+struct sigcontext {
+	unsigned long   sc_mask;     /* old sigmask */
+        unsigned long   sc_usp;      /* old user stack pointer */
+        unsigned long   sc_a0;
+        unsigned long   sc_a1;
+        unsigned long   sc_a2;
+        unsigned long   sc_a3;
+	// ABIV2: r4 ~ r13; ABIV1: r6 ~ r14, r1.
+        unsigned long   sc_regs[10];
+        unsigned long   sc_r15;
+#if (__CSKY__ == 2)                     /* config CPU=cskyv2(ck800) */
+	// r16 ~ r31;
+        unsigned long   sc_exregs[16];
+        unsigned long   sc_rhi;
+        unsigned long   sc_rlo;
+#endif
+        unsigned long   sc_sr;
+        unsigned long   sc_pc;
+	/* fpu */
+        unsigned long   sc_fcr;
+        unsigned long   sc_fsr;		/* Nothing in CPU_CSKYV2 */
+        unsigned long   sc_fesr;
+        unsigned long   sc_feinst1;	/* Nothing in CPU_CSKYV2 */
+        unsigned long   sc_feinst2;	/* Nothing in CPU_CSKYV2 */
+        unsigned long   sc_fpregs[32];
+};
+
+#endif /* _ASM_CSKY_SIGCONTEXT_H */
diff --git a/arch/csky/include/asm/signal.h b/arch/csky/include/asm/signal.h
new file mode 100644
index 0000000..0a684aa
--- /dev/null
+++ b/arch/csky/include/asm/signal.h
@@ -0,0 +1,162 @@
+#ifndef _CSKY_SIGNAL_H
+#define _CSKY_SIGNAL_H
+
+#define __ARCH_HAS_SA_RESTORER
+#include <linux/types.h>
+
+/* Avoid too many header ordering problems.  */
+struct siginfo;
+
+#ifdef __KERNEL__
+
+/* Most things should be clean enough to redefine this at will, if care
+   is taken to make libc match.  */
+
+#define _NSIG		64
+#define _NSIG_BPW	32
+#define _NSIG_WORDS	(_NSIG / _NSIG_BPW)
+
+typedef unsigned long old_sigset_t;		/* at least 32 bits */
+
+typedef struct {
+	unsigned long sig[_NSIG_WORDS];
+} sigset_t;
+
+#else
+
+/* Here we must cater to libcs that poke about in kernel headers.  */
+
+#define NSIG		32
+typedef unsigned long sigset_t;
+
+#endif /* __KERNEL__ */
+
+#define SIGHUP		 1
+#define SIGINT		 2
+#define SIGQUIT		 3
+#define SIGILL		 4
+#define SIGTRAP		 5
+#define SIGABRT		 6
+#define SIGIOT		 6
+#define SIGBUS		 7
+#define SIGFPE		 8
+#define SIGKILL		 9
+#define SIGUSR1		10
+#define SIGSEGV		11
+#define SIGUSR2		12
+#define SIGPIPE		13
+#define SIGALRM		14
+#define SIGTERM		15
+#define SIGSTKFLT	16
+#define SIGCHLD		17
+#define SIGCONT		18
+#define SIGSTOP		19
+#define SIGTSTP		20
+#define SIGTTIN		21
+#define SIGTTOU		22
+#define SIGURG		23
+#define SIGXCPU		24
+#define SIGXFSZ		25
+#define SIGVTALRM	26
+#define SIGPROF		27
+#define SIGWINCH	28
+#define SIGIO		29
+#define SIGPOLL		SIGIO
+/*
+#define SIGLOST		29
+*/
+#define SIGPWR		30
+#define SIGSYS		31
+#define	SIGUNUSED	31
+
+/* These should not be considered constants from userland.  */
+#define SIGRTMIN	32
+#define SIGRTMAX	(_NSIG-1)
+
+/*
+ * SA_FLAGS values:
+ *
+ * SA_ONSTACK indicates that a registered stack_t will be used.
+ * SA_INTERRUPT is a no-op, but left due to historical reasons. Use the
+ * SA_RESTART flag to get restarting signals (which were the default long ago)
+ * SA_NOCLDSTOP flag to turn off SIGCHLD when children stop.
+ * SA_RESETHAND clears the handler when the signal is delivered.
+ * SA_NOCLDWAIT flag on SIGCHLD to inhibit zombies.
+ * SA_NODEFER prevents the current signal from being masked in the handler.
+ *
+ * SA_ONESHOT and SA_NOMASK are the historical Linux names for the Single
+ * Unix names RESETHAND and NODEFER respectively.
+ */
+#define SA_NOCLDSTOP	0x00000001
+#define SA_NOCLDWAIT	0x00000002 /* not supported yet */
+#define SA_SIGINFO		0x00000004
+#define SA_ONSTACK		0x08000000
+#define SA_RESTART		0x10000000
+#define SA_NODEFER		0x40000000
+#define SA_RESETHAND	0x80000000
+
+#define SA_NOMASK		SA_NODEFER
+#define SA_ONESHOT		SA_RESETHAND
+#define SA_INTERRUPT	0x20000000 /* dummy -- ignored */
+
+/*
+ * sigaltstack controls
+ */
+#define SS_ONSTACK	1
+#define SS_DISABLE	2
+
+#define MINSIGSTKSZ	2048
+#define SIGSTKSZ	8192
+
+#include <asm-generic/signal-defs.h>
+
+#ifdef __KERNEL__
+
+/*
+ * These values of sa_flags are used only by the kernel as part of the
+ * irq handling routines.
+ *
+ * SA_INTERRUPT is also used by the irq handling routines.
+ * SA_SHIRQ is for shared interrupt support on PCI and EISA.
+ */
+#define SA_PROBE			SA_ONESHOT
+#define SA_SAMPLE_RANDOM	SA_RESTART
+#define SA_SHIRQ			0x04000000
+#endif
+
+#define SIG_BLOCK          0	/* for blocking signals */
+#define SIG_UNBLOCK        1	/* for unblocking signals */
+#define SIG_SETMASK        2	/* for setting the signal mask */
+
+#ifndef __KERNEL__
+
+/* Here we must cater to libcs that poke about in kernel headers.  */
+
+struct sigaction {
+	union {
+	  __sighandler_t _sa_handler;
+	  void (*_sa_sigaction)(int, struct siginfo *, void *);
+	} _u;
+	sigset_t sa_mask;
+	unsigned long sa_flags;
+	void (*sa_restorer)(void);
+};
+
+#define sa_handler	_u._sa_handler
+#define sa_sigaction	_u._sa_sigaction
+
+#endif /* __KERNEL__ */
+
+typedef struct sigaltstack {
+	void *ss_sp;
+	int ss_flags;
+	size_t ss_size;
+} stack_t;
+
+#ifdef __KERNEL__
+
+#include <asm/sigcontext.h>
+#define ptrace_signal_deliver() do { } while (0)
+#endif /* __KERNEL__ */
+
+#endif /* _CSKY_SIGNAL_H */
diff --git a/arch/csky/include/asm/string.h b/arch/csky/include/asm/string.h
new file mode 100644
index 0000000..7f7e5d7
--- /dev/null
+++ b/arch/csky/include/asm/string.h
@@ -0,0 +1,17 @@
+#ifndef _CSKY_STRING_MM_H_
+#define _CSKY_STRING_MM_H_
+
+#ifndef __ASSEMBLY__
+#include <linux/types.h>
+#include <linux/compiler.h>
+
+#define __HAVE_ARCH_MEMCPY
+extern void * memcpy(void *to, const void *from, size_t l);
+
+/* New and improved.  In arch/csky/lib/memset.c */
+#define __HAVE_ARCH_MEMSET
+extern void * memset(void *dest, int c, size_t l);
+
+#endif
+
+#endif /* _CSKY_STRING_MM_H_ */
diff --git a/arch/csky/include/asm/swab.h b/arch/csky/include/asm/swab.h
new file mode 100644
index 0000000..094a647
--- /dev/null
+++ b/arch/csky/include/asm/swab.h
@@ -0,0 +1,25 @@
+#ifndef __ASM_CSKY_SWAB_H
+#define __ASM_CSKY_SWAB_H
+
+#include <linux/compiler.h>
+#include <linux/types.h>
+
+#ifdef __CSKYABIV2__
+
+static inline __attribute_const__ __u16 __arch_swab16(__u16 x)
+{
+	__asm__ ("revh %0, %1" : "=r" (x) : "r" (x));
+	return x;
+}
+#define __arch_swab16 __arch_swab16
+
+static inline __attribute_const__ __u32 __arch_swab32(__u32 x)
+{
+	__asm__ ("revb %0, %1" : "=r" (x) : "r" (x));
+	return x;
+}
+#define __arch_swab32 __arch_swab32
+
+#endif /* __CSKYABIV2__ */
+
+#endif /* __ASM_CSKY_SWAB_H */
diff --git a/arch/csky/include/asm/switch_to.h b/arch/csky/include/asm/switch_to.h
new file mode 100644
index 0000000..3f771e5
--- /dev/null
+++ b/arch/csky/include/asm/switch_to.h
@@ -0,0 +1,18 @@
+#ifndef __ASM_CSKY_SWITCH_TO_H
+#define __ASM_CSKY_SWITCH_TO_H
+
+#include <linux/thread_info.h>
+
+/*
+ * TODO: we need change switch_to with thread_info,
+ * and we must move pt_regs from thread to thread_info first.
+ */
+extern struct task_struct *__switch_to(struct task_struct *, struct task_struct *);
+
+#define switch_to(prev,next,last) \
+do{ \
+	last = __switch_to(prev, next); \
+} while (0)
+
+#endif /*__ASM_CSKY_SWITCH_TO_H */
+
diff --git a/arch/csky/include/asm/syscalls.h b/arch/csky/include/asm/syscalls.h
new file mode 100644
index 0000000..da6d1f9
--- /dev/null
+++ b/arch/csky/include/asm/syscalls.h
@@ -0,0 +1,14 @@
+#ifndef __ASM_CSKY_SYSCALLS_H
+#define __ASM_CSKY_SYSCALLS_H
+
+#include <linux/linkage.h>
+
+#include <asm-generic/syscalls.h>
+
+asmlinkage long sys_cacheflush(void __user *, unsigned long, int);
+
+asmlinkage long sys_set_thread_area(unsigned long addr);
+
+asmlinkage long sys_csky_fadvise64_64(int fd, int advice, loff_t offset, loff_t len);
+
+#endif /* __ASM_CSKY_SYSCALLS_H */
diff --git a/arch/csky/include/asm/thread_info.h b/arch/csky/include/asm/thread_info.h
new file mode 100644
index 0000000..236ff0d
--- /dev/null
+++ b/arch/csky/include/asm/thread_info.h
@@ -0,0 +1,75 @@
+#ifndef _ASM_CSKY_THREAD_INFO_H
+#define _ASM_CSKY_THREAD_INFO_H
+
+#ifndef __ASSEMBLY__
+
+#include <asm/types.h>
+#include <asm/page.h>
+#include <abi/regdef.h>
+#include <asm/processor.h>
+
+struct thread_info {
+	struct task_struct	*task;
+	void			*dump_exec_domain;
+	unsigned long		flags;
+	int			preempt_count;
+	unsigned long		tp_value;
+	mm_segment_t		addr_limit;
+	struct restart_block	restart_block;
+	struct pt_regs		*regs;
+};
+
+#define INIT_THREAD_INFO(tsk)			\
+{						\
+	.task		= &tsk,			\
+	.preempt_count  = INIT_PREEMPT_COUNT,	\
+	.addr_limit     = KERNEL_DS,		\
+	.restart_block = {			\
+		.fn = do_no_restart_syscall,	\
+	},					\
+}
+
+#define THREAD_SIZE_ORDER (13 - PAGE_SHIFT)
+
+#define init_thread_info	(init_thread_union.thread_info)
+#define init_stack		(init_thread_union.stack)
+
+static inline struct thread_info *current_thread_info(void)
+{
+	unsigned long sp;
+
+	__asm__ __volatile__(
+			"mov %0, sp\n\t"
+			:"=r"(sp));
+
+	return (struct thread_info *)(sp & ~(THREAD_SIZE - 1));
+}
+
+#endif /* !__ASSEMBLY__ */
+
+/* entry.S relies on these definitions!
+ * bits 0-5 are tested at every exception exit
+ */
+#define TIF_SIGPENDING		0	/* signal pending */
+#define TIF_NOTIFY_RESUME	1       /* callback before returning to user */
+#define TIF_NEED_RESCHED	2	/* rescheduling necessary */
+#define TIF_SYSCALL_TRACE	5	/* syscall trace active */
+#define TIF_DELAYED_TRACE	14	/* single step a syscall */
+#define TIF_POLLING_NRFLAG	16	/* true if poll_idle() is polling TIF_NEED_RESCHED */
+#define TIF_MEMDIE		18      /* is terminating due to OOM killer */
+#define TIF_FREEZE		19	/* thread is freezing for suspend */
+#define TIF_RESTORE_SIGMASK	20	/* restore signal mask in do_signal() */
+#define TIF_SECCOMP		21	/* secure computing */
+
+#define _TIF_SIGPENDING         (1 << TIF_SIGPENDING)
+#define _TIF_NOTIFY_RESUME      (1 << TIF_NOTIFY_RESUME)
+#define _TIF_NEED_RESCHED       (1 << TIF_NEED_RESCHED)
+#define _TIF_SYSCALL_TRACE      (1 << TIF_SYSCALL_TRACE)
+#define _TIF_DELAYED_TRACE	(1 << TIF_DELAYED_TRACE)
+#define _TIF_POLLING_NRFLAG     (1 << TIF_POLLING_NRFLAG)
+#define _TIF_MEMDIE		(1 << TIF_MEMDIE)
+#define _TIF_FREEZE             (1 << TIF_FREEZE)
+#define _TIF_RESTORE_SIGMASK    (1 << TIF_RESTORE_SIGMASK)
+#define _TIF_SECCOMP            (1 << TIF_SECCOMP)
+
+#endif	/* _ASM_CSKY_THREAD_INFO_H */
diff --git a/arch/csky/include/asm/tlb.h b/arch/csky/include/asm/tlb.h
new file mode 100644
index 0000000..8768c93
--- /dev/null
+++ b/arch/csky/include/asm/tlb.h
@@ -0,0 +1,31 @@
+#ifndef __ASM_CSKY_TLB_H
+#define __ASM_CSKY_TLB_H
+
+#include <asm/cacheflush.h>
+
+#define tlb_start_vma(tlb, vma) \
+	do { \
+		if (!tlb->fullmm) \
+		cache_op_range(vma->vm_start, vma->vm_end, \
+			INS_CACHE|DATA_CACHE|CACHE_CLR|CACHE_INV, 0); \
+	}  while (0)
+
+#if defined(CONFIG_MMU_HARD_REFILL) && !defined(__ck807__)
+/*
+ * FIXME: may be use function flush_tlb_range like other arch.
+ */
+#define tlb_end_vma(tlb, vma) \
+	do { \
+		if (!tlb->fullmm) \
+		cache_op_range(vma->vm_start, vma->vm_end, \
+			INS_CACHE|DATA_CACHE|CACHE_CLR|CACHE_INV, 0); \
+	}  while (0)
+#else
+#define tlb_end_vma(tlb, vma) do {} while(0)
+#endif
+
+#define tlb_flush(tlb)	flush_tlb_mm((tlb)->mm)
+
+#include <asm-generic/tlb.h>
+
+#endif /* __ASM_CSKY_TLB_H */
diff --git a/arch/csky/include/asm/tlbflush.h b/arch/csky/include/asm/tlbflush.h
new file mode 100644
index 0000000..bb42ce9
--- /dev/null
+++ b/arch/csky/include/asm/tlbflush.h
@@ -0,0 +1,28 @@
+#ifndef __ASM_TLBFLUSH_H
+#define __ASM_TLBFLUSH_H
+/*
+ * TLB flushing:
+ *
+ *  - flush_tlb_all() flushes all processes TLB entries
+ *  - flush_tlb_mm(mm) flushes the specified mm context TLB entries
+ *  - flush_tlb_page(vma, vmaddr) flushes one page
+ *  - flush_tlb_range(vma, start, end) flushes a range of pages
+ *  - flush_tlb_kernel_range(start, end) flushes a range of kernel pages
+ */
+extern void local_flush_tlb_all(void);
+extern void local_flush_tlb_mm(struct mm_struct *mm);
+extern void local_flush_tlb_page(struct vm_area_struct *vma, unsigned long page);
+extern void local_flush_tlb_range(struct vm_area_struct *vma, unsigned long start, unsigned long end);
+extern void local_flush_tlb_kernel_range(unsigned long start, unsigned long end);
+
+extern void local_flush_tlb_one(unsigned long vaddr);
+
+#define flush_tlb_all()                 local_flush_tlb_all()
+#define flush_tlb_mm(mm)                local_flush_tlb_mm(mm)
+#define flush_tlb_range(vma, vmaddr, end)   \
+        local_flush_tlb_range(vma, vmaddr, end)
+#define flush_tlb_kernel_range(vmaddr,end) \
+        local_flush_tlb_kernel_range(vmaddr, end)
+#define flush_tlb_page(vma, page)       local_flush_tlb_page(vma, page)
+
+#endif
diff --git a/arch/csky/include/asm/traps.h b/arch/csky/include/asm/traps.h
new file mode 100644
index 0000000..b43c3b4
--- /dev/null
+++ b/arch/csky/include/asm/traps.h
@@ -0,0 +1,142 @@
+#ifndef __ASM_CSKY_TRAPS_H
+#define __ASM_CSKY_TRAPS_H
+
+#ifndef __ASSEMBLY__
+
+#include <linux/linkage.h>
+#include <asm/ptrace.h>
+
+typedef void (*e_vector)(void);
+
+#endif
+
+#define VEC_RESET       0
+#define VEC_ALIGN       1
+#define VEC_ACCESS      2
+#define VEC_ZERODIV     3
+#define VEC_ILLEGAL     4
+#define VEC_PRIV        5
+#define VEC_TRACE       6
+#define VEC_BREAKPOINT  7
+#define VEC_UNRECOVER   8
+#define VEC_SOFTRESET   9
+#define VEC_AUTOVEC     10
+#define VEC_FAUTOVEC    11
+#define VEC_HWACCEL     12
+
+#define	VEC_TLBMISS	    14
+#define	VEC_TLBMODIFIED	15
+
+#define VEC_TRAP0       16
+#define VEC_TRAP1       17
+#define VEC_TRAP2       18
+#define VEC_TRAP3       19
+
+#define	VEC_TLBINVALIDL	20
+#define	VEC_TLBINVALIDS	21
+
+#define VEC_PRFL        29
+#define VEC_FPE         30
+
+#define VEC_USER        32
+
+#define VEC_INT1        33
+#define VEC_INT2        34
+#define VEC_INT3        35
+#define VEC_INT4        36
+#define VEC_INT5        37
+#define VEC_INT6        38
+#define VEC_INT7        39
+#define VEC_INT8        40
+
+#define VECOFF(vec)     ((vec)<<2)
+
+#ifndef __ASSEMBLY__
+
+/* Status register bits */
+#define PS_S            0x80000000              /* Supervisor Mode */
+#define PS_TM           0x0000c000              /* Trace mode */
+#define PS_TP           0x00002000              /* Trace pending */
+#define PS_TC           0x00001000              /* Translation control */
+#define PS_SC           0x00000400              /* Spare control */
+#define PS_MM           0x00000200              /* Extern memory manager */
+#define PS_EE           0x00000100              /* Exception enable */
+#define PS_IC           0x00000080              /* Interrupt Control */
+#define PS_IE           0x00000040              /* Interrupt enable */
+#define PS_FE           0x00000010              /* Fast interrupt enable */
+#define PS_AF           0x00000002              /* Alternate register file */
+#define PS_C            0x00000001              /* Carrier */
+
+#define PS_VECMASK      0x007f0000              /* VEC mask */
+
+
+
+/* structure for stack frames */
+
+struct frame {
+    struct pt_regs ptregs;
+    union {
+	    struct {
+		    unsigned long  iaddr;    /* instruction address */
+	    } fmt2;
+	    struct {
+		    unsigned long  effaddr;  /* effective address */
+	    } fmt3;
+	    struct {
+		    unsigned long  effaddr;  /* effective address */
+		    unsigned long  pc;	     /* pc of faulted instr */
+	    } fmt4;
+	    struct {
+		    unsigned long  effaddr;  /* effective address */
+		    unsigned short ssw;      /* special status word */
+		    unsigned short wb3s;     /* write back 3 status */
+		    unsigned short wb2s;     /* write back 2 status */
+		    unsigned short wb1s;     /* write back 1 status */
+		    unsigned long  faddr;    /* fault address */
+		    unsigned long  wb3a;     /* write back 3 address */
+		    unsigned long  wb3d;     /* write back 3 data */
+		    unsigned long  wb2a;     /* write back 2 address */
+		    unsigned long  wb2d;     /* write back 2 data */
+		    unsigned long  wb1a;     /* write back 1 address */
+		    unsigned long  wb1dpd0;  /* write back 1 data/push data 0*/
+		    unsigned long  pd1;      /* push data 1*/
+		    unsigned long  pd2;      /* push data 2*/
+		    unsigned long  pd3;      /* push data 3*/
+	    } fmt7;
+	    struct {
+		    unsigned long  iaddr;    /* instruction address */
+		    unsigned short int1[4];  /* internal registers */
+	    } fmt9;
+	    struct {
+		    unsigned short int1;
+		    unsigned short ssw;      /* special status word */
+		    unsigned short isc;      /* instruction stage c */
+		    unsigned short isb;      /* instruction stage b */
+		    unsigned long  daddr;    /* data cycle fault address */
+		    unsigned short int2[2];
+		    unsigned long  dobuf;    /* data cycle output buffer */
+		    unsigned short int3[2];
+	    } fmta;
+	    struct {
+		    unsigned short int1;
+		    unsigned short ssw;     /* special status word */
+		    unsigned short isc;     /* instruction stage c */
+		    unsigned short isb;     /* instruction stage b */
+		    unsigned long  daddr;   /* data cycle fault address */
+		    unsigned short int2[2];
+		    unsigned long  dobuf;   /* data cycle output buffer */
+		    unsigned short int3[4];
+		    unsigned long  baddr;   /* stage B address */
+		    unsigned short int4[2];
+		    unsigned long  dibuf;   /* data cycle input buffer */
+		    unsigned short int5[3];
+		    unsigned	   ver : 4; /* stack frame version # */
+		    unsigned	   int6:12;
+		    unsigned short int7[18];
+	    } fmtb;
+    } un;
+};
+
+#endif /* __ASSEMBLY__ */
+
+#endif /* __ASM_CSKY_TRAPS_H */
diff --git a/arch/csky/include/asm/uaccess.h b/arch/csky/include/asm/uaccess.h
new file mode 100644
index 0000000..0ca4e6b
--- /dev/null
+++ b/arch/csky/include/asm/uaccess.h
@@ -0,0 +1,412 @@
+#ifndef __ASM_CSKY_UACCESS_H
+#define __ASM_CSKY_UACCESS_H
+
+/*
+ * User space memory access functions
+ */
+#include <linux/compiler.h>
+#include <linux/errno.h>
+#include <linux/types.h>
+#include <linux/sched.h>
+#include <linux/mm.h>
+#include <linux/string.h>
+#include <asm/segment.h>
+
+#define VERIFY_READ	0
+#define VERIFY_WRITE	1
+
+/* We let the MMU do all checking */
+static inline int access_ok(int type, const void * addr, unsigned long size)
+{
+    return (((unsigned long)addr < current_thread_info()->addr_limit.seg) &&
+              ((unsigned long)(addr + size) < current_thread_info()->addr_limit.seg));
+}
+/*
+static inline int access_ok(int type, const void * addr, unsigned long size)
+{
+   return 1;
+}
+*/
+
+static inline int verify_area(int type, const void * addr, unsigned long size)
+{
+    return access_ok(type, addr, size) ? 0 : -EFAULT;
+}
+
+#define __addr_ok(addr) (access_ok(VERIFY_READ, addr,0))
+
+extern int __put_user_bad(void);
+
+/*
+ * Tell gcc we read from memory instead of writing: this is because
+ * we do not write to any memory gcc knows about, so there are no
+ * aliasing issues.
+ */
+
+/*
+ * These are the main single-value transfer routines.  They automatically
+ * use the right size if we just have the right pointer type.
+ *
+ * This gets kind of ugly. We want to return _two_ values in "get_user()"
+ * and yet we don't want to do any pointers, because that is too much
+ * of a performance impact. Thus we have a few rather ugly macros here,
+ * and hide all the ugliness from the user.
+ *
+ * The "__xxx" versions of the user access functions are versions that
+ * do not verify the address space, that must have been done previously
+ * with a separate "access_ok()" call (this is used when we do multiple
+ * accesses to the same area of user memory).
+ *
+ * As we use the same address space for kernel and user data on
+ * Ckcore, we can just do these as direct assignments.  (Of course, the
+ * exception handling means that it's no longer "just"...)
+ */
+
+#define put_user(x,ptr) \
+  __put_user_check((x), (ptr), sizeof(*(ptr)))
+
+#define __put_user(x,ptr) \
+  __put_user_nocheck((x), (ptr), sizeof(*(ptr)))
+
+#define __ptr(x) ((unsigned long *)(x))
+
+#define get_user(x,ptr) \
+  __get_user_check((x), (ptr), sizeof(*(ptr)))
+
+#define __get_user(x,ptr) \
+  __get_user_nocheck((x), (ptr), sizeof(*(ptr)))
+
+#define __put_user_nocheck(x, ptr, size)                                \
+({                                                                      \
+	long __pu_err=0;                                                \
+	typeof(*(ptr)) *__pu_addr = (ptr);                              \
+	typeof(*(ptr)) __pu_val = (typeof(*(ptr)))(x);                  \
+	if(__pu_addr){                                                  \
+		__put_user_size(__pu_val, (__pu_addr), (size), __pu_err);   \
+	}                                                               \
+	__pu_err;                                                       \
+})
+
+#define __put_user_check(x,ptr,size)                                    \
+({                                                                      \
+	long __pu_err = -EFAULT;                                        \
+	typeof(*(ptr)) *__pu_addr = (ptr);                              \
+	typeof(*(ptr)) __pu_val = (typeof(*(ptr)))(x);                  \
+	if (access_ok(VERIFY_WRITE, __pu_addr, size) && __pu_addr)      \
+		__put_user_size(__pu_val, __pu_addr, (size), __pu_err); \
+	__pu_err;                                                       \
+})
+
+#define __put_user_size(x,ptr,size,retval)                              \
+do {                                                                    \
+	retval = 0;                                                     \
+	switch (size) {                                                 \
+		case 1: __put_user_asm_b(x, ptr, retval); break;        \
+		case 2: __put_user_asm_h(x, ptr, retval); break;        \
+		case 4: __put_user_asm_w(x, ptr, retval); break;        \
+		case 8: __put_user_asm_64(x, ptr, retval); break;       \
+		default: __put_user_bad();                              \
+	}	                                                        \
+} while (0)
+
+/*
+ * We don't tell gcc that we are accessing memory, but this is OK
+ * because we do not write to any memory gcc knows about, so there
+ * are no aliasing issues.
+ *
+ * Note that PC at a fault is the address *after* the faulting
+ * instruction.
+ */
+#define __put_user_asm_b(x, ptr, err)                           \
+do{                                                             \
+	int errcode;                                            \
+	 __asm__ __volatile__(                                  \
+	         "1:     stb   %1, (%2,0)        \n"            \
+	         "       br    3f                \n"            \
+	         "2:     mov   %0, %3            \n"            \
+	         "       br    3f                \n"            \
+	         ".section __ex_table,\"a\"      \n"            \
+	         ".align   2                     \n"            \
+	         ".long    1b,2b                 \n"            \
+	         ".previous                      \n"            \
+	          "3:                            \n"            \
+	         : "=r"(err), "=r"(x), "=r"(ptr), "=r"(errcode)  \
+	         : "0"(err), "1"(x), "2"(ptr), "3"(-EFAULT)      \
+	         : "memory");                                   \
+}while(0)
+
+#define __put_user_asm_h(x, ptr, err)                           \
+do{                                                             \
+	int errcode;                                            \
+	 __asm__ __volatile__(                                  \
+	         "1:     sth   %1, (%2,0)        \n"            \
+	         "       br    3f                \n"            \
+	         "2:     mov   %0, %3            \n"            \
+	         "       br    3f                \n"            \
+	         ".section __ex_table,\"a\"      \n"            \
+	         ".align   2                     \n"            \
+	         ".long    1b,2b                 \n"            \
+	         ".previous                      \n"            \
+	          "3:                            \n"            \
+	         :"=r"(err), "=r"(x), "=r"(ptr), "=r"(errcode)  \
+	         :"0"(err), "1"(x), "2"(ptr), "3"(-EFAULT)      \
+	         : "memory");                                   \
+}while(0)
+
+#define __put_user_asm_w(x, ptr, err)                           \
+do{                                                             \
+	int errcode;                                            \
+	 __asm__ __volatile__(                                  \
+	         "1:     stw   %1, (%2,0)        \n"            \
+	         "       br    3f                \n"            \
+	         "2:     mov   %0, %3            \n"            \
+	         "       br    3f                \n"            \
+	         ".section __ex_table,\"a\"      \n"            \
+	         ".align   2                     \n"            \
+	         ".long    1b,2b                 \n"            \
+	         ".previous                      \n"            \
+	          "3:                            \n"            \
+	         :"=r"(err), "=r"(x), "=r"(ptr), "=r"(errcode)  \
+	         :"0"(err), "1"(x), "2"(ptr), "3"(-EFAULT)      \
+	         : "memory");                                   \
+}while(0)
+
+
+#define __put_user_asm_64(x, ptr, err)                          \
+do{                                                             \
+	int tmp;                                                \
+	int errcode;                                            \
+	typeof(*(ptr)) src = ( typeof(*(ptr)))x;                \
+	typeof(*(ptr)) *psrc = &src;                            \
+	                                                        \
+	__asm__ __volatile__(                                   \
+	        "     ldw     %3, (%1, 0)     \n"               \
+	        "1:   stw     %3, (%2, 0)     \n"               \
+	        "     ldw     %3, (%1, 4)     \n"               \
+	        "2:   stw     %3, (%2, 4)     \n"               \
+	        "     br      4f              \n"               \
+	        "3:   mov     %0, %4          \n"               \
+	        "     br      4f              \n"               \
+	        ".section __ex_table, \"a\"   \n"               \
+	        ".align   2                   \n"               \
+	        ".long    1b, 3b              \n"               \
+	        ".long    2b, 3b              \n"               \
+	        ".previous                    \n"               \
+	        "4:                           \n"               \
+	        :"=r"(err), "=r"(psrc), "=r"(ptr), "=r"(tmp), "=r"(errcode) \
+	        : "0"(err), "1"(psrc), "2"(ptr), "3"(0), "4"(-EFAULT)       \
+	        : "memory" );                                   \
+}while (0)
+
+#define __get_user_nocheck(x, ptr, size)                        \
+({                                                              \
+	long  __gu_err;	                                        \
+	__get_user_size(x, (ptr), (size), __gu_err);            \
+	__gu_err;                                               \
+})
+
+#define __get_user_check(x, ptr, size)                          \
+({                                                              \
+	int __gu_err = -EFAULT;	                                \
+	const __typeof__(*(ptr)) __user * __gu_ptr = (ptr);     \
+	if (access_ok(VERIFY_READ, __gu_ptr, size) && __gu_ptr) \
+		__get_user_size(x, __gu_ptr, (size), __gu_err); \
+	__gu_err;                                               \
+})
+
+#define __get_user_size(x, ptr, size, retval)                   \
+do {                                                            \
+	switch (size) {                                         \
+		case 1: __get_user_asm_common((x),ptr,"ldb",retval); break; \
+		case 2: __get_user_asm_common((x),ptr,"ldh",retval); break; \
+		case 4: __get_user_asm_common((x),ptr,"ldw",retval); break; \
+		default:                                        \
+			x=0;                                    \
+			(retval) = __get_user_bad();            \
+	}                                                       \
+} while (0)
+
+#define __get_user_asm_common(x, ptr, ins, err)                 \
+do{                                                             \
+	int errcode;                                            \
+	__asm__ __volatile__(                                   \
+	        "1:   " ins "   %1, (%4,0)      \n"             \
+	        "       br    3f                \n"             \
+	        /* Fix up codes */                              \
+	        "2:     mov   %0, %2            \n"             \
+	        "       movi  %1, 0             \n"             \
+	        "       br    3f                \n"             \
+	        ".section __ex_table,\"a\"      \n"             \
+	        ".align   2                     \n"             \
+	        ".long    1b,2b                 \n"             \
+	        ".previous                      \n"             \
+	        "3:                            \n"              \
+	        :"=r"(err), "=r"(x), "=r"(errcode)              \
+	        :"0"(0), "r"(ptr), "2"(-EFAULT)                 \
+	        : "memory");                                    \
+}while(0)
+
+extern int __get_user_bad(void);
+
+#define __copy_user(to, from, n)                                \
+do{                                                             \
+	int w0, w1, w2, w3;                                     \
+	__asm__ __volatile__(                                   \
+		"0:     cmpnei  %1, 0           \n"             \
+		"       bf      8f              \n"             \
+		"       mov     %3, %1          \n"             \
+		"       or      %3, %2          \n"             \
+		"       andi    %3, 3           \n"             \
+		"       cmpnei  %3, 0           \n"             \
+		"       bf      1f              \n"             \
+		"       br      5f              \n"             \
+		"1:     cmplti  %0, 16          \n"   /* 4W */  \
+		"       bt      3f              \n"             \
+		"       ldw     %3, (%2, 0)     \n"             \
+		"       ldw     %4, (%2, 4)     \n"             \
+		"       ldw     %5, (%2, 8)     \n"             \
+		"       ldw     %6, (%2, 12)    \n"             \
+		"2:     stw     %3, (%1, 0)     \n"             \
+		"9:     stw     %4, (%1, 4)     \n"             \
+		"10:    stw     %5, (%1, 8)     \n"             \
+		"11:    stw     %6, (%1, 12)    \n"             \
+		"       addi    %2, 16          \n"             \
+		"       addi    %1, 16          \n"             \
+		"       subi    %0, 16          \n"             \
+		"       br      1b              \n"             \
+		"3:     cmplti  %0, 4           \n"  /* 1W */   \
+		"       bt      5f              \n"             \
+		"       ldw     %3, (%2, 0)     \n"             \
+		"4:     stw     %3, (%1, 0)     \n"             \
+		"       addi    %2, 4           \n"             \
+		"       addi    %1, 4           \n"             \
+		"       subi    %0, 4           \n"             \
+		"       br      3b              \n"             \
+		"5:     cmpnei  %0, 0           \n"  /* 1B */   \
+		"       bf      8f              \n"             \
+		"       ldb     %3, (%2, 0)     \n"             \
+		"6:     stb     %3, (%1, 0)     \n"             \
+		"       addi    %2,  1          \n"             \
+		"       addi    %1,  1          \n"             \
+		"       subi    %0,  1          \n"             \
+		"       br      5b              \n"             \
+		"7:     br      8f              \n"             \
+		".section __ex_table, \"a\"     \n"             \
+		".align   2                     \n"             \
+		".long    2b, 7b                \n"             \
+		".long    9b, 7b                \n"             \
+		".long   10b, 7b                \n"             \
+		".long   11b, 7b                \n"             \
+		".long    4b, 7b                \n"             \
+		".long    6b, 7b                \n"             \
+		".previous                      \n"             \
+		"8:                             \n"             \
+	        : "=r"(n), "=r"(to), "=r"(from), "=r"(w0), "=r"(w1), "=r"(w2), "=r"(w3)   \
+		: "0"(n), "1"(to), "2"(from)                    \
+		: "memory" );                                   \
+} while (0)
+
+#define __copy_user_zeroing(to, from, n) \
+do{                                                             \
+	int tmp;                                                \
+	int nsave;                                              \
+	__asm__ __volatile__(                                   \
+		"0:     cmpnei  %1, 0           \n"             \
+		"       bf      7f              \n"             \
+		"       mov     %3, %1          \n"             \
+		"       or      %3, %2          \n"             \
+		"       andi    %3, 3           \n"             \
+		"       cmpnei  %3, 0           \n"             \
+		"       bf      1f              \n"             \
+		"       br      5f              \n"             \
+		"1:     cmplti  %0, 16          \n"   /* 4W */  \
+		"       bt      3f              \n"             \
+		"2:     ldw     %3, (%2, 0)     \n"             \
+		"10:    ldw     %4, (%2, 4)     \n"             \
+		"       stw     %3, (%1, 0)     \n"             \
+		"       stw     %4, (%1, 4)     \n"             \
+		"11:    ldw     %3, (%2, 8)     \n"             \
+		"12:    ldw     %4, (%2, 12)    \n"             \
+		"       stw     %3, (%1, 8)     \n"             \
+		"       stw     %4, (%1, 12)    \n"             \
+		"       addi    %2, 16          \n"             \
+		"       addi    %1, 16          \n"             \
+		"       subi    %0, 16          \n"             \
+		"       br      1b              \n"             \
+		"3:     cmplti  %0, 4           \n"  /* 1W */   \
+		"       bt      5f              \n"             \
+		"4:     ldw     %3, (%2, 0)     \n"             \
+		"       stw     %3, (%1, 0)     \n"             \
+		"       addi    %2, 4           \n"             \
+		"       addi    %1, 4           \n"             \
+		"       subi    %0, 4           \n"             \
+		"       br      3b              \n"             \
+		"5:     cmpnei  %0, 0           \n"  /* 1B */   \
+		"       bf      7f              \n"             \
+		"6:     ldb     %3, (%2, 0)     \n"             \
+		"       stb     %3, (%1, 0)     \n"             \
+		"       addi    %2,  1          \n"             \
+		"       addi    %1,  1          \n"             \
+		"       subi    %0,  1          \n"             \
+		"       br      5b              \n"             \
+		"8:     mov     %3, %0          \n" /* zero */  \
+		"       movi    %4, 0           \n"             \
+		"9:     stb     %4, (%1, 0)     \n"             \
+		"       addi    %1, 1           \n"             \
+		"       subi    %3, 1           \n"             \
+		"       cmpnei  %3, 0           \n"             \
+		"       bt      9b              \n"             \
+		"       br      7f              \n"             \
+		".section __ex_table, \"a\"     \n"             \
+		".align   2                     \n"             \
+		".long    2b, 8b                \n"             \
+		".long   10b, 8b                \n"             \
+		".long   11b, 8b                \n"             \
+		".long   12b, 8b                \n"             \
+		".long    4b, 8b                \n"             \
+		".long    6b, 8b                \n"             \
+		".previous                      \n"             \
+		"7:                             \n"             \
+		: "=r"(n), "=r"(to), "=r"(from), "=r"(nsave), "=r"(tmp)   \
+		: "0"(n), "1"(to), "2"(from)                    \
+		: "memory" );                                   \
+} while (0)
+
+unsigned long __generic_copy_from_user(void *to, const void *from, unsigned long n);
+unsigned long __generic_copy_to_user(void *to, const void *from, unsigned long n);
+
+#define copy_from_user(to, from, n) __generic_copy_from_user(to, from, n)
+#define copy_to_user(to, from, n) __generic_copy_to_user(to, from, n)
+
+#define __copy_from_user(to, from, n) copy_from_user(to, from, n)
+#define __copy_to_user(to, from, n) copy_to_user(to, from, n)
+unsigned long clear_user(void *to, unsigned long n);
+unsigned long __clear_user(void __user *to, unsigned long n);
+
+#define __copy_to_user_inatomic         __copy_to_user
+#define __copy_from_user_inatomic       __copy_from_user
+
+long strncpy_from_user(char *dst, const char *src, long count);
+long __strncpy_from_user(char *dst, const char *src, long count);
+
+/*
+ * Return the size of a string (including the ending 0)
+ *
+ * Return 0 on exception, a value greater than N if too long
+ */
+long strnlen_user(const char *src, long n);
+
+#define strlen_user(str) strnlen_user(str, 32767)
+
+/*
+ * Zero Userspace
+ */
+struct exception_table_entry
+{
+	unsigned long insn;
+	unsigned long nextinsn;
+};
+
+extern int fixup_exception(struct pt_regs *regs);
+
+#endif /* __ASM_CSKY_UACCESS_H */
diff --git a/arch/csky/include/asm/unistd.h b/arch/csky/include/asm/unistd.h
new file mode 100644
index 0000000..6517aa4
--- /dev/null
+++ b/arch/csky/include/asm/unistd.h
@@ -0,0 +1,2 @@
+#include <uapi/asm/unistd.h>
+
diff --git a/arch/csky/include/asm/user.h b/arch/csky/include/asm/user.h
new file mode 100644
index 0000000..dbbe771
--- /dev/null
+++ b/arch/csky/include/asm/user.h
@@ -0,0 +1,100 @@
+#ifndef __ASM_CSKY_USER_H
+#define __ASM_CSKY_USER_H
+
+#include <asm/page.h>
+#include <asm/ptrace.h>
+/*
+ *  Core file format: The core file is written in such a way that gdb
+ *  can understand it and provide useful information to the user (under
+ *  linux we use the 'trad-core' bfd).  There are quite a number of
+ *  obstacles to being able to view the contents of the floating point
+ *  registers, and until these are solved you will not be able to view the
+ *  contents of them.  Actually, you can read in the core file and look at
+ *  the contents of the user struct to find out what the floating point
+ *  registers contain.
+ *  The actual file contents are as follows:
+ *  UPAGE: 1 page consisting of a user struct that tells gdb what is present
+ *  in the file.  Directly after this is a copy of the task_struct, which
+ *  is currently not used by gdb, but it may come in useful at some point.
+ *  All of the registers are stored as part of the upage.  The upage should
+ *  always be only one page.
+ *  DATA: The data area is stored.  We use current->end_text to
+ *  current->brk to pick up all of the user variables, plus any memory
+ *  that may have been malloced.  No attempt is made to determine if a page
+ *  is demand-zero or if a page is totally unused, we just cover the entire
+ *  range.  All of the addresses are rounded in such a way that an integral
+ *  number of pages is written.
+ *  STACK: We need the stack information in order to get a meaningful
+ *  backtrace.  We need to write the data from (esp) to
+ *  current->start_stack, so we round each of these off in order to be able
+ *  to write an integer number of pages.
+ *  The minimum core file size is 3 pages, or 12288 bytes.
+ */
+
+struct user_cskyfp_struct {
+	unsigned long  fcr;         /* fpu control reg */
+	unsigned long  fsr;         /* fpu status reg, nothing in CPU_CSKYV2 */
+	unsigned long  fesr;        /* fpu exception status reg */
+	unsigned long  fp[32];      /* fpu general regs */
+};
+
+/*
+ * This is the old layout of "struct pt_regs" as of Linux 1.x, and
+ * is still the layout used by user (the new pt_regs doesn't have
+ * all registers).
+ *
+ * In this struct, both ABIV1 & ABIV2 have the same general regs:
+ * CSKY ABIv1: r0 ~ r31, psr, pc, hi, lo
+ * CSKY ABIv2: r0 ~ r31, psr, pc, hi, lo
+ * but in CSKY ABIV1, r16 ~ r31 don't exist, so in ABIV1, they are zero.
+ */
+struct user_regs_struct {
+      unsigned long	gregs[32];  // ABIV1, usp = r0; ABIV2, usp = r14
+      unsigned long	psr;
+      unsigned long	pc;
+      unsigned long	hi;
+      unsigned long	lo;
+};
+
+/* user_regs_struct->gregs[REG_WHY].
+ * flag: 0: enter system call
+ *       1: leave system call
+ */
+#define REG_WHY  9
+
+/*
+ * When the kernel dumps core, it starts by dumping the user struct -
+ * this will be used by gdb to figure out where the data and stack segments
+ * are within the file, and what virtual addresses to use.
+ */
+struct user{
+/* We start with the registers, to mimic the way that "memory" is returned
+   from the ptrace(3,...) function.  */
+	struct user_regs_struct  regs;	/* Where the registers are actually stored */
+	int                 u_fpvalid;  /* True if math co-processor being used. */
+
+/* The rest of this junk is to help gdb figure out what goes where */
+	unsigned long int   u_tsize;	/* Text segment size (pages). */
+	unsigned long int   u_dsize;	/* Data segment size (pages). */
+	unsigned long int   u_ssize;	/* Stack segment size (pages). */
+	unsigned long       start_code; /* Starting virtual address of text. */
+	unsigned long       start_stack;/* Starting virtual address of stack area.
+				   					   This is actually the bottom of the stack,
+				      				   the top of the stack is always found in
+									    the esp register.  */
+	long int            signal;     /* Signal that caused the core dump. */
+	int                 reserved;	/* No longer used */
+	unsigned long       u_ar0;		/* Used by gdb to help find the values
+										for the registers. */
+	unsigned long       magic;		/* To uniquely identify a core file */
+	char                u_comm[32];	/* User command that was responsible */
+	struct user_cskyfp_struct  u_fp;   /* Floating point registers */
+	struct user_cskyfp_struct* u_fpstate;	/* Math Co-processor pointer. */
+};
+
+#define NBPG 4096
+#define UPAGES 1
+#define HOST_TEXT_START_ADDR (u.start_code)
+#define HOST_STACK_END_ADDR (u.start_stack + u.u_ssize * NBPG)
+
+#endif /* __ASM_CSKY_USER_H */
diff --git a/arch/csky/include/asm/vdso.h b/arch/csky/include/asm/vdso.h
new file mode 100644
index 0000000..b6b2765
--- /dev/null
+++ b/arch/csky/include/asm/vdso.h
@@ -0,0 +1,8 @@
+#ifndef __ASM_CSKY_VDSO_H
+#define __ASM_CSKY_VDSO_H
+
+struct csky_vdso {
+	unsigned short rt_signal_retcode[4];
+};
+
+#endif /* __ASM_CSKY_VDSO_H */
diff --git a/arch/csky/include/uapi/asm/Kbuild b/arch/csky/include/uapi/asm/Kbuild
new file mode 100644
index 0000000..0b86648
--- /dev/null
+++ b/arch/csky/include/uapi/asm/Kbuild
@@ -0,0 +1,5 @@
+include include/uapi/asm-generic/Kbuild.asm
+
+header-y	+= cachectl.h
+header-y	+= stat.h
+
diff --git a/arch/csky/include/uapi/asm/cachectl.h b/arch/csky/include/uapi/asm/cachectl.h
new file mode 100644
index 0000000..c63285c
--- /dev/null
+++ b/arch/csky/include/uapi/asm/cachectl.h
@@ -0,0 +1,21 @@
+#ifndef __ASM_CSKY_CACHECTL_H
+#define __ASM_CSKY_CACHECTL_H
+
+/*
+ * Options for cacheflush system call
+ *
+ * cacheflush() is currently fluch_cache_all().
+ */
+#define ICACHE  (1<<0)      /* flush instruction cache        */
+#define DCACHE  (1<<1)      /* writeback and flush data cache */
+#define BCACHE  (ICACHE|DCACHE) /* flush both caches              */
+
+/*
+ * Caching modes for the cachectl(2) call
+ *
+ * cachectl(2) is currently not supported and returns ENOSYS.
+ */
+#define CACHEABLE   0   /* make pages cacheable */
+#define UNCACHEABLE 1   /* make pages uncacheable */
+
+#endif /* __ASM_CSKY_CACHECTL_H */
diff --git a/arch/csky/include/uapi/asm/stat.h b/arch/csky/include/uapi/asm/stat.h
new file mode 100644
index 0000000..1f110ca
--- /dev/null
+++ b/arch/csky/include/uapi/asm/stat.h
@@ -0,0 +1,84 @@
+#ifndef _CSKY_STAT_H
+#define _CSKY_STAT_H
+
+struct __old_kernel_stat {
+	unsigned short st_dev;
+	unsigned short st_ino;
+	unsigned short st_mode;
+	unsigned short st_nlink;
+	unsigned short st_uid;
+	unsigned short st_gid;
+	unsigned short st_rdev;
+	unsigned long  st_size;
+	unsigned long  st_atime;
+	unsigned long  st_mtime;
+	unsigned long  st_ctime;
+};
+
+#define STAT_HAVE_NSEC 
+
+struct stat {
+#if defined(__cskyBE__)
+	unsigned short st_dev;
+	unsigned short __pad1;
+#else
+	unsigned long  st_dev;
+#endif
+	unsigned long  st_ino;
+	unsigned short st_mode;
+	unsigned short st_nlink;
+	unsigned short st_uid;
+	unsigned short st_gid;
+#if defined(__cskyBE__)
+	unsigned short st_rdev;
+	unsigned short __pad2;
+#else
+	unsigned long  st_rdev;
+#endif
+	unsigned long  st_size;
+	unsigned long  st_blksize;
+	unsigned long  st_blocks;
+	unsigned long  st_atime;
+	unsigned long  st_atime_nsec;
+	unsigned long  st_mtime;
+	unsigned long  st_mtime_nsec;
+	unsigned long  st_ctime;
+	unsigned long  st_ctime_nsec;
+	unsigned long  __unused4;
+	unsigned long  __unused5;
+};
+
+/* This matches struct stat64 in glibc2.1, hence the absolutely
+ * insane amounts of padding around dev_t's.
+ */
+struct stat64 {
+	unsigned long long 	st_dev;
+	unsigned char	__pad0[4];
+
+#define STAT64_HAS_BROKEN_ST_INO	1
+	unsigned long	__st_ino;
+	unsigned int	st_mode;
+	unsigned int	st_nlink;
+
+	unsigned long	st_uid;
+	unsigned long	st_gid;
+
+	unsigned long long	st_rdev;
+	unsigned char	__pad3[4];
+
+	long long		st_size;
+	unsigned long	st_blksize;
+	unsigned long long	st_blocks;		/* Number 512-byte blocks allocated. */
+
+	unsigned long   st_atime;
+	unsigned long   st_atime_nsec;
+
+	unsigned long	st_mtime;
+	unsigned long   st_mtime_nsec;
+
+	unsigned long	st_ctime;
+	unsigned long   st_ctime_nsec;
+	unsigned long long	st_ino;
+};
+
+#endif /* _CSKY_STAT_H */
diff --git a/arch/csky/include/uapi/asm/unistd.h b/arch/csky/include/uapi/asm/unistd.h
new file mode 100644
index 0000000..e615aa9
--- /dev/null
+++ b/arch/csky/include/uapi/asm/unistd.h
@@ -0,0 +1,108 @@
+#define __ARCH_WANT_SYS_CLONE
+#define __ARCH_WANT_IPC_PARSE_VERSION
+#define __ARCH_WANT_OLD_READDIR
+#define __ARCH_WANT_STAT64
+#define __ARCH_WANT_SYS_ALARM
+#define __ARCH_WANT_SYS_GETHOSTNAME
+#define __ARCH_WANT_SYS_IPC
+#define __ARCH_WANT_SYS_PAUSE
+#define __ARCH_WANT_SYS_SGETMASK
+#define __ARCH_WANT_SYS_SIGNAL
+#define __ARCH_WANT_SYS_TIME
+#define __ARCH_WANT_SYS_UTIME
+#define __ARCH_WANT_SYS_WAITPID
+#define __ARCH_WANT_SYS_SOCKETCALL
+#define __ARCH_WANT_SYS_GETPGRP
+#define __ARCH_WANT_SYS_LLSEEK
+#define __ARCH_WANT_SYS_NICE
+#define __ARCH_WANT_SYS_OLD_GETRLIMIT
+#define __ARCH_WANT_SYS_OLDUMOUNT
+#define __ARCH_WANT_SYS_SIGPENDING
+#define __ARCH_WANT_SYS_SIGPROCMASK
+#define __ARCH_WANT_SYS_RT_SIGACTION
+#define __ARCH_WANT_SYS_RT_SIGSUSPEND
+#define __ARCH_WANT_SYS_OLDUMOUNT
+#define __ARCH_WANT_SYS_SIGPENDING
+#define __ARCH_WANT_SYS_SIGPROCMASK
+#define __ARCH_WANT_SYS_CLONE
+#define __ARCH_WANT_SYS_VFORK
+#define __ARCH_WANT_SYS_FORK
+#define __ARCH_WANT_RENAMEAT
+#define __ARCH_WANT_SYSCALL_NO_AT
+#define __ARCH_WANT_SYSCALL_DEPRECATED
+#define __ARCH_WANT_SYSCALL_OFF_T
+#define __ARCH_WANT_SYSCALL_NO_FLAGS
+#define __ARCH_WANT_SYS_OLD_SELECT
+#define __ARCH_WANT_SYNC_FILE_RANGE2
+
+/*
+ * FIXME:
+ * __NR_rt_sigreturn must be 173
+ */
+#undef	__NR_rt_sigreturn
+#undef	__NR_getppid
+
+#include <asm-generic/unistd.h>
+
+/*
+ * FIXME:
+ * __NR_rt_sigreturn must be 173
+ * Because gcc/config/csky/linux-unwind.h
+ * use hard code design,
+ * and didn't use our kernel headers.
+ */
+#if __NR_rt_sigreturn != 139
+#error __NR_rt_sigreturn has changed.
+#endif
+
+#if __NR_getppid != 173
+#error __NR_getppid has changed.
+#endif
+
+#undef	__NR_rt_sigreturn
+#define	__NR_rt_sigreturn 173
+__SC_COMP(__NR_rt_sigreturn, sys_rt_sigreturn, compat_sys_rt_sigreturn)
+
+#undef	__NR_getppid
+#define	__NR_getppid 139
+__SYSCALL(__NR_getppid, sys_getppid)
+
+
+/*
+ * other define
+ */
+#define __NR_set_thread_area	(__NR_arch_specific_syscall + 0)
+__SYSCALL(__NR_set_thread_area, sys_set_thread_area)
+#define __NR_ipc		(__NR_arch_specific_syscall + 1)
+__SYSCALL(__NR_ipc, sys_ipc)
+#define __NR_socketcall		(__NR_arch_specific_syscall + 2)
+__SYSCALL(__NR_socketcall, sys_socketcall)
+#define __NR_ugetrlimit		(__NR_arch_specific_syscall + 3)
+__SYSCALL(__NR_ugetrlimit, sys_getrlimit)
+#define __NR_cacheflush		(__NR_arch_specific_syscall + 4)
+__SYSCALL(__NR_cacheflush, sys_cacheflush)
+#define __NR_sysfs		(__NR_arch_specific_syscall + 5)
+__SYSCALL(__NR_sysfs, sys_sysfs)
+
+__SYSCALL(__NR_fadvise64_64, sys_csky_fadvise64_64)
+
+#define __NR_setgroups32	__NR_setgroups
+#define __NR_getgid32		__NR_getgid
+#define __NR_getgroups32	__NR_getgroups
+#define __NR_setuid32		__NR_setuid
+#define __NR_setgid32		__NR_setgid
+#define __NR_getresgid32	__NR_getresgid
+#define __NR_chown32		__NR_chown
+#define __NR_setfsuid32		__NR_setfsuid
+#define __NR_setfsgid32		__NR_setfsgid
+#define __NR_lchown32		__NR_lchown
+#define __NR_fchown32		__NR_fchown
+#define __NR_geteuid32		__NR_geteuid
+#define __NR_getegid32		__NR_getegid
+#define __NR_getresuid32	__NR_getresuid
+#define __NR_setresuid32	__NR_setresuid
+#define __NR_setresgid32	__NR_setresgid
+#define __NR_setreuid32		__NR_setreuid
+#define __NR_setregid32		__NR_setregid
+#define __NR__llseek		__NR_llseek
+
diff --git a/arch/csky/kernel/Makefile b/arch/csky/kernel/Makefile
new file mode 100644
index 0000000..7081cb7
--- /dev/null
+++ b/arch/csky/kernel/Makefile
@@ -0,0 +1,15 @@
+extra-y := head.o vmlinux.lds
+
+
+obj-y := entry.o signal.o traps.o alignment.o irq.o ptrace.o
+obj-y += time.o vdso.o power.o syscall.o platform.o syscall_table.o
+obj-y += setup.o csky_ksyms.o process.o cpu-probe.o qemu-exit.o
+
+obj-$(CONFIG_MODULES)		 += module.o
+
+obj-$(CONFIG_NATIONALCHIP_TIMER) += timer-nationalchip.o
+
+obj-$(CONFIG_NATIONALCHIP_IRQ)	 += irq-nationalchip.o
+obj-$(CONFIG_CSKY_IRQ)		 += irq-csky.o
+obj-$(CONFIG_DAHUA_IRQ)		 += irq-dahua.o
+
diff --git a/arch/csky/kernel/alignment.c b/arch/csky/kernel/alignment.c
new file mode 100644
index 0000000..870fa81
--- /dev/null
+++ b/arch/csky/kernel/alignment.c
@@ -0,0 +1,532 @@
+#include <linux/compiler.h>
+#include <linux/kernel.h>
+#include <linux/errno.h>
+#include <linux/string.h>
+#include <linux/proc_fs.h>
+#include <linux/seq_file.h>
+#include <linux/init.h>
+#include <linux/sched.h>
+#include <linux/uaccess.h>
+
+#include <asm/unaligned.h>
+
+extern void die_if_kernel(char *, struct pt_regs *, long);
+
+#ifdef CONFIG_SOFT_HANDMISSALIGN
+#define HANDLER_SUCCESS 0
+#define HANDLER_FAILURE	1
+#define SP_NUM 0
+#define R4_NUM 4
+#define R15_NUM 4
+#define R16_NUM 16
+#define R28_NUM 28
+
+
+/* C-SKY CPU V2 32 bit instruction like 11'B in the highest two bit  */
+#define IS_T32(hi16)  (((hi16) & 0xc000) == 0xc000 )
+
+#define CODING_BITS(i)  (i & 0xFC000000)
+#define LDST_TYPE(i)    (i & 0xf000)
+
+static unsigned long ai_user;
+static unsigned long ai_sys;
+static unsigned long ai_skipped;
+static unsigned long ai_half;
+static unsigned long ai_word;
+static unsigned long ai_qword;
+static int ai_usermode;
+
+#define UM_WARN		(1 << 0)
+#define UM_FIXUP	(1 << 1)
+#define UM_SIGNAL	(1 << 2)
+
+static const char *usermode_action[] = {
+	"ignored",
+	"warn",
+	"fixup",
+	"fixup+warn",
+	"signal",
+	"signal+warn"
+};
+
+static int alignment_proc_show(struct seq_file *m, void *v)
+{
+	seq_printf(m, "User:\t\t%lu\n", ai_user);
+	seq_printf(m, "System:\t\t%lu\n", ai_sys);
+	seq_printf(m, "Skipped:\t%lu\n", ai_skipped);
+	seq_printf(m, "Half:\t\t%lu\n", ai_half);
+	seq_printf(m, "Word:\t\t%lu\n", ai_word);
+	seq_printf(m, "Qword:\t\t%lu\n", ai_qword);
+	seq_printf(m, "User faults:\t%i (%s)\n", ai_usermode,
+			usermode_action[ai_usermode]);
+
+	return 0;
+}
+
+static int alignment_proc_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, alignment_proc_show, NULL);
+}
+
+static int proc_alignment_write(struct file *file, const char __user *buffer,
+				size_t count, loff_t *pos)
+{
+	char mode;
+
+	if (count > 0) {
+		if (get_user(mode, buffer))
+			return -EFAULT;
+		if (mode >= '0' && mode <= '5')
+			ai_usermode = mode - '0';
+	}
+	return count;
+}
+
+static const struct file_operations alignment_proc_fops = {
+	.open		= alignment_proc_open,
+	.read		= seq_read,
+	.llseek		= seq_lseek,
+	.release	= single_release,
+	.write		= proc_alignment_write,
+};
+
+#ifdef  __cskyBE__
+#define BE		1
+#define FIRST_BYTE_16	"rotri	%1, 8\n"
+#define FIRST_BYTE_32	"rotri	%1, 24\n"
+#define NEXT_BYTE	"rotri  %1, 24\n"
+#else
+#define BE		0
+#define FIRST_BYTE_16
+#define FIRST_BYTE_32
+#define NEXT_BYTE	"lsri   %1, 8\n"
+#endif
+
+#define __get8_unaligned_check(val,addr,err)		\
+	__asm__(					\
+	"1:	ldb	%1, (%2)\n"			\
+	"	addi	%2, 1\n"			\
+	"	br	3f\n"				\
+	"2:	movi	%0, 1\n"			\
+	"	br	3f\n"				\
+	"	.section __ex_table,\"a\"\n"		\
+	"	.align	2\n"				\
+	"	.long	1b, 2b\n"			\
+	"	.previous\n"				\
+	"3:\n"						\
+	: "=r" (err), "=r" (val), "=r" (addr)		\
+	: "0" (err), "2" (addr))
+
+#define get16_unaligned_check(val,addr)				\
+	do {							\
+		unsigned int err = 0, v, a = addr;		\
+		__get8_unaligned_check(v,a,err);		\
+		val =  v << ((BE) ? 8 : 0);			\
+		__get8_unaligned_check(v,a,err);		\
+		val |= v << ((BE) ? 0 : 8);			\
+		if (err)					\
+			goto fault;				\
+	} while (0)
+
+#define get32_unaligned_check(val,addr)				\
+	do {							\
+		unsigned int err = 0, v, a = addr;		\
+		__get8_unaligned_check(v,a,err);		\
+		val =  v << ((BE) ? 24 :  0);			\
+		__get8_unaligned_check(v,a,err);		\
+		val |= v << ((BE) ? 16 :  8);			\
+		__get8_unaligned_check(v,a,err);		\
+		val |= v << ((BE) ?  8 : 16);			\
+		__get8_unaligned_check(v,a,err);		\
+		val |= v << ((BE) ?  0 : 24);			\
+		if (err)					\
+			goto fault;				\
+	} while (0)
+
+#define put16_unaligned_check(val,addr)				\
+	do {							\
+		unsigned int err = 0, v = val, a = addr;	\
+		__asm__( FIRST_BYTE_16				\
+		"1:	stb	%1, (%2)\n"			\
+		"	addi	%2, 1\n"			\
+			NEXT_BYTE				\
+		"2:	stb	%1, (%2)\n"			\
+		"	br	4f\n"				\
+		"3:	movi	%0, 1\n"			\
+		"	br	4f\n"				\
+		"	.section __ex_table,\"a\"\n"		\
+		"	.align	2\n"				\
+		"	.long	1b, 3b\n"			\
+		"	.long	2b, 3b\n"			\
+		"	.previous\n"				\
+		"4:\n"						\
+		: "=r" (err), "=r" (v), "=r" (a)		\
+		: "0" (err), "1" (v), "2" (a));			\
+		if (err)					\
+			goto fault;				\
+	} while (0)
+
+#define put32_unaligned_check(val,addr)				\
+	do {							\
+		unsigned int err = 0, v = val, a = addr;	\
+		__asm__( FIRST_BYTE_32				\
+		"1:	stb	%1, (%2)\n"			\
+		"	addi	%2, 1\n"			\
+			NEXT_BYTE				\
+		"2:	stb	%1, (%2)\n"			\
+		"	addi	%2, 1\n"			\
+			NEXT_BYTE				\
+		"3:	stb	%1, (%2)\n"			\
+		"	addi	%2, 1\n"			\
+			NEXT_BYTE				\
+		"4:	stb	%1, (%2)\n"			\
+		"	br	6f\n"				\
+		"5:	movi	%0, 1\n"			\
+		"	br	6f\n"				\
+		"	.section __ex_table,\"a\"\n"		\
+		"	.align	2\n"				\
+		"	.long	1b, 5b\n"			\
+		"	.long	2b, 5b\n"			\
+		"	.long	3b, 5b\n"			\
+		"	.long	4b, 5b\n"			\
+		"	.previous\n"				\
+		"6:\n"						\
+		: "=r" (err), "=r" (v), "=r" (a)		\
+		: "0" (err), "1" (v), "2" (a));			\
+		if (err)					\
+			goto fault;				\
+	} while (0)
+
+inline static unsigned int
+get_regs_value(unsigned int rx, struct pt_regs *regs)
+{
+	unsigned int value;
+
+	if(rx == 0){
+		if(user_mode(regs)){
+			__asm__ __volatile__("mfcr %0, ss1 \n\r"
+						:"=r"(value));
+		}else{
+			value = sizeof(struct pt_regs) + ((unsigned int)regs);
+		}
+	}else if(rx == 1){
+		value = regs->regs[9];
+	}else if(rx == 15){
+		value = regs->r15;
+	}else{
+		value = *((int *)regs + rx + 1);
+	}
+
+	return value;
+}
+
+inline static int
+put_regs_value(unsigned int value, unsigned int rx, struct pt_regs *regs){
+	if(rx == 0){
+		printk("alignment handler trying to write sp.\n");
+		goto fault;
+	}else if(rx == 1){
+		regs->regs[9] = value;
+	}else if(rx == 15){
+		regs->r15 = value;
+	}else{
+		*((int *)regs + rx + 1) = value;
+	}
+	return 0;
+fault:
+	return 1;
+}
+
+static int
+handle_ldh_ldw_v1(unsigned long instr, struct pt_regs *regs){
+	unsigned int regx = instr & 0xf;
+	unsigned int regz = (instr >> 8) & 0xf;
+	unsigned int imm4 = (instr >> 4) & 0xf;
+	unsigned int destaddr, ldh_ldw;
+	unsigned int dataregx, tmpval32;
+	unsigned short tmpval16;
+
+	dataregx = get_regs_value(regx, regs);
+
+	ldh_ldw = instr & 0x6000;
+	if(ldh_ldw == 0x4000){ // ldh
+		destaddr = dataregx + (imm4 << 1);
+		get16_unaligned_check(tmpval16, destaddr);
+		if(put_regs_value((unsigned int)tmpval16, regz, regs) != 0){
+			goto fault;
+		}
+		ai_half += 1;
+	}else if(ldh_ldw == 0x0000){ // ldw
+		destaddr = dataregx + (imm4 << 2);
+		get32_unaligned_check(tmpval32, destaddr);
+		if(put_regs_value(tmpval32, regz, regs) != 0){
+			goto fault;
+		}
+		ai_word += 1;
+	}else{
+		goto fault;
+	}
+
+	return HANDLER_SUCCESS;
+fault:
+	return HANDLER_FAILURE;
+}
+
+static int
+handle_ldm_v1(unsigned long instr, struct pt_regs *regs){
+	unsigned int regf = instr & 0xf;
+	unsigned int datasp;
+	unsigned int tmpval32, i;
+
+	// regf can not be r0 or r15.
+	if(regf == 0 || regf == 15){
+		goto fault;
+	}
+
+	datasp = get_regs_value(SP_NUM, regs);
+	for(i = regf; i <= R15_NUM; i++){
+		get32_unaligned_check(tmpval32, datasp + (i - regf) * 4);
+		if(put_regs_value(tmpval32, i, regs) != 0){
+			goto fault;
+		}
+	}
+	ai_qword += 1;
+
+	return HANDLER_SUCCESS;
+fault:
+	return HANDLER_FAILURE;
+}
+
+static int
+handle_ldq_v1(unsigned long instr, struct pt_regs *regs){
+	unsigned int regf = instr & 0xf;
+	unsigned int datarf;
+	unsigned int tmpval32, i;
+
+	// regf can not be r4 - r7.
+	if(regf > 3 && regf < 8){
+		goto fault;
+	}
+
+	datarf = get_regs_value(regf, regs);
+	for(i = 4; i <= 8; i++){
+		get32_unaligned_check(tmpval32, datarf + (i - 4) * 4);
+		if(put_regs_value(tmpval32, i, regs) != 0){
+			goto fault;
+		}
+	}
+	ai_qword += 1;
+
+	return HANDLER_SUCCESS;
+fault:
+	return HANDLER_FAILURE;
+}
+
+static int
+handle_sth_stw_v1(unsigned long instr, struct pt_regs *regs){
+	unsigned int regx = instr & 0xf;
+	unsigned int regz = (instr >> 8) & 0xf;
+	unsigned int imm4 = (instr >> 4) & 0xf;
+	unsigned int destaddr, sth_stw;
+	unsigned int dataregx, dataregz;
+
+	dataregx = get_regs_value(regx, regs);
+	dataregz = get_regs_value(regz, regs);
+
+	sth_stw = instr & 0x6000;
+	if(sth_stw == 0x4000){ // sth
+		destaddr = dataregx + (imm4 << 1);
+		put16_unaligned_check(dataregz, destaddr);
+		ai_half += 1;
+	}else if(sth_stw == 0x0000){ //stw
+		destaddr = dataregx + (imm4 << 2);
+		put32_unaligned_check(dataregz, destaddr);
+		ai_word += 1;
+	}else{
+		goto fault;
+	}
+
+	return HANDLER_SUCCESS;
+fault:
+	return HANDLER_FAILURE;
+}
+
+static int
+handle_stq_v1(unsigned long instr, struct pt_regs *regs){
+	unsigned int regf = instr & 0xf;
+	unsigned int datarf;
+	unsigned int tmpval32, i;
+
+	// regf can not be r4 - r7.
+	if(regf > 3 && regf < 8){
+		goto fault;
+	}
+
+	datarf = get_regs_value(regf, regs);
+	for(i = 4; i <= 7; i++){
+		tmpval32 = get_regs_value(i, regs);
+		put32_unaligned_check(tmpval32, datarf + (i - 4) * 4);
+	}
+	ai_qword += 1;
+
+	return HANDLER_SUCCESS;
+fault:
+	return HANDLER_FAILURE;
+}
+
+static int
+handle_stm_v1(unsigned long instr, struct pt_regs *regs){
+	unsigned int regf = instr & 0xf;
+	unsigned int datasp;
+	unsigned int tmpval32, i;
+
+	// regf can not be r0 or r15.
+	if(regf == 0 || regf == 15){
+		goto fault;
+	}
+
+	datasp = get_regs_value(SP_NUM, regs);
+	for(i = regf; i <= R15_NUM; i++){
+		tmpval32 = get_regs_value(i, regs);
+		put32_unaligned_check(tmpval32, datasp + (i - regf) * 4);
+	}
+	ai_qword += 1;
+
+	return HANDLER_SUCCESS;
+fault:
+	return HANDLER_FAILURE;
+}
+
+asmlinkage void alignment_c(struct pt_regs *regs)
+{
+	int err;
+	unsigned long instr = 0, instrptr;
+	unsigned int fault;
+	u16 tinstr = 0;
+	int (*handler)(unsigned long inst, struct pt_regs *regs) = NULL;
+	int isize = 2;
+	mm_segment_t fs;
+
+	instrptr = instruction_pointer(regs);
+
+	fs = get_fs();
+	set_fs(KERNEL_DS);
+	fault = __get_user(tinstr, (u16 *)(instrptr & ~1));
+	instr = (unsigned long)tinstr;
+
+	set_fs(fs);
+	if (fault) {
+		goto bad_or_fault;
+	}
+
+	if (user_mode(regs)) {
+		goto user;
+	}
+
+	ai_sys += 1;
+fixup:
+	regs->pc += isize;
+
+	if((instr & 0x9000) == 0x9000){ // sth, stw
+		handler = handle_sth_stw_v1;
+	}else if((instr & 0x9000) == 0x8000){ // ldh, ldw
+		handler = handle_ldh_ldw_v1;
+	}else if((instr & 0xfff0) == 0x0070){ // stm
+		handler = handle_stm_v1;
+	}else if((instr & 0xfff0) == 0x0060){ // ldm
+		handler = handle_ldm_v1;
+	}else if((instr & 0xfff0) == 0x0050){ // stq
+		handler = handle_stq_v1;
+	}else if((instr & 0xfff0) == 0x0040){ // ldq
+		handler = handle_ldq_v1;
+	}else{
+		goto bad_or_fault;
+	}
+
+	if (!handler)
+		goto bad_or_fault;
+
+	err = handler(instr, regs);
+	if (err != HANDLER_SUCCESS)
+	{
+		regs->pc -=2;
+		goto bad_or_fault;
+	}
+
+	return;
+
+bad_or_fault:
+	if(fixup_exception(regs)) {
+		ai_skipped += 1;
+		return;
+	}
+
+	die_if_kernel("Alignment trap: not handle this instruction", regs, 0);
+	return;
+
+user:
+	ai_user += 1;
+
+	if (ai_usermode & UM_WARN)
+		printk("Alignment trap: %s(pid=%d) PC=0x%x Ins=0x%x\n",
+			current->comm, current->pid,
+			(unsigned int)regs->pc, (unsigned int)instr);
+
+	if (ai_usermode & UM_FIXUP)
+		goto fixup;
+
+	if (ai_usermode & UM_SIGNAL)
+		force_sig(SIGBUS, current);
+
+	return;
+}
+
+/*
+ * This needs to be done after sysctl_init, otherwise sys/ will be
+ * overwritten.  Actually, this shouldn't be in sys/ at all since
+ * it isn't a sysctl, and it doesn't contain sysctl information.
+ * We now locate it in /proc/cpu/alignment instead.
+ */
+static int __init alignment_init(void)
+{
+	struct proc_dir_entry *res;
+
+	res = proc_mkdir("cpu", NULL);
+	if (!res)
+		return -ENOMEM;
+
+	res = proc_create("alignment", S_IWUSR | S_IRUGO, res, &alignment_proc_fops);
+	if (!res)
+		return -ENOMEM;
+
+	ai_usermode = UM_FIXUP;
+
+	return 0;
+}
+fs_initcall(alignment_init);
+
+#else /* !CONFIG_SOFT_HANDMISSALIGN */
+
+asmlinkage void alignment_c(struct pt_regs *regs)
+{
+	int sig;
+	siginfo_t info;
+
+	sig = SIGBUS;
+	info.si_code = BUS_ADRALN;
+	info.si_signo = sig;
+	info.si_errno = 0;
+	info.si_addr = (void *)regs->pc;
+	if (user_mode(regs)){
+		force_sig_info(sig, &info, current);
+        return;
+	}
+
+	if(fixup_exception(regs)) {
+	    return;
+	}
+	die_if_kernel("Kernel mode Alignment exception", regs, 0);
+	return;
+}
+
+#endif /* CONFIG_SOFT_HANDMISSALIGN */
diff --git a/arch/csky/kernel/asm-offsets.c b/arch/csky/kernel/asm-offsets.c
new file mode 100644
index 0000000..fe2f7a2
--- /dev/null
+++ b/arch/csky/kernel/asm-offsets.c
@@ -0,0 +1,91 @@
+#include <linux/sched.h>
+#include <linux/kernel_stat.h>
+#include <linux/kbuild.h>
+#include <abi/regdef.h>
+
+int main(void)
+{
+	/* offsets into the task struct */
+	DEFINE(TASK_STATE,        offsetof(struct task_struct, state));
+	DEFINE(TASK_THREAD_INFO,  offsetof(struct task_struct, stack));
+	DEFINE(TASK_FLAGS,        offsetof(struct task_struct, flags));
+	DEFINE(TASK_PTRACE,       offsetof(struct task_struct, ptrace));
+	DEFINE(TASK_THREAD,       offsetof(struct task_struct, thread));
+	DEFINE(TASK_MM,           offsetof(struct task_struct, mm));
+	DEFINE(TASK_ACTIVE_MM,    offsetof(struct task_struct, active_mm));
+
+	/* offsets into the thread struct */
+	DEFINE(THREAD_KSP,        offsetof(struct thread_struct, ksp));
+	DEFINE(THREAD_USP,        offsetof(struct thread_struct, usp));
+	DEFINE(THREAD_SR,         offsetof(struct thread_struct, sr));
+	DEFINE(THREAD_ESP0,       offsetof(struct thread_struct, esp0));
+	DEFINE(THREAD_FESR,       offsetof(struct thread_struct, fesr));
+	DEFINE(THREAD_FSR,        offsetof(struct thread_struct, fsr));
+	DEFINE(THREAD_FCR,        offsetof(struct thread_struct, fcr));
+	DEFINE(THREAD_FPREG,      offsetof(struct thread_struct, fp));
+	DEFINE(THREAD_DSPCSR,     offsetof(struct thread_struct, dspcsr));
+	DEFINE(THREAD_DSPHI,      offsetof(struct thread_struct, hi));
+	DEFINE(THREAD_DSPLO,      offsetof(struct thread_struct, lo));
+
+	/* offsets into the thread_info struct */
+	DEFINE(TINFO_FLAGS,       offsetof(struct thread_info, flags));
+	DEFINE(TINFO_PREEMPT,     offsetof(struct thread_info, preempt_count));
+	DEFINE(TINFO_ADDR_LIMIT,  offsetof(struct thread_info, addr_limit));
+	DEFINE(TINFO_TP_VALUE,   offsetof(struct thread_info, tp_value));
+	DEFINE(TINFO_TASK,        offsetof(struct thread_info, task));
+
+	/* offsets into the pt_regs */
+	DEFINE(PT_PC,             offsetof(struct pt_regs, pc));
+	DEFINE(PT_ORIG_AO,        offsetof(struct pt_regs, orig_a0));
+	DEFINE(PT_SR,             offsetof(struct pt_regs, sr));
+
+	DEFINE(PT_A0,             offsetof(struct pt_regs, a0));
+	DEFINE(PT_A1,             offsetof(struct pt_regs, a1));
+	DEFINE(PT_A2,             offsetof(struct pt_regs, a2));
+	DEFINE(PT_A3,             offsetof(struct pt_regs, a3));
+	DEFINE(PT_REGS0,          offsetof(struct pt_regs, regs[0]));
+	DEFINE(PT_REGS1,          offsetof(struct pt_regs, regs[1]));
+	DEFINE(PT_REGS2,          offsetof(struct pt_regs, regs[2]));
+	DEFINE(PT_REGS3,          offsetof(struct pt_regs, regs[3]));
+	DEFINE(PT_REGS4,          offsetof(struct pt_regs, regs[4]));
+	DEFINE(PT_REGS5,          offsetof(struct pt_regs, regs[5]));
+	DEFINE(PT_REGS6,          offsetof(struct pt_regs, regs[6]));
+	DEFINE(PT_REGS7,          offsetof(struct pt_regs, regs[7]));
+	DEFINE(PT_REGS8,          offsetof(struct pt_regs, regs[8]));
+	DEFINE(PT_REGS9,          offsetof(struct pt_regs, regs[9]));
+	DEFINE(PT_R15,            offsetof(struct pt_regs, r15));
+#if defined(__CSKYABIV2__)
+	DEFINE(PT_R16,            offsetof(struct pt_regs, exregs[0]));
+	DEFINE(PT_R17,            offsetof(struct pt_regs, exregs[1]));
+	DEFINE(PT_R18,            offsetof(struct pt_regs, exregs[2]));
+	DEFINE(PT_R19,            offsetof(struct pt_regs, exregs[3]));
+	DEFINE(PT_R20,            offsetof(struct pt_regs, exregs[4]));
+	DEFINE(PT_R21,            offsetof(struct pt_regs, exregs[5]));
+	DEFINE(PT_R22,            offsetof(struct pt_regs, exregs[6]));
+	DEFINE(PT_R23,            offsetof(struct pt_regs, exregs[7]));
+	DEFINE(PT_R24,            offsetof(struct pt_regs, exregs[8]));
+	DEFINE(PT_R25,            offsetof(struct pt_regs, exregs[9]));
+	DEFINE(PT_R26,            offsetof(struct pt_regs, exregs[10]));
+	DEFINE(PT_R27,            offsetof(struct pt_regs, exregs[11]));
+	DEFINE(PT_R28,            offsetof(struct pt_regs, exregs[12]));
+	DEFINE(PT_R29,            offsetof(struct pt_regs, exregs[13]));
+	DEFINE(PT_R30,            offsetof(struct pt_regs, exregs[14]));
+	DEFINE(PT_R31,            offsetof(struct pt_regs, exregs[15]));
+	DEFINE(PT_RHI,            offsetof(struct pt_regs, rhi));
+	DEFINE(PT_RLO,            offsetof(struct pt_regs, rlo));
+#endif
+#if 0
+	/* offsets into the irq_handler struct */
+	DEFINE(IRQ_HANDLER,       offsetof(struct irq_node, handler));
+	DEFINE(IRQ_DEVID,         offsetof(struct irq_node, dev_id));
+	DEFINE(IRQ_NEXT,          offsetof(struct irq_node, next));
+#endif
+	/* offsets into the irq_cpustat_t struct */
+	DEFINE(CPUSTAT_SOFTIRQ_PENDING, offsetof(irq_cpustat_t, __softirq_pending));
+
+	/* signal defines */
+	DEFINE(SIGSEGV, SIGSEGV);
+	DEFINE(SIGTRAP, SIGTRAP);
+
+	return 0;
+}
diff --git a/arch/csky/kernel/cpu-probe.c b/arch/csky/kernel/cpu-probe.c
new file mode 100644
index 0000000..9d0e7ad
--- /dev/null
+++ b/arch/csky/kernel/cpu-probe.c
@@ -0,0 +1,72 @@
+#include <linux/of.h>
+#include <linux/init.h>
+#include <linux/seq_file.h>
+#include <abi/reg_ops.h>
+#include <linux/memblock.h>
+
+char cpu_name[32] = CSKYCPU_DEF_NAME;
+
+#define MSA_MASK 0xe0000000
+
+static __init void setup_cpu_msa(void)
+{
+	unsigned int tmp;
+
+	tmp = memblock_start_of_DRAM();
+
+	if (tmp != (PHYS_OFFSET + CONFIG_RAM_BASE)) {
+		pr_err("C-SKY: start of DRAM doesn't defconfig: %x-%x.\n",
+		       tmp, PHYS_OFFSET + CONFIG_RAM_BASE);
+		return;
+	}
+
+	if ((tmp & MSA_MASK) != (mfcr_msa0() & MSA_MASK)) {
+		pr_err("C-SKY: start of DRAM doesn't fit MMU MSA0: %x-%x.\n",
+			mfcr_msa0(), tmp);
+		return;
+	}
+
+	tmp = tmp & MSA_MASK;
+	mtcr_msa0(tmp | 0xe);
+	mtcr_msa1(tmp | 0x6);
+}
+
+__init void cpu_dt_probe(void)
+{
+	setup_cpu_msa();
+}
+
+static int c_show(struct seq_file *m, void *v)
+{
+	seq_printf(m, "C-SKY CPU : %s\n", cpu_name);
+	seq_printf(m, "revision  : 0x%08x\n", mfcr_cpuidrr());
+	seq_printf(m, "ccr reg   : 0x%08x\n", mfcr_ccr());
+	seq_printf(m, "ccr2 reg  : 0x%08x\n", mfcr_ccr2());
+	seq_printf(m, "hint reg  : 0x%08x\n", mfcr_hint());
+	seq_printf(m, "msa0 reg  : 0x%08x\n", mfcr_msa0());
+	seq_printf(m, "msa1 reg  : 0x%08x\n", mfcr_msa1());
+	seq_printf(m, "\n");
+
+	return 0;
+}
+
+static void *c_start(struct seq_file *m, loff_t *pos)
+{
+	return *pos < 1 ? (void *)1 : NULL;
+}
+
+static void *c_next(struct seq_file *m, void *v, loff_t *pos)
+{
+	++*pos;
+	return NULL;
+}
+
+static void c_stop(struct seq_file *m, void *v) {}
+
+const struct seq_operations cpuinfo_op = {
+	.start	= c_start,
+	.next	= c_next,
+	.stop	= c_stop,
+	.show	= c_show,
+};
+
diff --git a/arch/csky/kernel/csky_ksyms.c b/arch/csky/kernel/csky_ksyms.c
new file mode 100644
index 0000000..998f8ae
--- /dev/null
+++ b/arch/csky/kernel/csky_ksyms.c
@@ -0,0 +1,39 @@
+#include <linux/module.h>
+#include <asm/uaccess.h>
+#include <asm/cacheflush.h>
+
+asmlinkage long long __ashldi3 (long long, int);
+asmlinkage long long __ashrdi3 (long long, int);
+asmlinkage long long __lshrdi3 (long long, int);
+asmlinkage long long __muldi3 (long long, long long);
+
+/* The following are special because they're not called
+ *  explicitly (the C compiler generates them).  Fortunately,
+ *  their interface isn't gonna change any time soon now, so
+ *  it's OK to leave it out of version control. 
+ */
+EXPORT_SYMBOL(__ashldi3);
+EXPORT_SYMBOL(__ashrdi3);
+EXPORT_SYMBOL(__lshrdi3);
+EXPORT_SYMBOL(__muldi3);
+
+/*
+ * String functions
+ */
+EXPORT_SYMBOL(memset);
+EXPORT_SYMBOL(memcpy);
+
+/* user mem (segment) */
+EXPORT_SYMBOL(__generic_copy_from_user);
+EXPORT_SYMBOL(__generic_copy_to_user);
+EXPORT_SYMBOL(strnlen_user);
+EXPORT_SYMBOL(__strncpy_from_user);
+EXPORT_SYMBOL(strncpy_from_user);
+EXPORT_SYMBOL(clear_user);
+EXPORT_SYMBOL(__clear_user);
+
+EXPORT_SYMBOL(get_wchan);
+
+extern asmlinkage void trap(void);
+EXPORT_SYMBOL(trap);
+
diff --git a/arch/csky/kernel/entry.S b/arch/csky/kernel/entry.S
new file mode 100644
index 0000000..82a4707
--- /dev/null
+++ b/arch/csky/kernel/entry.S
@@ -0,0 +1,1047 @@
+#include <linux/linkage.h>
+#include <abi/entry.h>
+#include <abi/pgtable-bits.h>
+#include <asm/errno.h>
+#include <asm/setup.h>
+#include <asm/traps.h>
+#include <asm/unistd.h>
+#include <asm/asm-offsets.h>
+#include <linux/threads.h>
+#include <asm/setup.h>
+#include <asm/page.h>
+#include <asm/thread_info.h>
+#include <asm/fpu.h>
+
+#define PTE_HALF        0
+#define PTE_SIZE        4
+#define PTE_BIT         2
+#define PTEP_INDX_MSK	0xff8
+#define PTE_INDX_MSK    0xffc
+#define PTE_INDX_SHIFT  10
+#define _PGDIR_SHIFT    22
+#define THREADSIZE_MASK_BIT 13
+
+/*
+ * Make sure our user space atomic helper(trap 2) is restarted
+ * if it was interrupted in a critical region. Here we
+ * perform a quick test inline since it should be false
+ * 99.9999% of the time. The rest is done out of line.
+ *
+ * This macro is used in tlbmodified.
+ */
+.macro kuser_cmpxchg_check
+	mfcr    a0, epc
+	btsti	a0, 31			/* is in super user mode?    if yes -=> call kuser_cmpxchg_fixup */
+	bf	1f
+	jbsr	kuser_cmpxchg_fixup
+1:
+.endm
+
+.export system_call
+.export buserr
+.export trap
+.export alignment
+.export inthandler
+.export autohandler
+.export fasthandler
+
+.export fastautohandler
+.export sys_fork, sys_clone
+.export sw_usp
+.export sw_ksp
+
+.export handle_tlbinvalidl
+.export handle_tlbmodified
+.export handle_tlbmissinst
+.export handle_tlbmissdata
+.export tlbinvalidl
+.export tlbinvalids
+.export tlbmiss
+.export readtlbinvalid
+.export writetlbinvalid
+.export handle_fpe
+.export handle_illegal
+
+.import irq_stat
+
+#ifndef CONFIG_MMU_HARD_REFILL
+.import pgd_current
+#endif
+
+.data
+sw_ksp:
+.long 0
+sw_usp:
+.long 0
+
+.text
+
+/*
+ * Tlbinvalidl exception handle routine.
+ */
+ENTRY(handle_tlbinvalidl)
+tlbinvalidl:
+	mtcr    a3, ss2
+	mtcr    r6, ss3
+	mtcr    a2, ss4
+
+	SET_CP_MMU
+#ifdef CONFIG_MMU_HARD_REFILL
+	RD_PGDR	r6
+	bclri   r6, 0
+	lrw	a3, PHYS_OFFSET
+	subu	r6, a3
+	bseti	r6, 31
+#else
+	lrw     r6, (pgd_current)
+	ldw     r6, (r6)
+#endif
+	RD_MEH	    a3
+	mov     a2, a3
+   	lsri    a2, _PGDIR_SHIFT
+	lsli    a2, 2
+	addu    r6, a2
+	ldw     r6, (r6)
+#ifdef CONFIG_MMU_HARD_REFILL
+	lrw	a2, PHYS_OFFSET
+	subu	r6, a2
+	bseti	r6, 31
+#endif
+
+	lsri    a3, PTE_INDX_SHIFT
+	lrw     a2, PTE_INDX_MSK
+	and     a3, a2
+	addu    r6, a3
+	ldw     a3, (r6)
+	bgeni   a2, 31            /* move 0x80000000 to a2 */
+	WR_MCIR	a2
+	movi    a2, (_PAGE_PRESENT | _PAGE_READ)
+	and     a3, a2
+	cmpne   a3, a2
+	bt      readtlbinvalid   /* PTE not present, jump to fix it. */
+
+	/* PTE present, now make it valid */
+	ldw     a3, (r6)
+#ifdef __CSKYABIV1__
+	bgeni   a2, 7         /* a2 = (_PAGE_VALID | _PAGE_ACCESSED) */
+ 	bseti   a2, 3
+#else
+	movi    a2, (_PAGE_VALID | _PAGE_ACCESSED)
+#endif
+	or      a3, a2
+	stw     a3, (r6)
+
+	/*
+	 * Below, fill a jTLB with two PTEs of which we have set one above.
+	 * When do this, we make sure set Entrylo0 with the low PTE in Page
+	 * Table, and Entrylo1 with the high one.
+	 */
+	bclri   r6, PTE_BIT
+#ifdef __CSKYABIV1__
+	ldw     a2, (r6, 4)
+	lsri    a2, 6
+	WR_MEL1 a2
+	ldw     a2, (r6)
+	lsri    a2, 6
+	WR_MEL0 a2
+#else
+	ldw     a2, (r6, 4)
+	WR_MEL1 a2
+	ldw     a2, (r6)
+	WR_MEL0    a2
+#endif
+
+	RD_MIR  a3         /* Read MIR */
+	bgeni   a2, 29     /* Use write index by default */
+	btsti   a3, 31     /* Is probe success ? */
+	bf      1f
+	bgeni   a2, 25
+	WR_MCIR a2
+	bgeni   a2, 28     /* If probe failed, invalid index and write random */
+
+1:
+	WR_MCIR a2
+	mfcr    a3, ss2
+	mfcr    r6, ss3
+	mfcr    a2, ss4
+	rte
+
+readtlbinvalid:
+	mfcr    a3, ss2
+	mfcr    r6, ss3
+	mfcr    a2, ss4
+	SAVE_ALL
+
+	SET_CP_MMU
+	RD_MEH	a3
+	bmaski  r8, 12
+	andn    a3, r8             /* r8 = !(0xfffff000) */
+	mov     a2, a3
+	psrset  ee, ie          /* Enable exception & interrupt */
+	mov     a0, sp
+	movi    a1, 0
+	jbsr    do_page_fault
+	movi    r11_sig, 0             /* r11 = 0, Not a syscall. */
+	jmpi    ret_from_exception
+
+/*
+ * Tlbinvalids exception handle routine.
+ */
+ENTRY(handle_tlbinvalids)
+tlbinvalids:
+	mtcr    a3, ss2
+	mtcr    r6, ss3
+	mtcr    a2, ss4
+
+	SET_CP_MMU
+#ifdef CONFIG_MMU_HARD_REFILL
+	RD_PGDR	r6
+	bclri   r6, 0
+	lrw	a3, PHYS_OFFSET
+	subu	r6, a3
+	bseti	r6, 31
+#else
+ 	lrw 	r6, pgd_current
+	ldw     r6, (r6)
+#endif
+
+	RD_MEH	a3
+	mov     a2, a3
+	lsri    a2, _PGDIR_SHIFT
+	lsli    a2, 2
+	addu    r6, a2
+	ldw     r6, (r6)
+#ifdef CONFIG_MMU_HARD_REFILL
+	lrw	a2, PHYS_OFFSET
+	subu	r6, a2
+	bseti   r6, 31
+#endif
+
+	lsri    a3, PTE_INDX_SHIFT
+	lrw     a2, PTE_INDX_MSK
+	and     a3, a2
+	addu    r6, a3
+	ldw     a3, (r6)
+	bgeni   a2, 31           /* TLB probe command, a2 = 0x80000000 */
+	WR_MCIR	a2
+	movi    a2, (_PAGE_PRESENT | _PAGE_WRITE)
+	and     a3, a2
+	xor     a3, a2
+	cmpnei  a3, 0
+	bt      writetlbinvalid  /* PTE not present, jump to fix it. */
+
+	/* PTE resent, set it to be valid. */
+	ldw     a3, (r6)
+
+#ifdef __CSKYABIV1__
+	/* a2 = (_PAGE_ACCESSED | _PAGE_MODIFIED | _PAGE_VALID | _PAGE_DIRTY) */
+	movi    a2, 0x18
+	bseti   a2, 7
+	bseti   a2, 8
+#else
+	movi    a2, (_PAGE_ACCESSED | _PAGE_MODIFIED | _PAGE_VALID | _PAGE_DIRTY)
+#endif
+
+	or      a3, a2
+	stw     a3, (r6)
+	/*
+	 * Below, fill a jTLB with two PTEs of which we have set one above.
+	 * When do this, we make sure set Entrylo0 with the low PTE in Page
+	 * Table, and Entrylo1 with the high one.
+	 */
+	bclri   r6, PTE_BIT
+#ifdef __CSKYABIV1__
+	ldw     a2, (r6,4)
+	lsri    a2, 6
+	WR_MEL1	a2
+	ldw 	a2, (r6)
+	lsri	a2, 6
+	WR_MEL0	a2
+#else
+	ldw     a2, (r6,4)
+	WR_MEL1 a2
+	ldw     a2, (r6)
+	WR_MEL0 a2
+#endif
+
+	RD_MIR  a3         /* Read MIR */
+	bgeni   a2, 29     /* Use write index by default */
+	btsti   a3, 31     /* Is probe success ? */
+	bf      1f
+	bgeni   a2, 25
+	WR_MCIR a2
+	bgeni   a2, 28     /* If probe failed, invalid index and write random */
+
+1:
+	WR_MCIR	a2
+
+	mfcr    a3, ss2
+	mfcr    r6, ss3
+	mfcr    a2, ss4
+	rte
+
+writetlbinvalid:
+	mfcr    a3, ss2
+	mfcr    r6, ss3
+	mfcr    a2, ss4
+	SAVE_ALL
+
+	SET_CP_MMU
+	RD_MEH	    a3
+	bmaski  r8, 12
+	andn    a3, r8          /* r8 = !(0xfffff000) */
+	mov     a2, a3
+	psrset  ee, ie          /* Enable exception & interrupt */
+	mov     a0, sp
+	movi    a1, 1
+	jbsr    (do_page_fault)
+	movi    r11_sig, 0             /* r11 = 0, Not a syscall. */
+	jmpi    (ret_from_exception)
+
+/*
+ * Tlbmiss exception handle routine.
+ */
+ENTRY(handle_tlbmiss)
+tlbmiss:
+#ifndef CONFIG_MMU_HARD_REFILL
+	lrw     a0, (pgd_current)
+	ldw     a0, (a0)
+
+	SET_CP_MMU
+	RD_MEH  a1
+#ifdef __CSKYABIV1__
+	mov     a2, a1
+	lsri    a2, _PGDIR_SHIFT
+	ixw     a0, a2
+	ldw     a0, (a0)
+
+	lsri    a1, PTE_INDX_SHIFT
+	lrw     a2, PTE_INDX_MSK
+	and     a1, a2
+	addu    a0, a1
+	bclri   a0, PTE_BIT
+	ldw     a1, (a0)
+	lsri    a1, 6
+	WR_MEL0 a1
+	ldw     a1, (a0, 4)
+	lsri    a1, 6
+	WR_MEL1 a1
+#else
+#error ck8xx only hardrefill for tlbmiss, because some no shadow regs
+#endif
+
+	bgeni   a1, 28           /* TLB write random command, r5 = 0x10000000 */
+	WR_MCIR a1
+#endif
+	/*
+	 * clear TP in psr[13]
+	 */
+	mfcr    a1, epsr
+	bclri   a1, 13
+	mtcr    a1, epsr
+	rte
+
+/*
+ * Tlbmodified exception handle routine.
+ */
+ENTRY(handle_tlbmodified)
+	mtcr    a3, ss2
+	mtcr    r6, ss3
+	mtcr    a2, ss4
+
+	/*
+	 * clear TP in psr[13]
+	 */
+	mfcr    a3, epsr
+	bclri   a3, 13
+	mtcr    a3, epsr
+
+	SET_CP_MMU
+#ifdef CONFIG_MMU_HARD_REFILL
+	RD_PGDR	r6
+	bclri   r6, 0
+	lrw	a3, PHYS_OFFSET
+	subu	r6, a3
+	bseti   r6, 31
+#else
+	lrw     r6, (pgd_current)
+	ldw     r6, (r6)
+#endif
+
+	RD_MEH  a3
+	mov     a2, a3
+	lsri    a2, _PGDIR_SHIFT
+	lsli    a2, 2
+	addu    r6, a2
+
+	/*
+	 * get pte table to r6
+	 */
+	ldw     r6, (r6)
+#ifdef CONFIG_MMU_HARD_REFILL
+	lrw	a2, PHYS_OFFSET
+	subu	r6, a2
+	bseti   r6, 31
+#endif
+
+	lsri    a3, PTE_INDX_SHIFT
+	lrw     a2, PTE_INDX_MSK
+	and     a3, a2
+	addu    r6, a3
+	ldw     a3, (r6)/* get pte to a3*/
+
+	bgeni   a2, 31	/* TLB probe command, a2 = 0x80000000 */
+	WR_MCIR	a2	/* find faulting entry */
+
+	/*
+	 * if _PAGE_WRITE == 0, goto tlbmodified.
+	 */
+	movi    a2, _PAGE_WRITE
+	and     a3, a2
+	cmpnei  a3, 0
+	bf      tlbmodified
+	ldw     a3, (r6)
+
+	/*
+	 * Present and writable bits set, set accessed and dirty bits.
+	 * a2 = (_PAGE_ACCESSED | _PAGE_MODIFIED | _PAGE_VALID | _PAGE_DIRTY)
+	 */
+#ifdef __CSKYABIV1__
+	movi    a2, 0x18
+	bseti   a2, 7
+	bseti   a2, 8
+#else
+	movi    a2, (_PAGE_ACCESSED | _PAGE_MODIFIED | _PAGE_VALID | _PAGE_DIRTY)
+#endif
+	or      a3, a2
+	stw     a3, (r6)
+
+	/* Now reload the entry into the tlb. */
+	bclri   r6, PTE_BIT
+#ifdef __CSKYABIV1__
+	ldw     a2, (r6, 4)
+	lsri    a2, 6
+	WR_MEL1	a2
+	ldw     a2, (r6)
+	lsri    a2, 6
+	WR_MEL0	a2
+#else
+	ldw     a2, (r6, 4)
+	WR_MEL1 a2
+	ldw     a2, (r6)
+	WR_MEL0 a2
+#endif
+
+	RD_MIR  a3         /* Read MIR */
+	bgeni   a2, 29     /* Use write index by default */
+	btsti   a3, 31     /* Is probe success ? */
+	bf      1f
+	bgeni   a2, 25
+	WR_MCIR a2
+	bgeni   a2, 28     /* If probe failed, invalid index and write random */
+
+1:
+	WR_MCIR	a2
+
+	mfcr    a3, ss2
+	mfcr    r6, ss3
+	mfcr    a2, ss4
+	rte
+
+tlbmodified:
+	mfcr    a3, ss2
+	mfcr    r6, ss3
+	mfcr    a2, ss4
+	SAVE_ALL
+	kuser_cmpxchg_check
+
+	SET_CP_MMU
+	RD_MEH	a3
+	bmaski  r8, 12
+	andn    a3, r8          /* a3 = a3 & (~0xfff) */
+	mov     a2, a3
+	psrset  ee, ie          /* Enable exception & interrupt */
+	mov     a0, sp
+	movi    a1, 1
+	jbsr    (do_page_fault)
+	movi    r11_sig, 0             /* r11 = 0, Not a syscall. */
+	jmpi    (ret_from_exception)
+
+/*
+ * This function is used to handle access exception.
+ */
+ENTRY(buserr)
+	SAVE_ALL
+	SET_SMOD_MMU_CP15
+	movi    r11_sig, 0        /* r11 = 0, Not a syscall. use in signal handle */
+	mov     a0, sp            /* Stack address is arg[0] */
+	jbsr    buserr_c          /* Call C level handler */
+	jmpi    ret_from_exception
+
+ENTRY(system_call)
+	SAVE_ALL
+	SET_SMOD_MMU_CP15
+
+	/*
+	 * Do not use r2-r7 here, because the arguments are saved in r2-r6
+	 * and the syscall number is saved in syscallid when the exception is a
+	 * systemcall.
+	 * Use temp regs instead
+	 *
+	 * When excuting a trap instruction, the pc does not increase.
+	 * The pc should
+	 * be increased manully and save in epc register.
+	 */
+	mfcr    r13, epc                /* Get the trap point */
+
+#if defined(__CSKYABIV1__)
+	addi    r13, 2                  /* Increase the epc */
+#elif defined(__CSKYABIV2__)
+	addi    r13, 4                  /* Increase the epc, because the Instruct "trap x" in CK ISA V2 is 32 bit */
+#endif
+
+	mtcr    r13, epc                /* Save return point */
+	stw     r13, (sp)               /* Save it in stack*/
+	psrset  ee, ie                 /* Enable Exception & interrupt */
+
+	/* Stack frame for syscall, origin call set_esp0 */
+	mov     r12, sp
+
+	bmaski  r11, 13
+	andn    r12, r11
+	bgeni   r11, 9
+	addi    r11, 32
+	addu    r12, r11
+	st      sp, (r12, 0)
+
+	lrw     r11, __NR_syscalls
+	cmphs   syscallid, r11                 /* Check nr of syscall */
+	bt      ret_from_exception
+
+	lrw     r13, sys_call_table
+	ixw     r13, syscallid                 /* Index into syscall table */
+	ldw     r11, (r13)               /* Get syscall function */
+	cmpnei  r11, 0                  /* Check for not null */
+	bf      ret_from_exception
+
+	mov     r9, sp				 /* Get task pointer */
+	bmaski  r10, THREADSIZE_MASK_BIT
+	andn    r9, r10                      /* Get thread_info */
+	ldw     r8, (r9, TINFO_FLAGS)       /* Get thread_info.flags value */
+	btsti   r8, TIF_SYSCALL_TRACE       /* Check if TIF_SYSCALL_TRACE set */
+	bt      1f
+#if defined(__CSKYABIV2__)
+	subi    sp, 8
+	stw  	r5, (sp, 0x4)
+	stw  	r4, (sp, 0x0)
+	jsr     r11                      /* Do system call */
+	addi 	sp, 8
+#else
+	jsr     r11
+#endif
+	stw     a0, (sp, LSAVE_A0)      /* Save return value */
+	jmpi    ret_from_exception
+
+1:
+	movi    a0, 0                   /* enter system call */
+	mov     a1, sp                  /* right now, sp --> pt_regs */
+	jbsr    syscall_trace
+	/* Prepare args before do system call */
+	ldw     a0, (sp, LSAVE_A0)
+	ldw     a1, (sp, LSAVE_A1)
+	ldw     a2, (sp, LSAVE_A2)
+	ldw     a3, (sp, LSAVE_A3)
+#if defined(__CSKYABIV2__)
+	subi    sp, 8
+	stw     r5, (sp, 0x4)
+	stw     r4, (sp, 0x0)
+#else
+	ldw     r6, (sp, LSAVE_REGS0)
+	ldw     r7, (sp, LSAVE_REGS1)
+#endif
+	jsr     r11                     /* Do system call */
+#if defined(__CSKYABIV2__)
+	addi    sp, 8
+#endif
+	stw     a0, (sp, LSAVE_A0)     /* Save return value */
+
+	movi    a0, 1                   /* leave system call */
+	mov     a1, sp                  /* right now, sp --> pt_regs */
+	jbsr    syscall_trace
+
+syscall_exit_work:
+	ld       syscallid, (sp, 8)     /* get psr, is user mode? */
+	btsti    syscallid, 31
+	bt       2f
+
+	jmpi     resume_userspace
+
+2:      RESTORE_ALL
+
+ENTRY(ret_from_kernel_thread)
+	jbsr     schedule_tail
+	mov	 a0, r8
+	jsr	 r9
+	jbsr     ret_from_exception
+
+
+ENTRY(ret_from_fork)
+	jbsr     schedule_tail
+	mov      r9, sp				 /* Get task pointer */
+	bmaski   r10, THREADSIZE_MASK_BIT
+	andn     r9, r10                     /* Get thread_info */
+	ldw      r8, (r9, TINFO_FLAGS)       /* Get thread_info.flags value */
+	movi     r11_sig, 1                  /* is a syscall */
+	btsti    r8, TIF_SYSCALL_TRACE       /* Check if TIF_SYSCALL_TRACE set */
+	bf       3f
+	movi     a0, 1                       /* leave system call */
+	mov      a1, sp                      /* right now, sp --> pt_regs */
+	jbsr     syscall_trace
+3:
+	jbsr     ret_from_exception
+
+ret_from_exception:
+	ld       syscallid, (sp,8)     /* get psr, is user mode? */
+	btsti    syscallid, 31
+	bt       1f
+	/*
+	 * Load address of current->thread_info, Then get address of task_struct
+	 * Get task_needreshed in task_struct
+	 */
+	mov     r9, sp     					 /* Get current stack  pointer */
+	bmaski  r10, THREADSIZE_MASK_BIT
+	andn    r9, r10                      /* Get task_struct */
+
+resume_userspace:
+	ldw      r8, (r9, TINFO_FLAGS)
+	andi     r8, (_TIF_SIGPENDING | _TIF_NOTIFY_RESUME | _TIF_NEED_RESCHED)
+	cmpnei   r8, 0
+	bt       exit_work
+1:  RESTORE_ALL
+
+exit_work:
+	mov      a0, sp                 /* Stack address is arg[0] */
+	jbsr     set_esp0               /* Call C level */
+	btsti    r8, TIF_NEED_RESCHED
+	bt       work_resched
+	cmpnei   r8, 0		/* If thread_info->flag is empty, RESTORE_ALL. */
+	bf       1b
+	mov      a1, sp
+	mov      a0, r8
+	mov      a2, r11_sig        /* syscall? */
+	btsti    r8, TIF_SIGPENDING /* delivering a signal? */
+	clrt     r11_sig            /* prevent further restarts(set r11 = 0) */
+	jbsr     do_notify_resume	/* do signals */
+	br       resume_userspace
+
+work_resched:
+	lrw      syscallid, ret_from_exception
+	mov      r15, syscallid                /* Return address in link */
+	jmpi     schedule
+
+ENTRY(sys_rt_sigreturn)
+	movi	r11_sig, 0
+	jmpi	do_rt_sigreturn
+
+/*
+ * Common trap handler. Standard traps come through here first
+ */
+
+ENTRY(trap)
+	SAVE_ALL
+	SET_SMOD_MMU_CP15
+
+	movi     r11_sig, 0             /* r11 = 0, Not a syscall. */
+	mfcr     a0, psr                /* Get psr register */
+	lsri     a0, 16                 /* Get vector in base 8 bits */
+	sextb    a0                     /* Fill upper bytes with zero */
+	mov      a1, sp                 /* Push Stack pointer arg */
+	jbsr     trap_c                 /* Call C-level trap handler */
+	jmpi     ret_from_exception
+
+/*
+ * Common illegal handler.
+ */
+
+ENTRY(handle_illegal)
+	SAVE_ALL
+	psrset   ee
+	movi     r11_sig, 0             /* r11 = 0, Not a syscall. */
+	mov      a0, sp                 /* Push Stack pointer arg */
+	jbsr     handle_illegal_c       /* Call C-level trap handler */
+	jmpi     ret_from_exception
+
+/*
+ * Alignment_exception handler.
+ */
+ENTRY(alignment)
+	SAVE_ALL
+	SET_SMOD_MMU_CP15
+	psrset   ee                     /* Enable Exception */
+	movi     r11_sig, 0             /* r11 = 0, Not a syscall. */
+	mov      a0, sp                 /* Push Stack pointer arg */
+	jbsr     alignment_c            /* Call C-level align exception handler */
+	jmpi     ret_from_exception
+
+ENTRY(trap1)
+#if defined(__CSKYABIV1__)
+	mtcr     sp, ss1
+	mfcr     sp, ss0
+	mtcr     a1, ss4
+#elif defined(__CSKYABIV2__)
+	subi     sp, 8
+	stw      a1,(sp)
+#endif
+	mfcr     a1, epc                /* Get the trap point */
+#if defined(__CSKYABIV1__)
+	addi     a1, 2                  /* Increase the epc */
+#elif defined(__CSKYABIV2__)
+	addi     a1, 4                  /* Increase the epc, because the Instruct "trap x" in CK ISA V2 is 32 bit */
+#endif
+	mtcr     a1, epc                /* Save return point */
+
+	movi     a1, 0x32
+	mtcr     a1, cr17
+#if defined(__CSKYABIV1__)
+	mfcr     a1, ss4
+	mtcr     sp, ss0
+	mfcr     sp, ss1
+#elif defined(__CSKYABIV2__)
+	ldw      a1,(sp)
+	addi     sp, 8
+#endif
+	rte
+
+/*
+ * exception  trap 2 use to cmpxchg, reference prototype:
+ *      int __kernel_cmpxchg(int oldval, int newval, int *ptr)
+ *
+ * If *ptr != oldval, direct return 1,
+ * else set *ptr = newval, then return 0.
+ *
+ * Input:
+ *      a0 = oldval
+ *      a1 = newval
+ *      a2 = ptr
+ * Output:
+ *      a0 = returned value (zero or non-zero)
+ *
+ * Clobbered:
+ *      a3!
+ *
+ * Attention: trap 2 is not a atomic function!
+ * The "stw a1, (a2)" may produce tlbmodified exception, then may cause schedule.
+ * So return back to "ldw" after tlbmodified, if stw was interrupted.
+ */
+
+ENTRY(trap2)
+#if defined(__CSKYABIV1__)
+	mtcr     sp, ss1
+	mfcr     sp, ss0
+#endif
+	mfcr     a3, epc		/* Get the trap point */
+#if defined(__CSKYABIV1__)
+	addi     a3, 2			/* Increase the epc */
+#elif defined(__CSKYABIV2__)
+	addi     a3, 4			/* Increase the epc, because the Instruct "trap x" in CK ISA V2 is 32 bit */
+#endif
+	subi     sp, 8
+	stw      a3, (sp, 0)		/* need to save epc to sp */
+	mfcr     a3, epsr
+	stw      a3, (sp, 4)		/* need to save epsr to sp */
+
+	psrset   ee			/* Enable Exception for tlb exception */
+
+1:					/* "1" is for kuser_cmpxchg_fixup */
+	ldw      a3, (a2)
+	cmpne    a0, a3
+#if defined(__CSKYABIV1__)
+	bt       3f
+#elif defined(__CSKYABIV2__)
+	bt16     3f
+#endif
+2:					/* "2" is for kuser_cmpxchg_fixup */
+	stw      a1, (a2)
+3:
+	mvc      a0			/* return value */
+	ldw      a3, (sp, 0)		/* restore epc */
+	mtcr     a3, epc
+	ldw      a3, (sp, 4)		/* restore epsr */
+	mtcr     a3, epsr
+	addi     sp, 8
+#if defined(__CSKYABIV1__)
+	mtcr     sp, ss0
+	mfcr     sp, ss1
+#endif
+	rte
+
+/*
+ *  Called from kuser_cmpxchg_check macro.
+ *  Input:
+ *  	a0 = address of interrupted insn(epc).
+ *  	1b = first critical insn, 2b = last critical insn.
+ *  Output:
+ *	None.
+ *
+ *  Clobbered:
+ *      a0, a1!
+ *
+ *  If a2 == 2b then saved pt_regs's epc is set to 1b.
+ */
+ENTRY(kuser_cmpxchg_fixup)
+	lrw	a1, 2b
+	cmpne	a1, a0
+	bt	1f
+	subi	a1, (2b - 1b)		/* get 1b */
+	stw	a1, (sp, 0)		/* set pt_reg's epc = 1b */
+1:
+	rts
+
+/*
+ * Reference prototype:
+ *  int __kernel_get_tls(int addr)
+ * Input:
+ *  none 
+ * Output:
+ *  r2 = TLS value
+ * Clobbered:
+ *  none
+ * Definition and user space usage example:
+ *  typedef int (__kernel_get_tls_t)(int addr);
+ * Get the TLS value as previously set via the set_thread_area syscall.
+ * This could be used as follows:
+ * #define __kernel_get_tls() \
+ *  ({ register unsigned int __result asm("a0"); \
+ *         asm( "trap  3" \
+ *          : "=r" (__result) : :  ); \
+ *     __result; })
+ */
+ENTRY(trap3)                        /*added for get tls*/
+#if defined(__CSKYABIV1__)
+	mtcr     sp, ss1
+	mfcr     sp, ss0
+#endif
+
+	subi     sp, 8                  /* because sp may align wich 0x2000 */
+	mfcr     a0, epc                /* Get the trap point */
+#if defined(__CSKYABIV1__)
+	addi     a0, 2                  /* Increase the epc */
+#elif defined(__CSKYABIV2__)
+	addi     a0, 4                  /* Increase the epc, because the Instruct "trap x" in CK ISA V2 is 32 bit */
+#endif
+	mtcr     a0, epc                /* Save return point */
+
+	bmaski   a0, (PAGE_SHIFT + 1)   /* kernel stack is 2*page if page is 4k */
+	not      a0
+	and      a0, sp                 /* thread_info local in bottom of stack */
+
+	ldw      a0, (a0, TINFO_TP_VALUE) /* get tls */
+
+	addi     sp, 8
+#if defined(__CSKYABIV1__)
+	mtcr     sp, ss0
+	mfcr     sp, ss1
+#endif
+	rte
+
+/*
+ * handle FPU exception.
+ */
+ENTRY(handle_fpe)
+	SAVE_ALL
+	/* Clear FPU exception state */
+#if defined(CONFIG_CPU_HAS_FPU)
+	mfcr      a0, cr<2, 2>	       /* fpu fesr is cr<2,2> in CSKY_CPUV2 */
+	movi      r11_sig, 0           /* r11 = 0, Not a syscall. */
+	mov       a1, sp               /* Push Stack pointer arg */
+	jbsr      handle_fpe_c         /* Call C-level fpe handler */
+#endif
+	jmpi      ret_from_exception
+
+/*
+ * handle interrupt.
+ */
+ENTRY(inthandler)
+	SAVE_ALL
+	SET_SMOD_MMU_CP15
+	psrset	ee				/* Enable exceptions */
+
+	movi	r11_sig, 0			/* r11 = 0, Not a syscall. */
+
+#ifdef CONFIG_PREEMPT
+	mov	r9, sp				/* Get current stack  pointer */
+	bmaski  r10, THREADSIZE_MASK_BIT
+	andn    r9, r10				/* Get thread_info */
+
+	ldw      r8, (r9, TINFO_PREEMPT)
+	addi     r8, 1
+	stw      r8, (r9, TINFO_PREEMPT)
+#endif
+	mfcr     a0, psr                /* Get PSR register */
+	lsri     a0, 16                 /* Get vector in 7 bits */
+	sextb    a0                     /* Fill upper bytes with zero */
+	subi     a0, 32                 /* Real irq nomber need sub VEC offset(32)*/
+	mov      a1, sp                 /* arg[1] is stack pointer */
+	jbsr     csky_do_IRQ          /* Call handler */
+
+#ifdef CONFIG_PREEMPT
+	subi     r8, 1
+	stw      r8, (r9, TINFO_PREEMPT)
+	cmpnei   r8, 0
+	bt       2f
+	ldw      r8, (r9, TINFO_FLAGS)
+	btsti    r8, TIF_NEED_RESCHED
+	bf       2f
+1:
+	jbsr     preempt_schedule_irq   /* irq en/disable is done inside */
+	ldw      r7, (r9, TINFO_FLAGS)  /* get new tasks TI_FLAGS */
+	btsti    r7, TIF_NEED_RESCHED
+	bt       1b                     /* go again */
+#endif
+2:
+	jmpi     ret_from_exception
+
+/*
+ * This is the auto-vectored interrupt handler (for all hardware interrupt
+ * sources). It figures out the vector number and calls the appropriate
+ * interrupt service routine directly. This is for auto-vectored normal
+ * interrupts only.
+ *
+ */
+
+ENTRY(autohandler)
+	SAVE_ALL
+	SET_SMOD_MMU_CP15
+	psrset  ee       // enable exception
+	movi    r11_sig, 0                   /* r11 = 0, Not a syscall. */
+
+#ifdef CONFIG_PREEMPT
+	mov     r9, sp                       /* Get current stack  pointer */
+	bmaski  r10, THREADSIZE_MASK_BIT
+	andn    r9, r10                      /* Get thread_info */
+
+	/*
+	 * Get task_struct->stack.preempt_count for current,
+	 * and increase 1.
+	 */
+	ldw      r8, (r9, TINFO_PREEMPT)
+	addi     r8, 1
+	stw      r8, (r9, TINFO_PREEMPT)
+#endif
+
+	mov      a0, sp                      /* arg[0] is stack pointer */
+	jbsr     csky_do_auto_IRQ          /* Call handler */
+
+#ifdef CONFIG_PREEMPT
+	subi     r8, 1
+	stw      r8, (r9, TINFO_PREEMPT)
+	cmpnei   r8, 0
+	bt       2f
+	ldw      r8, (r9, TINFO_FLAGS)
+	btsti    r8, TIF_NEED_RESCHED
+	bf       2f
+1:
+	jbsr     preempt_schedule_irq   /* irq en/disable is done inside */
+	ldw      r7, (r9, TINFO_FLAGS)  /* get new tasks TI_FLAGS */
+	btsti    r7, TIF_NEED_RESCHED
+	bt       1b                     /* go again */
+#endif
+2:
+	jmpi     ret_from_exception
+
+/*
+ * a0 =  prev task_struct *
+ * a1 =  next task_struct *
+ * a0 =  return next
+ */
+ENTRY(__switch_to)
+	lrw      a3, TASK_THREAD        /* struct_thread offset in task_struct */
+	addu     a3, a0                 /* a3 point to thread in prev task_struct */
+
+	mfcr     a2, psr                /* Save PSR value */
+	stw      a2, (a3, THREAD_SR)    /* Save PSR in task struct */
+	bclri    a2, 6                  /* Disable interrupts */
+	mtcr     a2, psr
+
+	SAVE_SWITCH_STACK
+
+#if defined(__CSKYABIV2__)
+	mfcr     r6, cr<14, 1>           /* Get current usp */
+#else
+	mfcr     r6, ss1                /* Get current usp */
+#endif
+	stw      r6, (a3, THREAD_USP)   /* Save usp in task struct */
+	stw      sp, (a3, THREAD_KSP)   /* Save ksp in task struct */
+
+#ifdef CONFIG_CPU_HAS_FPU
+	FPU_SAVE_REGS
+#endif
+
+#if  defined(CONFIG_CPU_HAS_DSP) || defined(__CK810__)
+	/* Save DSP regs */
+	lrw      r10, THREAD_DSPHI
+	add      r10, a3
+	mfhi     r6
+	mflo     r7
+	stw      r6, (r10, 0)           /* THREAD_DSPHI */
+	stw      r7, (r10, 4)           /* THREAD_DSPLO */
+	mfcr     r6, cr14
+	stw      r6, (r10, 8)           /* THREAD_DSPCSR */
+#endif
+
+	/* Set up next process to run */
+	lrw      a3, TASK_THREAD	/* struct_thread offset in task_struct */
+	addu     a3, a1			/* a3 point to thread in next task_struct */
+
+	ldw      sp, (a3, THREAD_KSP)	/* Set next ksp */
+	ldw      r6, (a3, THREAD_USP)	/* Set next usp */
+
+#if defined(__CSKYABIV2__)
+	mtcr     r6, cr<14, 1>           /* Get current usp */
+#else
+	mtcr     r6, ss1                /* Get current usp */
+#endif
+
+#ifdef CONFIG_CPU_HAS_FPU
+	FPU_RESTORE_REGS
+#endif
+
+#if  defined(CONFIG_CPU_HAS_DSP) || defined(__CSKYABIV2__)
+	lrw      r10, THREAD_DSPHI
+	add      r10, a3
+	ldw      r6, (r10, 8)   /* THREAD_DSPCSR */
+#if defined(__CSKYABIV2__)
+	mtcr     r6, cr14
+#else
+	/*
+	 * Because bit 0 in CK610's cr14 is read only, we need to restore it by
+	 * using special method
+	 */
+	btsti    r6, 0
+	movi     r7, 0xf
+	bf       1f
+	bmaski   r7, 0           /* old is "lrw r7, 0xffffffff" */
+1:
+	mthi     r7
+	mulua    r7, r7
+#endif
+	/* Restore DSP regs */
+	ldw      r6, (r10, 0)    /* THREAD_DSPHI */
+	ldw      r7, (r10, 4)    /* THREAD_DSPLO */
+	mthi     r6
+	mtlo     r7
+#endif
+
+	ldw      a2, (a3, THREAD_SR)    /* Set next PSR */
+	mtcr     a2, psr
+
+#if  defined(__CSKYABIV2__)
+	/* set TLS register (r31) */
+	addi     r7, a1, TASK_THREAD_INFO
+	ldw      r31, (r7, TINFO_TP_VALUE)
+#endif
+
+	RESTORE_SWITCH_STACK
+
+	rts
+ENDPROC(__switch_to)
diff --git a/arch/csky/kernel/head.S b/arch/csky/kernel/head.S
new file mode 100644
index 0000000..cfcb215
--- /dev/null
+++ b/arch/csky/kernel/head.S
@@ -0,0 +1,18 @@
+#include <linux/linkage.h>
+#include <linux/init.h>
+#include <asm/page.h>
+#include <abi/regdef.h>
+
+ENTRY(_start)
+	/* set super user mode */
+	lrw	a3, DEFAULT_PSR_VALUE
+	mtcr    a3, psr
+	psrset  ee
+
+	/* set stack point */
+	lrw     a3, init_thread_union + THREAD_SIZE
+	mov	sp, a3
+
+	jmpi	csky_start
+END(_start)
+
diff --git a/arch/csky/kernel/irq-csky.c b/arch/csky/kernel/irq-csky.c
new file mode 100644
index 0000000..17b7057
--- /dev/null
+++ b/arch/csky/kernel/irq-csky.c
@@ -0,0 +1,136 @@
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/of.h>
+#include <linux/of_address.h>
+#include <linux/module.h>
+#include <linux/irqdomain.h>
+#include <linux/irqchip.h>
+#include <linux/irq.h>
+#include <linux/interrupt.h>
+#include <asm/irq.h>
+#include <asm/io.h>
+
+static unsigned int intc_reg;
+
+#define CK_VA_INTC_ICR		(void *)(intc_reg + 0x00)	/* Interrupt control register(High 16bits) */
+#define CK_VA_INTC_ISR		(void *)(intc_reg + 0x00)	/* Interrupt status register(Low 16bits) */
+#define CK_VA_INTC_NEN31_00	(void *)(intc_reg + 0x10)	/* Normal interrupt enable register Low */
+#define	CK_VA_INTC_NEN63_32	(void *)(intc_reg + 0x28)	/* Normal interrupt enable register High */
+#define	CK_VA_INTC_SOURCE	(void *)(intc_reg + 0x40)	/* Proiority Level Select Registers 0 */
+
+static void ck_irq_mask(struct irq_data *d)
+{
+	unsigned int temp, irq;
+
+	irq = d->irq;
+
+	if (irq < 32) {
+		temp = __raw_readl(CK_VA_INTC_NEN31_00);
+		temp &= ~(1 << irq);
+		__raw_writel(temp, CK_VA_INTC_NEN31_00);
+	} else {
+		temp = __raw_readl(CK_VA_INTC_NEN63_32);
+		temp &= ~(1 << (irq -32));
+		__raw_writel(temp, CK_VA_INTC_NEN63_32);
+	}
+}
+
+static void ck_irq_unmask(struct irq_data *d)
+{
+	unsigned int temp, irq;
+
+	irq = d->irq;
+
+	if (irq < 32) {
+		temp = __raw_readl(CK_VA_INTC_NEN31_00);
+		temp |= 1 << irq;
+		__raw_writel(temp, CK_VA_INTC_NEN31_00);
+	} else {
+		temp = __raw_readl(CK_VA_INTC_NEN63_32);
+		temp |= 1 << (irq -32);
+		__raw_writel(temp, CK_VA_INTC_NEN63_32);
+	}
+}
+
+static struct irq_chip ck_irq_chip = {
+	.name		= "csky_intc_v1",
+	.irq_mask	= ck_irq_mask,
+	.irq_unmask	= ck_irq_unmask,
+};
+
+static int ck_irq_map(struct irq_domain *h, unsigned int virq,
+				irq_hw_number_t hw_irq_num)
+{
+	irq_set_chip_and_handler(virq, &ck_irq_chip, handle_level_irq);
+	return 0;
+}
+
+static const struct irq_domain_ops ck_irq_ops = {
+	.map	= ck_irq_map,
+	.xlate	= irq_domain_xlate_onecell,
+};
+
+static unsigned int ck_get_irqno(void)
+{
+	unsigned int temp;
+	temp = __raw_readl(CK_VA_INTC_ISR);
+	return temp & 0x3f;
+};
+
+static int __init
+__intc_init(struct device_node *np, struct device_node *parent, bool ave)
+{
+	struct irq_domain *root_domain;
+	int i;
+
+	csky_get_auto_irqno = ck_get_irqno;
+
+	if (parent)
+		panic("pic not a root intc\n");
+
+	intc_reg = (unsigned int)of_iomap(np, 0);
+	if (!intc_reg)
+		panic("%s, of_iomap err.\n", __func__);
+
+	__raw_writel(0, CK_VA_INTC_NEN31_00);
+	__raw_writel(0,	CK_VA_INTC_NEN63_32);
+
+	if (ave == true)
+		__raw_writel( 0xc0000000, CK_VA_INTC_ICR);
+	else
+		__raw_writel( 0x0, CK_VA_INTC_ICR);
+	/*
+	 * csky irq ctrl has 64 sources.
+	 */
+	#define INTC_IRQS 64
+	for (i=0; i<INTC_IRQS; i=i+4)
+		__raw_writel((i+3)|((i+2)<<8)|((i+1)<<16)|(i<<24),
+				CK_VA_INTC_SOURCE + i);
+
+	root_domain = irq_domain_add_legacy(np, INTC_IRQS, 0, 0, &ck_irq_ops, NULL);
+	if (!root_domain)
+		panic("root irq domain not available\n");
+
+	irq_set_default_host(root_domain);
+
+	return 0;
+}
+
+static int __init
+intc_init(struct device_node *np, struct device_node *parent)
+{
+
+	return __intc_init(np, parent, false);
+}
+IRQCHIP_DECLARE(csky_intc_v1, "csky,intc-v1", intc_init);
+
+/*
+ * use auto vector exceptions 10 for interrupt.
+ */
+static int __init
+intc_init_ave(struct device_node *np, struct device_node *parent)
+{
+	return __intc_init(np, parent, true);
+}
+IRQCHIP_DECLARE(csky_intc_v1_ave, "csky,intc-v1,ave", intc_init_ave);
+
diff --git a/arch/csky/kernel/irq-dahua.c b/arch/csky/kernel/irq-dahua.c
new file mode 100644
index 0000000..920443b
--- /dev/null
+++ b/arch/csky/kernel/irq-dahua.c
@@ -0,0 +1,221 @@
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/of.h>
+#include <linux/of_address.h>
+#include <linux/module.h>
+#include <linux/irqdomain.h>
+#include <linux/irqchip.h>
+#include <linux/irq.h>
+#include <linux/interrupt.h>
+#include <asm/irq.h>
+#include <asm/io.h>
+
+static unsigned int intc_reg;
+
+#define DHC_PIC_BASE	intc_reg
+
+/* register */
+#define DHC_REG_PIC_MODE        0x0000
+#define DHC_REG_PIC_PO          0x0004
+#define DHC_REG_PIC_MASK        0x0008
+#define DHC_REG_PIC_VECTOR      0x000C
+#define DHC_REG_PIC_COW1        0x0010
+
+#define DHC_REG_PIC_PRIOR0      0x0014
+#define DHC_REG_PIC_PRIOR1      0x0018
+#define DHC_REG_PIC_PRIOR2      0x001C
+#define DHC_REG_PIC_PRIOR3      0x0020
+#define DHC_REG_PIC_PRIOR4      0x0024
+#define DHC_REG_PIC_PRIOR5      0x0028
+#define DHC_REG_PIC_PRIOR6      0x002C
+#define DHC_REG_PIC_PRIOR7      0x0030
+
+#define DHC_REG_PIC_COW2        0x0034
+#define DHC_REG_PIC_STATUS      0x0054
+
+#define DHC_REG_PIC_STATUS1     0x0058
+#define DHC_REG_PIC_MODE1       0x0060
+#define DHC_REG_PIC_PO1         0x0064
+#define DHC_REG_PIC_MASK1       0x0068
+#define DHC_REG_PIC_PRIOR8      0x006c
+#define DHC_REG_PIC_PRIOR9      0x0070
+#define DHC_REG_PIC_PRIOR10     0x0074
+#define DHC_REG_PIC_PRIOR11     0x0078
+#define DHC_REG_PIC_PRIOR12     0x007c
+#define DHC_REG_PIC_PRIOR13     0x0080
+#define DHC_REG_PIC_PRIOR14     0x0084
+#define DHC_REG_PIC_PRIOR15     0x0088
+
+/* register map */
+#define DHC_PR_PIC_MODE         ( *( volatile unsigned int *)( DHC_PIC_BASE + DHC_REG_PIC_MODE ) )
+#define DHC_PR_PIC_PO           ( *( volatile unsigned int *)( DHC_PIC_BASE + DHC_REG_PIC_PO ) )
+#define DHC_PR_PIC_MASK         ( *( volatile unsigned int *)( DHC_PIC_BASE + DHC_REG_PIC_MASK ) )
+#define DHC_PR_PIC_VECTOR       ( *( volatile unsigned int *)( DHC_PIC_BASE + DHC_REG_PIC_VECTOR ) )
+#define DHC_PR_PIC_COW1         ( *( volatile unsigned int *)( DHC_PIC_BASE + DHC_REG_PIC_COW1 ) )
+
+#define DHC_PR_PIC_PRIOR0       ( *( volatile unsigned int *)( DHC_PIC_BASE + DHC_REG_PIC_PRIOR0 ) )
+#define DHC_PR_PIC_PRIOR1       ( *( volatile unsigned int *)( DHC_PIC_BASE + DHC_REG_PIC_PRIOR1 ) )
+#define DHC_PR_PIC_PRIOR2       ( *( volatile unsigned int *)( DHC_PIC_BASE + DHC_REG_PIC_PRIOR2 ) )
+#define DHC_PR_PIC_PRIOR3       ( *( volatile unsigned int *)( DHC_PIC_BASE + DHC_REG_PIC_PRIOR3 ) )
+#define DHC_PR_PIC_PRIOR4       ( *( volatile unsigned int *)( DHC_PIC_BASE + DHC_REG_PIC_PRIOR4 ) )
+#define DHC_PR_PIC_PRIOR5       ( *( volatile unsigned int *)( DHC_PIC_BASE + DHC_REG_PIC_PRIOR5 ) )
+#define DHC_PR_PIC_PRIOR6       ( *( volatile unsigned int *)( DHC_PIC_BASE + DHC_REG_PIC_PRIOR6 ) )
+#define DHC_PR_PIC_PRIOR7       ( *( volatile unsigned int *)( DHC_PIC_BASE + DHC_REG_PIC_PRIOR7 ) )
+
+#define DHC_PR_PIC_COW2         ( *( volatile unsigned int *)( DHC_PIC_BASE + DHC_REG_PIC_COW2 ) )
+#define DHC_PR_PIC_STATUS       ( *( volatile unsigned int *)( DHC_PIC_BASE + DHC_REG_PIC_STATUS ) )
+
+
+#define DHC_PR_PIC_STATUS1      ( *( volatile unsigned int *)( DHC_PIC_BASE + DHC_REG_PIC_STATUS1 ) )
+#define DHC_PR_PIC_MODE1        ( *( volatile unsigned int *)( DHC_PIC_BASE + DHC_REG_PIC_MODE1 ) )
+#define DHC_PR_PIC_PO1          ( *( volatile unsigned int *)( DHC_PIC_BASE + DHC_REG_PIC_PO1 ) )
+#define DHC_PR_PIC_MASK1        ( *( volatile unsigned int *)( DHC_PIC_BASE + DHC_REG_PIC_MASK1 ) )
+#define DHC_PR_PIC_PRIOR8       ( *( volatile unsigned int *)( DHC_PIC_BASE + DHC_REG_PIC_PRIOR8 ) )
+#define DHC_PR_PIC_PRIOR9       ( *( volatile unsigned int *)( DHC_PIC_BASE + DHC_REG_PIC_PRIOR9 ) )
+#define DHC_PR_PIC_PRIOR10      ( *( volatile unsigned int *)( DHC_PIC_BASE + DHC_REG_PIC_PRIOR10 ) )
+#define DHC_PR_PIC_PRIOR11      ( *( volatile unsigned int *)( DHC_PIC_BASE + DHC_REG_PIC_PRIOR11 ) )
+#define DHC_PR_PIC_PRIOR12      ( *( volatile unsigned int *)( DHC_PIC_BASE + DHC_REG_PIC_PRIOR12 ) )
+#define DHC_PR_PIC_PRIOR13      ( *( volatile unsigned int *)( DHC_PIC_BASE + DHC_REG_PIC_PRIOR13 ) )
+#define DHC_PR_PIC_PRIOR14      ( *( volatile unsigned int *)( DHC_PIC_BASE + DHC_REG_PIC_PRIOR14 ) )
+#define DHC_PR_PIC_PRIOR15      ( *( volatile unsigned int *)( DHC_PIC_BASE + DHC_REG_PIC_PRIOR15 ) )
+
+/* PIC_MODE */
+#define DHC_REG_PIC_TRI_EDGE        ( 0x01 )
+#define DHC_REG_PIC_TRI_EDGE_ALL    ( 0xFFFFFFFF )
+#define DHC_REG_PIC_TRI_LEVEL       ( 0x00 )
+#define DHC_REG_PIC_TRI_LEVEL_ALL   ( 0x00 )
+
+/* PIC_PO */
+#define DHC_REG_PIC_POS_H           ( 0x01 )        /* posedge or high level */
+#define DHC_REG_PIC_POS_H_ALL       ( 0xFFFFFFFF )
+
+#define DHC_REG_PIC_NEG_L           ( 0x00 )        /* negedge or low level */
+#define DHC_REG_PIC_NEG_L_ALL       ( 0x00 )
+
+
+/* PIC_MASK */
+#define DHC_REG_PIC_MASK_BIT        ( 0x01 )
+#define DHC_REG_PIC_MASK_ALL        ( 0xFFFFFFFF )
+
+#define DHC_REG_PIC_UNMASK_BIT      ( 0x00 )
+#define DHC_REG_PIC_UNMASK_ALL      ( 0x00 )
+
+/* COW1 */
+#define DHC_REG_PIC_COW1_EOI	    ( 0x02 )
+#define DHC_REG_PIC_COW1_FEOI	    ( 0x03 )
+
+#define DHC_NR_IRQS                 ( 64 )
+
+static void ck_irq_mask(struct irq_data *d)
+{
+	if(d->irq < 32)
+	{
+		DHC_PR_PIC_MASK |= ( 1 << d->irq );
+	}
+	else
+	{
+		DHC_PR_PIC_MASK1 |= ( 1 << (d->irq - 32) );
+	}
+}
+
+static void ck_irq_unmask(struct irq_data *d)
+{
+	if(d->irq < 32)
+	{
+		DHC_PR_PIC_MASK &= ~( 1 << d->irq );
+	}
+	else
+	{
+		DHC_PR_PIC_MASK1 &= ~( 1 << (d->irq - 32) );
+	}
+
+}
+
+static struct irq_chip ck_irq_chip = {
+	.name		= "dahua_intc_v1",
+	.irq_mask	= ck_irq_mask,
+	.irq_unmask	= ck_irq_unmask,
+};
+
+static int ck_irq_map(struct irq_domain *h, unsigned int virq,
+				irq_hw_number_t hw_irq_num)
+{
+	irq_set_chip_and_handler(virq, &ck_irq_chip, handle_level_irq);
+	return 0;
+}
+
+static const struct irq_domain_ops ck_irq_ops = {
+	.map	= ck_irq_map,
+	.xlate	= irq_domain_xlate_onecell,
+};
+
+static unsigned int ck_get_irqno(void)
+{
+	return DHC_PR_PIC_STATUS & 0x7f;
+};
+
+static int __init
+__intc_init(struct device_node *np, struct device_node *parent, int ave)
+{
+	struct irq_domain *root_domain;
+
+	if (parent)
+		panic("pic not a root intc\n");
+
+	intc_reg = (unsigned int)of_iomap(np, 0);
+	if (!intc_reg)
+		panic("%s, of_iomap err.\n", __func__);
+
+	csky_get_auto_irqno = ck_get_irqno;
+
+	/* set all pic_mode to edge */
+	DHC_PR_PIC_MODE  = DHC_REG_PIC_TRI_EDGE_ALL;
+	DHC_PR_PIC_MODE1 = DHC_REG_PIC_TRI_EDGE_ALL;
+
+	/* set posedge */
+	DHC_PR_PIC_PO  = DHC_REG_PIC_POS_H_ALL;
+	DHC_PR_PIC_PO1 = DHC_REG_PIC_POS_H_ALL;
+
+	/* set mask */
+	DHC_PR_PIC_MASK  = DHC_REG_PIC_MASK_ALL;
+	DHC_PR_PIC_MASK1 = DHC_REG_PIC_MASK_ALL;
+	DHC_PR_PIC_COW2  = 0x42;
+
+	/*
+	 * Initial the Interrupt source priority level registers
+	 */
+	DHC_PR_PIC_PRIOR0  = 0x03020100 + 0x40404040;
+	DHC_PR_PIC_PRIOR1  = 0x07060504 + 0x40404040;
+	DHC_PR_PIC_PRIOR2  = 0x0b0a0908 + 0x40404040;
+	DHC_PR_PIC_PRIOR3  = 0x0f0e0d0c + 0x40404040;
+
+	DHC_PR_PIC_PRIOR4  = 0x13121110 + 0x40404040;
+	DHC_PR_PIC_PRIOR5  = 0x17161514 + 0x40404040;
+	DHC_PR_PIC_PRIOR6  = 0x1b1a1918 + 0x40404040;
+	DHC_PR_PIC_PRIOR7  = 0x1f1e1d1c + 0x40004040;
+
+	DHC_PR_PIC_PRIOR8  = 0x03020100 + 0x40404040;
+	DHC_PR_PIC_PRIOR9  = 0x07060504 + 0x40404040;
+	DHC_PR_PIC_PRIOR10 = 0x0b0a0908 + 0x40404040;
+	DHC_PR_PIC_PRIOR11 = 0x0f0e0d0c + 0x40404040;
+	DHC_PR_PIC_PRIOR12 = 0x13121110 + 0x40404040;
+	DHC_PR_PIC_PRIOR13 = 0x17161514 + 0x40404040;
+	DHC_PR_PIC_PRIOR14 = 0x1b1a1918 + 0x40404040;
+	DHC_PR_PIC_PRIOR15 = 0x1f1e1d1c + 0x40404040;
+
+	root_domain = irq_domain_add_legacy(np, DHC_NR_IRQS, 0, 0, &ck_irq_ops, NULL);
+	if (!root_domain)
+		panic("root irq domain not available\n");
+
+	irq_set_default_host(root_domain);
+
+	return 0;
+}
+
+static int __init
+intc_init(struct device_node *np, struct device_node *parent)
+{
+	return __intc_init(np, parent, true);
+}
+IRQCHIP_DECLARE(dahua_intc_v1, "dahua,intc-v1", intc_init);
+
diff --git a/arch/csky/kernel/irq-nationalchip.c b/arch/csky/kernel/irq-nationalchip.c
new file mode 100644
index 0000000..0d0be54
--- /dev/null
+++ b/arch/csky/kernel/irq-nationalchip.c
@@ -0,0 +1,194 @@
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/of.h>
+#include <linux/of_address.h>
+#include <linux/module.h>
+#include <linux/irqdomain.h>
+#include <linux/irqchip.h>
+#include <linux/irq.h>
+#include <linux/interrupt.h>
+#include <asm/irq.h>
+#include <asm/io.h>
+
+#define NC_VA_INTC_NINT31_00		(void *)(intc_reg + 0x00)
+#define NC_VA_INTC_NINT63_32		(void *)(intc_reg + 0x04)
+#define NC_VA_INTC_NPEND31_00		(void *)(intc_reg + 0x10)
+#define NC_VA_INTC_NPEND63_32		(void *)(intc_reg + 0x14)
+#define NC_VA_INTC_NENSET31_00		(void *)(intc_reg + 0x20)
+#define NC_VA_INTC_NENSET63_32		(void *)(intc_reg + 0x24)
+#define NC_VA_INTC_NENCLR31_00		(void *)(intc_reg + 0x30)
+#define NC_VA_INTC_NENCLR63_32		(void *)(intc_reg + 0x34)
+#define NC_VA_INTC_NEN31_00		(void *)(intc_reg + 0x40)
+#define NC_VA_INTC_NEN63_32		(void *)(intc_reg + 0x44)
+#define NC_VA_INTC_NMASK31_00		(void *)(intc_reg + 0x50)
+#define NC_VA_INTC_NMASK63_32		(void *)(intc_reg + 0x54)
+#define NC_VA_INTC_SOURCE		(void *)(intc_reg + 0x60)
+
+static unsigned int intc_reg;
+
+static void nc_irq_mask(struct irq_data *d)
+{
+	unsigned int mask, irq;
+
+	irq = d->irq;
+
+	if (irq < 32) {
+		mask = __raw_readl(NC_VA_INTC_NMASK31_00);
+		mask |= 1 << irq;
+		__raw_writel(mask, NC_VA_INTC_NMASK31_00);
+	} else {
+		mask = __raw_readl(NC_VA_INTC_NMASK63_32);
+		mask |= 1 << (irq - 32);
+		__raw_writel(mask, NC_VA_INTC_NMASK63_32);
+	}
+}
+
+static void nc_irq_unmask(struct irq_data *d)
+{
+	unsigned int mask, irq;
+
+	irq = d->irq;
+
+	if (irq < 32) {
+		mask = __raw_readl(NC_VA_INTC_NMASK31_00);
+		mask &= ~( 1 << irq);
+		__raw_writel(mask, NC_VA_INTC_NMASK31_00);
+	} else {
+		mask = __raw_readl( NC_VA_INTC_NMASK63_32);
+		mask &= ~(1 << (irq - 32));
+		__raw_writel(mask, NC_VA_INTC_NMASK63_32);
+	}
+}
+
+static void nc_irq_en(struct irq_data *d)
+{
+	unsigned int mask, irq;
+
+	irq = d->irq;
+
+	if (irq < 32) {
+		mask = 1 << irq;
+		__raw_writel(mask, NC_VA_INTC_NENSET31_00);
+	} else {
+		mask = 1 << (irq - 32);
+		__raw_writel(mask, NC_VA_INTC_NENSET63_32);
+	}
+
+	nc_irq_unmask(d);
+}
+
+static void nc_irq_dis(struct irq_data *d)
+{
+	unsigned int mask, irq;
+
+	irq = d->irq;
+
+	if (irq < 32) {
+		mask = 1 << irq;
+		__raw_writel(mask, NC_VA_INTC_NENCLR31_00);
+	} else {
+		mask = 1 << (irq - 32);
+		__raw_writel(mask, NC_VA_INTC_NENCLR63_32);
+	}
+
+	nc_irq_mask(d);
+}
+
+struct irq_chip nc_irq_chip = {
+	.name =		"nationalchip_intc_v1",
+	.irq_mask =	nc_irq_mask,
+	.irq_unmask =	nc_irq_unmask,
+	.irq_enable =	nc_irq_en,
+	.irq_disable =	nc_irq_dis,
+};
+
+inline int ff1_64(unsigned int hi, unsigned int lo)
+{
+	int result;
+	__asm__ __volatile__(
+		"ff1 %0"
+		:"=r"(hi)
+		:"r"(hi)
+		:
+	);
+
+	__asm__ __volatile__(
+		"ff1 %0"
+		:"=r"(lo)
+		:"r"(lo)
+		:
+	);
+	if( lo != 32 )
+		result = 31-lo;
+	else if( hi != 32 ) result = 31-hi + 32;
+	else {
+		printk("nc_get_irqno error hi:%x, lo:%x.\n", hi, lo);
+		result = NR_IRQS;
+	}
+	return result;
+}
+
+unsigned int nc_get_irqno(void)
+{
+	unsigned int nint64hi, nint64lo, irq_no;
+
+	nint64lo = __raw_readl(NC_VA_INTC_NINT31_00);
+	nint64hi = __raw_readl(NC_VA_INTC_NINT63_32);
+	irq_no = ff1_64(nint64hi, nint64lo);
+
+	return irq_no;
+}
+
+static int irq_map(struct irq_domain *h, unsigned int virq,
+				irq_hw_number_t hw_irq_num)
+{
+	irq_set_chip_and_handler(virq, &nc_irq_chip, handle_level_irq);
+
+	return 0;
+}
+
+static const struct irq_domain_ops nc_irq_ops = {
+	.map	= irq_map,
+	.xlate	= irq_domain_xlate_onecell,
+};
+
+static int __init
+intc_init(struct device_node *intc, struct device_node *parent)
+{
+	struct irq_domain *root_domain;
+	unsigned int i;
+
+	if (parent)
+		panic("DeviceTree incore intc not a root irq controller\n");
+
+	csky_get_auto_irqno = nc_get_irqno;
+
+	intc_reg = (unsigned int) of_iomap(intc, 0);
+	if (!intc_reg)
+		panic("Nationalchip Intc Reg: %x.\n", intc_reg);
+
+	__raw_writel(0xffffffff, NC_VA_INTC_NENCLR31_00);
+	__raw_writel(0xffffffff, NC_VA_INTC_NENCLR63_32);
+	__raw_writel(0xffffffff, NC_VA_INTC_NMASK31_00);
+	__raw_writel(0xffffffff, NC_VA_INTC_NMASK63_32);
+
+	/*
+	 * nationalchip irq ctrl has 64 sources.
+	 */
+	#define INTC_IRQS 64
+	for (i=0; i<INTC_IRQS; i=i+4)
+		__raw_writel(i|((i+1)<<8)|((i+2)<<16)|((i+3)<<24),
+				NC_VA_INTC_SOURCE + i);
+
+	root_domain = irq_domain_add_legacy(intc, INTC_IRQS, 0, 0,
+			&nc_irq_ops, NULL);
+	if (!root_domain)
+		panic("root irq domain not avail\n");
+
+	irq_set_default_host(root_domain);
+
+	return 0;
+}
+
+IRQCHIP_DECLARE(nationalchip_intc_v1_ave, "nationalchip,intc-v1,ave", intc_init);
+
diff --git a/arch/csky/kernel/irq.c b/arch/csky/kernel/irq.c
new file mode 100644
index 0000000..6fd13d9
--- /dev/null
+++ b/arch/csky/kernel/irq.c
@@ -0,0 +1,33 @@
+#include <linux/init.h>
+#include <linux/interrupt.h>
+#include <linux/irq.h>
+#include <linux/irqchip.h>
+
+unsigned int (*csky_get_auto_irqno) (void) = NULL;
+
+int arch_show_interrupts(struct seq_file *p, int prec)
+{
+	return 0;
+}
+
+asmlinkage void csky_do_IRQ(int irq, struct pt_regs *regs)
+{
+	struct pt_regs *old_regs = set_irq_regs(regs);
+
+	irq_enter();
+	generic_handle_irq(irq);
+	irq_exit();
+
+	set_irq_regs(old_regs);
+}
+
+asmlinkage void csky_do_auto_IRQ(struct pt_regs *regs)
+{
+	csky_do_IRQ(csky_get_auto_irqno(), regs);
+}
+
+void __init init_IRQ(void)
+{
+	irqchip_init();
+}
+
diff --git a/arch/csky/kernel/module.c b/arch/csky/kernel/module.c
new file mode 100644
index 0000000..2ab379d
--- /dev/null
+++ b/arch/csky/kernel/module.c
@@ -0,0 +1,192 @@
+#include <linux/moduleloader.h>
+#include <linux/elf.h>
+#include <linux/mm.h>
+#include <linux/vmalloc.h>
+#include <linux/slab.h>
+#include <linux/fs.h>
+#include <linux/string.h>
+#include <linux/kernel.h>
+#include <linux/spinlock.h>
+#include <asm/pgtable.h>
+
+#if 0
+#define DEBUGP printk
+#else
+#define DEBUGP(fmt...)
+#endif
+
+#define IS_BSR32(hi16, lo16)        (((hi16) & 0xFC00) == 0xE000)
+#define IS_JSRI32(hi16, lo16)       ((hi16) == 0xEAE0)
+#define CHANGE_JSRI_TO_LRW(addr)    *(uint16_t *)(addr) = (*(uint16_t *)(addr) & 0xFF9F) | 0x0019; \
+							  *((uint16_t *)(addr) + 1) = *((uint16_t *)(addr) + 1) & 0xFFFF
+#define SET_JSR32_R25(addr)         *(uint16_t *)(addr) = 0xE8F9; \
+							  *((uint16_t *)(addr) + 1) = 0x0000;
+
+#ifdef CONFIG_MODULES
+
+void *module_alloc(unsigned long size)
+{
+#ifdef MODULE_START
+	struct vm_struct *area;
+
+	size = PAGE_ALIGN(size);
+	if (!size)
+		return NULL;
+
+	area = __get_vm_area(size, VM_ALLOC, MODULE_START, MODULE_END);
+	if (!area)
+		return NULL;
+
+	return __vmalloc_area(area, GFP_KERNEL, PAGE_KERNEL);
+#else
+	if (size == 0)
+		return NULL;
+	return vmalloc(size);
+#endif
+}
+
+/*
+ * Free memory returned from module_alloc
+ */
+void module_free(struct module *mod, void *module_region)
+{
+	vfree(module_region);
+	/* FIXME: If module_region == mod->init_region, trim exception
+	   table entries. */
+}
+
+/*
+ * We don't need anything special.
+ */
+int module_frob_arch_sections(Elf_Ehdr *hdr, Elf_Shdr *sechdrs,
+		char *secstrings, struct module *mod)
+{
+	return 0;
+}
+
+int apply_relocate(Elf_Shdr *sechdrs, const char *strtab, unsigned int symindex,
+		unsigned int relsec, struct module *me)
+{
+	unsigned int i;
+	Elf32_Rel *rel = (void *)sechdrs[relsec].sh_addr;
+	Elf32_Sym *sym;
+	uint32_t *location;
+	short * temp;
+
+	DEBUGP("Applying relocate section %u to %u\n", relsec,
+			sechdrs[relsec].sh_info); 
+	for (i = 0; i < sechdrs[relsec].sh_size / sizeof(*rel); i++) {
+		/* This is where to make the change */
+		location = (void *)sechdrs[sechdrs[relsec].sh_info].sh_addr
+			+ rel[i].r_offset;
+		/* This is the symbol it is referring to.  Note that all
+		   undefined symbols have been resolved.  */
+		sym = (Elf32_Sym *)sechdrs[symindex].sh_addr
+			+ ELF32_R_SYM(rel[i].r_info);
+		switch (ELF32_R_TYPE(rel[i].r_info)) {
+		case R_CSKY_NONE:
+		case R_CSKY_PCRELJSR_IMM11BY2:
+		case R_CSKY_PCRELJSR_IMM26BY2:
+			/* ignore */
+			break;
+		case R_CSKY_32:
+			/* We add the value into the location given */
+			*location += sym->st_value;
+			break;
+		case R_CSKY_PC32:
+			/* Add the value, subtract its postition */
+			*location += sym->st_value - (uint32_t)location;
+			break;
+		case R_CSKY_ADDR_HI16:
+			temp = ((short  *)location) + 1;
+			*temp = (short)((sym->st_value) >> 16);
+			break;
+		case R_CSKY_ADDR_LO16:
+			temp = ((short  *)location) + 1;
+			*temp = (short)((sym->st_value) & 0xffff);
+			break;
+		default:
+			printk(KERN_ERR "module %s: Unknown relocation: %u\n",
+					me->name, ELF32_R_TYPE(rel[i].r_info));
+			return -ENOEXEC;
+		}
+	}
+	return 0;
+}
+
+int apply_relocate_add(Elf32_Shdr *sechdrs, const char *strtab,
+		unsigned int symindex, unsigned int relsec, struct module *me)
+{
+	unsigned int i;
+	Elf32_Rela *rel = (void *)sechdrs[relsec].sh_addr;
+	Elf32_Sym *sym;
+	uint32_t *location;
+	short * temp;
+#ifdef CONFIG_CPU_CSKYV2
+	uint16_t *location_tmp;
+#endif
+
+	DEBUGP("Applying relocate_add section %u to %u\n", relsec,
+			sechdrs[relsec].sh_info);
+	for (i = 0; i < sechdrs[relsec].sh_size / sizeof(*rel); i++) {
+		/* This is where to make the change */
+		location = (void *)sechdrs[sechdrs[relsec].sh_info].sh_addr
+			+ rel[i].r_offset;
+		/* This is the symbol it is referring to.  Note that all
+		   undefined symbols have been resolved.  */
+		sym = (Elf32_Sym *)sechdrs[symindex].sh_addr
+			+ ELF32_R_SYM(rel[i].r_info);
+
+		switch (ELF32_R_TYPE(rel[i].r_info)) {
+		case R_CSKY_32:
+			/* We add the value into the location given */
+			*location = rel[i].r_addend + sym->st_value;
+			break;
+		case R_CSKY_PC32:
+			/* Add the value, subtract its postition */
+			*location = rel[i].r_addend + sym->st_value
+				- (uint32_t)location;
+			break;
+		case R_CSKY_PCRELJSR_IMM11BY2:
+			break;
+		case R_CSKY_PCRELJSR_IMM26BY2:
+#ifdef CONFIG_CPU_CSKYV2
+			location_tmp = (uint16_t *)location;
+			if (IS_BSR32(*location_tmp, *(location_tmp + 1)))
+				break;
+			else if (IS_JSRI32(*location_tmp, *(location_tmp + 1))) {
+				/* jsri 0x...  --> lrw r25, 0x... */
+				CHANGE_JSRI_TO_LRW(location);
+				/* lsli r0, r0 --> jsr r25 */
+				SET_JSR32_R25(location + 1);
+			}
+#endif
+			break;
+		case R_CSKY_ADDR_HI16:
+			temp = ((short  *)location) + 1;
+			*temp = (short)((rel[i].r_addend + sym->st_value) >> 16);
+			break;
+		case R_CSKY_ADDR_LO16:
+			temp = ((short  *)location) + 1;
+			*temp = (short)((rel[i].r_addend + sym->st_value) & 0xffff);
+			break;
+		default:
+			printk(KERN_ERR "module %s: Unknown relocation: %u\n",
+					me->name, ELF32_R_TYPE(rel[i].r_info));
+			return -ENOEXEC;
+		}
+	}
+	return 0;
+}
+
+int module_finalize(const Elf_Ehdr *hdr, const Elf_Shdr *sechdrs,
+		struct module *mod)
+{
+	return 0;
+}
+
+void module_arch_cleanup(struct module *mod)
+{
+}
+
+#endif /* CONFIG_MODULES */
diff --git a/arch/csky/kernel/platform.c b/arch/csky/kernel/platform.c
new file mode 100644
index 0000000..3f60c05
--- /dev/null
+++ b/arch/csky/kernel/platform.c
@@ -0,0 +1,16 @@
+#include <linux/init.h>
+#include <linux/of_platform.h>
+#include <linux/of_address.h>
+#include <linux/of_fdt.h>
+#include <linux/err.h>
+#include <linux/slab.h>
+#include <linux/sys_soc.h>
+#include <linux/io.h>
+
+static int __init csky_platform_init(void)
+{
+	return of_platform_default_populate(NULL, NULL, NULL);
+}
+device_initcall(csky_platform_init);
+
+
diff --git a/arch/csky/kernel/power.c b/arch/csky/kernel/power.c
new file mode 100644
index 0000000..126b674
--- /dev/null
+++ b/arch/csky/kernel/power.c
@@ -0,0 +1,29 @@
+#include <linux/reboot.h>
+
+void (*pm_power_off)(void);
+EXPORT_SYMBOL(pm_power_off);
+
+void machine_power_off(void)
+{
+	local_irq_disable();
+	if (pm_power_off)
+		pm_power_off();
+	while(1);
+}
+
+void machine_halt(void)
+{
+	local_irq_disable();
+	if (pm_power_off)
+		pm_power_off();
+	while(1);
+}
+
+void machine_restart(char *cmd)
+{
+	local_irq_disable();
+	do_kernel_restart(cmd);
+	while(1);
+}
+
+
diff --git a/arch/csky/kernel/process.c b/arch/csky/kernel/process.c
new file mode 100644
index 0000000..2cea5fa
--- /dev/null
+++ b/arch/csky/kernel/process.c
@@ -0,0 +1,171 @@
+#include <linux/sched.h>
+#include <linux/module.h>
+
+struct cpuinfo_csky cpu_data[NR_CPUS];
+
+asmlinkage void ret_from_fork(void);
+asmlinkage void ret_from_kernel_thread(void);
+
+/*
+ * Return saved PC from a blocked thread
+ */
+unsigned long thread_saved_pc(struct task_struct *tsk)
+{
+	struct switch_stack *sw = (struct switch_stack *)tsk->thread.ksp;
+
+	return sw->r15;
+}
+
+void show_regs(struct pt_regs * regs)
+{
+	printk("\n");
+	printk("PC: %08lx  Status: %04lx  orig_a0: %08lx  %s\n",
+                regs->pc, regs->sr, regs->orig_a0, print_tainted());
+
+#if defined(__CSKYABIV1__)
+	printk("r2: %08lx   r3: %08lx   r4: %08lx   r5: %08lx \n",
+		regs->a0, regs->a1, regs->a2, regs->a3);
+	printk("r6: %08lx   r7: %08lx   r8: %08lx   r9: %08lx \n",
+		regs->regs[0], regs->regs[1], regs->regs[2], regs->regs[3]);
+	printk("r10: %08lx  r11: %08lx  r12: %08lx  r13: %08lx \n",
+		regs->regs[4], regs->regs[5], regs->regs[6], regs->regs[7]);
+	printk("r14: %08lx  r1: %08lx  r15: %08lx\n \n",
+		regs->regs[8], regs->regs[9], regs->r15);
+#endif
+
+#if defined(__CSKYABIV2__)
+        printk("r16:0x%08lx    r17: 0x%08lx    r18: 0x%08lx    r19: 0x%08lx\n",
+                regs->exregs[0], regs->exregs[1], regs->exregs[2], regs->exregs[3]);
+        printk("r20 0x%08lx    r21: 0x%08lx    r22: 0x%08lx    r23: 0x%08lx\n",
+                regs->exregs[4], regs->exregs[5], regs->exregs[6], regs->exregs[7]);
+        printk("r24 0x%08lx    r25: 0x%08lx    r26: 0x%08lx    r27: 0x%08lx\n",
+                regs->exregs[8], regs->exregs[9], regs->exregs[10], regs->exregs[11]);
+        printk("r28 0x%08lx    r29: 0x%08lx    r30: 0x%08lx    r31: 0x%08lx\n",
+                regs->exregs[12], regs->exregs[13], regs->exregs[14], regs->exregs[15]);
+        printk("hi 0x%08lx     lo: 0x%08lx \n",
+                regs->rhi, regs->rlo);
+#endif
+
+	if (!(regs->sr & PS_S))
+		printk("USP: %08lx\n", rdusp());
+}
+
+/*
+ * Some archs flush debug and FPU info here
+ */
+void flush_thread(void)
+{
+}
+
+int copy_thread(unsigned long clone_flags,
+		unsigned long usp,
+		unsigned long kthread_arg,
+		struct task_struct *p)
+{
+	struct switch_stack * childstack;
+	unsigned long reg_psr = 0;
+	struct pt_regs *childregs = task_pt_regs(p);
+
+	preempt_disable();
+
+	__asm__ __volatile__("mfcr   %0, psr\n\t"
+			     :"+r"(reg_psr):);
+
+#ifdef CONFIG_CPU_HAS_FPU
+	save_fp_to_thread(p->thread.fp, &p->thread.fcr, &p->thread.fsr,
+	     &p->thread.fesr);
+#endif
+#if defined(CONFIG_CPU_HAS_DSP) || defined(__CSKYABIV2__)
+	__asm__ __volatile__("mfhi    %0 \n\r"
+			     "mflo    %1 \n\r"
+			    :"=r"(p->thread.hi), "=r"(p->thread.lo)
+		            :);
+#endif
+	preempt_enable();
+
+	childstack = ((struct switch_stack *) childregs) - 1;
+	memset(childstack, 0, sizeof(struct switch_stack));
+
+	/* setup ksp for switch_to !!! */
+	p->thread.ksp = (unsigned long)childstack;
+
+	if (unlikely(p->flags & PF_KTHREAD)) {
+		memset(childregs, 0, sizeof(struct pt_regs));
+		childstack->r15 = (unsigned long) ret_from_kernel_thread;
+		childstack->r8 = kthread_arg;
+		childstack->r9 = usp;
+		childregs->sr = reg_psr;
+
+		return 0;
+	} else {
+		*childregs = *(current_pt_regs());
+		childstack->r15 = (unsigned long) ret_from_fork;
+	}
+
+	/* Return 0 for subprocess when return from fork(),vfork(),clone() */
+	childregs->a0 = 0;
+
+	if (usp != 0)
+		p->thread.usp = usp;
+	else
+		p->thread.usp = rdusp();
+
+	if (clone_flags & CLONE_SETTLS) {
+		task_thread_info(p)->tp_value = (current_pt_regs())->regs[0];
+#ifdef __CSKYABIV2__
+		childregs->exregs[15] = task_thread_info(p)->tp_value;
+#endif
+	}
+
+	return 0;
+}
+
+/* Fill in the fpu structure for a core dump.  */
+int dump_fpu (struct pt_regs *regs, struct user_cskyfp_struct *fpu)
+{
+	memcpy(fpu, &current->thread.fcr, sizeof(*fpu));
+	return 1;
+}
+EXPORT_SYMBOL(dump_fpu);
+
+int dump_task_regs(struct task_struct *tsk, elf_gregset_t *pr_regs)
+{
+	struct pt_regs *regs = (struct pt_regs *)(tsk->thread.esp0);
+
+	/* NOTE: usp is error value. */
+	ELF_CORE_COPY_REGS ((*pr_regs), regs)
+
+	/* Now fix usp in pr_regs, usp is in pr_regs[2] */
+#if defined(__CSKYABIV2__)
+	(*pr_regs)[16] = tsk->thread.usp;
+#else
+	(*pr_regs)[2] = tsk->thread.usp;
+#endif
+
+	return 1;
+}
+
+unsigned long get_wchan(struct task_struct *p)
+{
+	unsigned long esp, pc;
+	unsigned long stack_page;
+	int count = 0;
+	if (!p || p == current || p->state == TASK_RUNNING)
+		return 0;
+
+	stack_page = (unsigned long)p;
+	esp = p->thread.esp0;
+	do {
+		if (esp < stack_page+sizeof(struct task_struct) ||
+		    esp >= 8184+stack_page)
+			return 0;
+		/*FIXME: There's may be error here!*/
+		pc = ((unsigned long *)esp)[1];
+		/* FIXME: This depends on the order of these functions. */
+		if (!in_sched_functions(pc))
+			return pc;
+		esp = *(unsigned long *) esp;
+	} while (count++ < 16);
+	return 0;
+}
+
diff --git a/arch/csky/kernel/ptrace.c b/arch/csky/kernel/ptrace.c
new file mode 100644
index 0000000..4ced657
--- /dev/null
+++ b/arch/csky/kernel/ptrace.c
@@ -0,0 +1,289 @@
+#include <linux/kernel.h>
+#include <linux/sched.h>
+#include <linux/mm.h>
+#include <linux/smp.h>
+#include <linux/errno.h>
+#include <linux/ptrace.h>
+#include <linux/user.h>
+#include <linux/signal.h>
+
+#include <asm/uaccess.h>
+#include <asm/page.h>
+#include <asm/pgtable.h>
+#include <asm/processor.h>
+#include <asm/asm-offsets.h>
+
+/*
+ * does not yet catch signals sent when the child dies.
+ * in exit.c or in signal.c.
+ */
+
+/* sets the trace bits. */
+#define TRACE_MODE_SI      1 << 14
+#define TRACE_MODE_RUN     0
+#define TRACE_MODE_JMP     0x3 << 14
+#define TRACE_MODE_MASK    ~(0x3 << 14)
+
+/*
+ * PT_xxx is the stack offset at which the register is  saved.
+ * Notice that usp has no stack-slot and needs to be treated
+ * specially (see get_reg/put_reg below).
+ * No usrsp of CSKY ABIV2 in this array !
+ */
+static int regoff[] = {
+#if defined(__CSKYABIV2__)
+	PT_A0,    PT_A1,     PT_A2,    PT_A3,
+	PT_REGS0, PT_REGS1,  PT_REGS2, PT_REGS3,
+	PT_REGS4, PT_REGS5,  PT_REGS6, PT_REGS7,
+	PT_REGS8, PT_REGS9,  -1,       PT_R15,
+	PT_R16,   PT_R17,    PT_R18,   PT_R19,
+	PT_R20,   PT_R21,    PT_R22,   PT_R23,
+	PT_R24,   PT_R25,    PT_R26,   PT_R27,
+	PT_R28,   PT_R29,    PT_R30,   PT_R31,
+	PT_SR,    PT_PC,     PT_RHI,   PT_RLO,
+#else
+	-1,       PT_REGS9,  PT_A0,    PT_A1,
+	PT_A2,    PT_A3,     PT_REGS0, PT_REGS1,
+	PT_REGS2, PT_REGS3,  PT_REGS4, PT_REGS5,
+	PT_REGS6, PT_REGS7,  PT_REGS8, PT_R15,
+	-1,       -1,        -1,       -1,
+	-1,       -1,        -1,       -1,
+	-1,       -1,        -1,       -1,
+	-1,       -1,        -1,       -1,
+	PT_SR,    PT_PC,     -1,       -1,
+#endif
+};
+
+/*
+ * Get contents of register REGNO in task TASK.
+ */
+static long get_reg(struct task_struct *task, int regno)
+{
+	unsigned long *addr;
+
+	if (regno == REGNO_USP)
+		addr = &task->thread.usp;
+	else if ((regno < sizeof(regoff)/sizeof(regoff[0])) && (regoff[regno] != -1))
+		addr = (unsigned long *)(task->thread.esp0 + regoff[regno]);
+	else
+		return 0;
+	return *addr;
+}
+
+/*
+ * Write contents of register REGNO in task TASK.
+ */
+static int put_reg(struct task_struct *task, int regno,
+		unsigned long data)
+{
+	unsigned long *addr;
+
+	if (regno == REGNO_USP)
+		addr = &task->thread.usp;
+	else if ((regno < sizeof(regoff) / sizeof(regoff[0])) && (regoff[regno] != -1))
+		addr = (unsigned long *) (task->thread.esp0 + regoff[regno]);
+	else
+		return -1;
+	*addr = data;
+	return 0;
+}
+/*
+ * Make sure the single step bit is not set.
+ */
+static void singlestep_disable(struct task_struct *child)
+{
+	unsigned long tmp;
+	tmp = (get_reg(child, REGNO_SR) & TRACE_MODE_MASK) | TRACE_MODE_RUN;
+	put_reg(child, REGNO_SR, tmp);
+	/* FIXME maybe wrong here: if clear flag of TIF_DELAYED_TRACE? */
+}
+
+
+static void singlestep_enable(struct task_struct *child)
+{
+	unsigned long tmp;
+	tmp = (get_reg(child, REGNO_SR) & TRACE_MODE_MASK) | TRACE_MODE_SI;
+	put_reg(child, REGNO_SR, tmp);
+	/* FIXME maybe wrong here: if set flag of TIF_DELAYED_TRACE? */
+
+}
+
+/*
+ * Make sure the single step bit is set.
+ */
+void user_enable_single_step(struct task_struct *child)
+{
+	if (child->thread.esp0 == 0) return;
+	singlestep_enable(child);
+}
+
+void user_disable_single_step(struct task_struct *child)
+{
+	if (child->thread.esp0 == 0) return;
+	singlestep_disable(child);
+}
+
+int ptrace_getfpregs(struct task_struct *child, void __user *data)
+{
+
+	if (!access_ok(VERIFY_WRITE, data, sizeof(struct user_cskyfp_struct)))
+		return -EIO;
+
+	if(copy_to_user(data, &child->thread.fcr,
+				sizeof(struct user_cskyfp_struct)))
+		return -EFAULT;
+
+	return 0;
+}
+
+int ptrace_setfpregs(struct task_struct *child, void __user *data)
+{
+	if (!access_ok(VERIFY_READ, data, sizeof(struct user_cskyfp_struct)))
+		return -EIO;
+
+	if(copy_from_user(&child->thread.fcr, data,
+				sizeof(struct user_cskyfp_struct)))
+		return -EFAULT;
+	return 0;
+}
+
+/*
+ * Called by kernel/ptrace.c when detaching..
+ *
+ * Make sure the single step bit is not set.
+ */
+void ptrace_disable(struct task_struct *child)
+{
+	singlestep_disable(child);
+}
+
+/*
+ * Handle the requests of ptrace system call.
+ *
+ * INPUT:
+ * child   - process being traced.
+ * request - request type.
+ * addr    - address of data that this request to read from or write to.
+ * data    - address of data that this request to read to or write from.
+ *
+ * RETURN:
+ * 0       - success
+ * others  - fail
+ */
+long arch_ptrace(struct task_struct *child, long request, unsigned long addr,
+		unsigned long data)
+{
+	unsigned long tmp = 0, ret = 0;
+	int i;
+
+	switch (request) {
+		/* read the word at location addr in the USER area. */
+	case PTRACE_PEEKUSR:
+		if (addr & 3)
+			goto out_eio;
+		addr >>= 2;     /* temporary hack. */
+
+		if (addr >= 0 && addr <= CSKY_GREG_NUM) {
+			tmp = get_reg(child, addr);
+		}else if(addr >= CSKY_FREG_NUM_LO && addr < CSKY_FREG_NUM_HI) {
+			tmp = child->thread.fp[addr - CSKY_FREG_NUM_LO];
+		}else if(addr >= CSKY_FREG_NUM_HI && addr < CSKY_FCR_NUM) {
+			tmp = (&(child->thread.fcr))[addr - CSKY_FREG_NUM_HI];
+		} else
+			break;
+		ret = put_user(tmp,(long unsigned int *) data);
+		break;
+
+	case PTRACE_POKEUSR:  /* write the word at location addr in the USER area */
+		if (addr & 3)
+			goto out_eio;
+		addr >>= 2;     /* temporary hack. */
+
+		if (addr >= 0 && addr <= CSKY_GREG_NUM) {
+			if (put_reg(child, addr, data)) /*** should protect 'psr'? ***/
+				goto out_eio;
+		}else if(addr >= CSKY_FREG_NUM_LO && addr < CSKY_FREG_NUM_HI) {
+			child->thread.fp[addr - CSKY_FREG_NUM_LO] = data;
+		}else if(addr >= CSKY_FREG_NUM_HI && addr <= CSKY_FCR_NUM) {
+			(&(child->thread.fcr))[addr - CSKY_FREG_NUM_HI] = data;
+		}else
+			goto out_eio;
+		break;
+	case PTRACE_GETREGS:    /* Get all gp regs from the child. */
+		for (i = 0; i <= CSKY_GREG_NUM; i++) {
+			tmp = get_reg(child, i);
+			ret = put_user(tmp, (unsigned long *)data);
+			if (ret)
+				break;
+			data += sizeof(long);
+		}
+		break;
+	case PTRACE_SETREGS:    /* Set all gp regs in the child. */
+		for (i = 0; i <= CSKY_GREG_NUM; i++) {
+			ret = get_user(tmp, (unsigned long *)data);
+			if (ret)
+				break;
+			put_reg(child, i, tmp);
+			data += sizeof(long);
+		}
+		break;
+
+	case PTRACE_GETFPREGS:
+		ret = ptrace_getfpregs(child, (void  __user *) data);
+		break;
+
+	case PTRACE_SETFPREGS:
+		ret = ptrace_setfpregs(child, (void __user *) data);
+		break;
+
+	case PTRACE_GET_THREAD_AREA:
+		ret = put_user(task_thread_info(child)->tp_value,
+				(long unsigned int *) data);
+		break;
+	default:
+		ret = ptrace_request(child, request, addr, data);
+		break;
+	}
+
+	return ret;
+out_eio:
+	return -EIO;
+}
+
+/*
+ * If process's system calls is traces, do some corresponding handles in this
+ * fuction before entering system call function and after exiting system call
+ * fuction.
+ */
+asmlinkage void syscall_trace(int why, struct pt_regs * regs)
+{
+	long saved_why;
+#ifdef __CSKYABIV2__
+	unsigned int SAVEDNUM =  5;  // r9 in ABIV2
+#else
+	unsigned int SAVEDNUM =  3;  // r9 in ABIV1
+#endif
+	/*
+	 * Save saved_why, why is used to denote syscall entry/exit;
+	 * why = 0:entry, why = 1: exit
+	 */
+	saved_why = regs->regs[SAVEDNUM];
+	regs->regs[SAVEDNUM] = why;
+
+	/* the 0x80 provides a way for the tracing parent to distinguish
+	   between a syscall stop and SIGTRAP delivery */
+	ptrace_notify(SIGTRAP | ((current->ptrace & PT_TRACESYSGOOD)
+				? 0x80 : 0));
+	/*
+	 * this isn't the same as continuing with a signal, but it will do
+	 * for normal use.  strace only continues with a signal if the
+	 * stopping signal is not SIGTRAP.  -brl
+	 */
+	if (current->exit_code) {
+		send_sig(current->exit_code, current, 1);
+		current->exit_code = 0;
+	}
+
+	regs->regs[SAVEDNUM] = saved_why;
+	return;
+}
diff --git a/arch/csky/kernel/qemu-exit.c b/arch/csky/kernel/qemu-exit.c
new file mode 100644
index 0000000..d50030a
--- /dev/null
+++ b/arch/csky/kernel/qemu-exit.c
@@ -0,0 +1,62 @@
+#include <linux/init.h>
+#include <linux/of.h>
+#include <linux/err.h>
+#include <linux/pm.h>
+#include <linux/module.h>
+#include <linux/platform_device.h>
+#include <asm/io.h>
+
+static volatile void *pmaddr;
+
+static void qemu_pm_power_off(void)
+{
+	*(unsigned int *)pmaddr = 0;
+}
+
+static int qemuexit_platform_probe(struct platform_device *dev)
+{
+	struct resource *res_mem;
+	void * __pmaddr;
+	int err;
+
+	res_mem = platform_get_resource(dev, IORESOURCE_MEM, 0);
+	__pmaddr = devm_ioremap_resource(&dev->dev, res_mem);
+	if (IS_ERR(__pmaddr)) {
+		err = PTR_ERR(__pmaddr);
+		return err;
+	}
+
+	pmaddr = __pmaddr;
+	pm_power_off = qemu_pm_power_off;
+
+	return 0;
+}
+
+static const struct of_device_id qemuexit_ids[] = {
+	{ .compatible = "csky,qemu-exit", },
+	{}
+};
+MODULE_DEVICE_TABLE(of, qemuexit_ids);
+
+static struct platform_driver qemuexit_platform_driver = {
+	.probe		= qemuexit_platform_probe,
+	.driver		= {
+		.name	= "qemu-exit",
+		.of_match_table = qemuexit_ids,
+	}
+};
+
+static int __init qemuexit_platform_init(void)
+{
+	return platform_driver_register(&qemuexit_platform_driver);
+}
+module_init(qemuexit_platform_init);
+
+static void __exit qemuexit_cleanup(void)
+{
+	platform_driver_unregister(&qemuexit_platform_driver);
+}
+module_exit(qemuexit_cleanup);
+
+MODULE_DESCRIPTION("C-SKY QMEU exit");
+MODULE_LICENSE("GPL");
diff --git a/arch/csky/kernel/setup.c b/arch/csky/kernel/setup.c
new file mode 100644
index 0000000..e6f9122
--- /dev/null
+++ b/arch/csky/kernel/setup.c
@@ -0,0 +1,147 @@
+#include <linux/console.h>
+#include <linux/memblock.h>
+#include <linux/bootmem.h>
+#include <linux/initrd.h>
+#include <linux/of.h>
+#include <linux/of_fdt.h>
+#include <linux/start_kernel.h>
+#include <asm/sections.h>
+#include <asm/mmu_context.h>
+#include <asm/pgalloc.h>
+
+phys_addr_t __init_memblock memblock_end_of_REG0(void)
+{
+	return (memblock.memory.regions[0].base + memblock.memory.regions[0].size);
+}
+
+phys_addr_t __init_memblock memblock_start_of_REG1(void)
+{
+	return memblock.memory.regions[1].base;
+}
+
+size_t __init_memblock memblock_size_of_REG1(void)
+{
+	return memblock.memory.regions[1].size;
+}
+
+static void __init csky_memblock_init(void)
+{
+	unsigned long zone_size[MAX_NR_ZONES];
+	unsigned long zhole_size[MAX_NR_ZONES];
+	signed long size;
+
+	memblock_reserve(__pa(_stext), _end - _stext);
+#ifdef CONFIG_BLK_DEV_INITRD
+	memblock_reserve(__pa(initrd_start), initrd_end - initrd_start);
+#endif
+
+	early_init_fdt_reserve_self();
+	early_init_fdt_scan_reserved_mem();
+
+	memblock_dump_all();
+
+	memset(zone_size, 0, sizeof(zone_size));
+	memset(zhole_size, 0, sizeof(zhole_size));
+
+	min_low_pfn = PFN_UP(memblock_start_of_DRAM());
+	max_low_pfn = PFN_UP(memblock_end_of_REG0());
+	max_pfn = PFN_DOWN(memblock_end_of_DRAM());
+
+	size = max_pfn - min_low_pfn;
+
+	if (memblock.memory.cnt > 1) {
+		zone_size[ZONE_NORMAL]  = PFN_DOWN(memblock_start_of_REG1()) - min_low_pfn;
+		zhole_size[ZONE_NORMAL] = PFN_DOWN(memblock_start_of_REG1()) - max_low_pfn;
+	} else {
+		if (size <= PFN_DOWN(LOWMEM_LIMIT - CONFIG_RAM_BASE))
+			zone_size[ZONE_NORMAL] = max_pfn - min_low_pfn;
+		else {
+			zone_size[ZONE_NORMAL] = PFN_DOWN(LOWMEM_LIMIT - CONFIG_RAM_BASE);
+			max_low_pfn = min_low_pfn + zone_size[ZONE_NORMAL];
+		}
+	}
+
+#ifdef CONFIG_HIGHMEM
+	size = 0;
+	if(memblock.memory.cnt > 1) {
+		size = PFN_DOWN(memblock_size_of_REG1());
+		highstart_pfn = PFN_DOWN(memblock_start_of_REG1());
+	} else {
+		size = max_pfn - min_low_pfn - PFN_DOWN(LOWMEM_LIMIT - CONFIG_RAM_BASE);
+		highstart_pfn =  min_low_pfn + PFN_DOWN(LOWMEM_LIMIT - CONFIG_RAM_BASE);
+	}
+
+	if (size > 0)
+		zone_size[ZONE_HIGHMEM] = size;
+
+	highend_pfn = max_pfn;
+#endif
+	memblock_set_current_limit(PFN_PHYS(max_low_pfn));
+
+	free_area_init_node(0, zone_size, min_low_pfn, zhole_size);
+}
+
+extern void cpu_dt_probe(void);
+extern void init_fpu(void);
+void __init setup_arch(char **cmdline_p)
+{
+	*cmdline_p = boot_command_line;
+
+	console_verbose();
+
+	printk("C-SKY: https://c-sky.github.io\n");
+
+	init_mm.start_code = (unsigned long) _stext;
+	init_mm.end_code = (unsigned long) _etext;
+	init_mm.end_data = (unsigned long) _edata;
+	init_mm.brk = (unsigned long) _end;
+
+	parse_early_param();
+
+	csky_memblock_init();
+
+	unflatten_and_copy_device_tree();
+
+	cpu_dt_probe();
+
+	sparse_init();
+
+	pgd_init((unsigned long *)swapper_pg_dir);
+
+#ifdef CONFIG_HIGHMEM
+	kmap_init();
+#endif
+	cache_op_all(INS_CACHE|DATA_CACHE|CACHE_CLR|CACHE_INV, 0);
+
+#if defined(CONFIG_VT) && defined(CONFIG_DUMMY_CONSOLE)
+	conswitchp = &dummy_con;
+#endif
+	init_fpu();
+}
+
+asmlinkage __visible void __init csky_start(
+	unsigned int	unused,
+	void *		param
+	)
+{
+	/* Setup mmu as coprocessor */
+	select_mmu_cp();
+
+	/* Setup page mask to 4k */
+	write_mmu_pagemask(0);
+
+	/* Clean up bss section */
+	memset(__bss_start, 0, __bss_stop - __bss_start);
+
+#ifdef CONFIG_CSKY_BUILTIN_DTB
+	printk("Use builtin dtb\n");
+	early_init_dt_scan(__dtb_start);
+#else
+	early_init_dt_scan(param);
+#endif
+	printk("Phys. mem: %ldMB\n", (unsigned long) memblock_phys_mem_size()/1024/1024);
+	start_kernel();
+
+	while(1);
+}
+
diff --git a/arch/csky/kernel/signal.c b/arch/csky/kernel/signal.c
new file mode 100644
index 0000000..5203025
--- /dev/null
+++ b/arch/csky/kernel/signal.c
@@ -0,0 +1,470 @@
+#include <linux/sched.h>
+#include <linux/mm.h>
+#include <linux/kernel.h>
+#include <linux/signal.h>
+#include <linux/syscalls.h>
+#include <linux/errno.h>
+#include <linux/wait.h>
+#include <linux/ptrace.h>
+#include <linux/unistd.h>
+#include <linux/stddef.h>
+#include <linux/highuid.h>
+#include <linux/personality.h>
+#include <linux/tty.h>
+#include <linux/binfmts.h>
+#include <linux/tracehook.h>
+#include <linux/freezer.h>
+
+#include <asm/setup.h>
+#include <asm/uaccess.h>
+#include <asm/pgtable.h>
+#include <asm/traps.h>
+#include <asm/ucontext.h>
+#include <abi/regdef.h>
+#include <asm/vdso.h>
+
+#define _BLOCKABLE (~(sigmask(SIGKILL) | sigmask(SIGSTOP)))
+
+struct rt_sigframe
+{
+	int sig;
+	struct siginfo *pinfo;
+	void *puc;
+	struct siginfo info;
+	struct ucontext uc;
+};
+
+typedef struct fpregset {
+	int f_fcr;
+	int f_fsr;		/* Nothing in CPU_CSKYV2 */
+	int f_fesr;
+	int f_feinst1;		/* Nothing in CPU_CSKYV2 */
+	int f_feinst2;		/* Nothing in CPU_CSKYV2 */
+	int f_fpregs[32];
+} fpregset_t;
+
+static inline int restore_fpu_state(struct sigcontext *sc)
+{
+	int err = 0;
+#ifdef CONFIG_CPU_HAS_FPU
+	fpregset_t fpregs;
+	unsigned long flg;
+	unsigned long tmp1, tmp2, tmp3, tmp4;
+	unsigned long fctl0, fctl1, fctl2;
+	int * fpgr;
+
+	if (__copy_from_user(&fpregs, &sc->sc_fcr, sizeof(fpregs)))
+	{
+		err = 1;
+		goto out;
+	}
+
+	local_irq_save(flg);
+	fctl0 = fpregs.f_fcr;
+	fctl1 = fpregs.f_fsr;
+	fctl2 = fpregs.f_fesr;
+	fpgr = &(fpregs.f_fpregs[0]);
+	__asm__ __volatile__(
+			"mtcr   %0, cr<1, 2> \n\r"
+			"mtcr   %1, cr<2, 2> \n\r"
+			::"r"(fctl0), "r"(fctl2));
+
+	__asm__ __volatile__(LDW_FPU_REGS(0, 4, 8, 12)
+			FMTVR_FPU_REGS(vr0, vr1)
+			LDW_FPU_REGS(16, 20, 24, 28)
+			FMTVR_FPU_REGS(vr2, vr3)
+			LDW_FPU_REGS(32, 36, 40, 44)
+			FMTVR_FPU_REGS(vr4, vr5)
+			LDW_FPU_REGS(48, 52, 56, 60)
+			FMTVR_FPU_REGS(vr6, vr7)
+			"addi   %4, 32 \n\r"
+			"addi   %4, 32 \n\r"
+			LDW_FPU_REGS(0, 4, 8, 12)
+			FMTVR_FPU_REGS(vr8, vr9)
+			LDW_FPU_REGS(16, 20, 24, 28)
+			FMTVR_FPU_REGS(vr10, vr11)
+			LDW_FPU_REGS(32, 36, 40, 44)
+			FMTVR_FPU_REGS(vr12, vr13)
+			LDW_FPU_REGS(48, 52, 56, 60)
+			FMTVR_FPU_REGS(vr14, vr15)
+			:"=a"(tmp1), "=a"(tmp2), "=a"(tmp3), "=a"(tmp4),
+			"+a"(fpgr));
+	local_irq_restore(flg);
+out:
+#endif
+	return err;
+}
+
+static inline int
+restore_sigframe(struct pt_regs *regs, struct sigcontext *usc, int *pr2)
+{
+	int err = 0;
+	int i = 0;
+	unsigned long usp;
+
+	/* Always make any pending restarted system calls return -EINTR */
+	current_thread_info()->task->restart_block.fn = do_no_restart_syscall;
+
+	/* restore passed registers */
+	err |= __get_user(regs->a0, &usc->sc_a0);
+	err |= __get_user(regs->a1, &usc->sc_a1);
+	err |= __get_user(regs->a2, &usc->sc_a2);
+	err |= __get_user(regs->a3, &usc->sc_a3);
+	for(i = 0; i < 10; i++)
+		err |= __get_user(regs->regs[i], &usc->sc_regs[i]);
+
+	err |= __get_user(regs->r15, &usc->sc_r15);
+#if defined(__CSKYABIV2__)
+	for(i = 0; i < 16; i++)
+	{
+		err |= __get_user(regs->exregs[i], &usc->sc_exregs[i]);
+	}
+	err |= __get_user(regs->rhi, &usc->sc_rhi);
+	err |= __get_user(regs->rlo, &usc->sc_rlo);
+#endif
+	err |= __get_user(regs->sr, &usc->sc_sr);
+	err |= __get_user(regs->pc, &usc->sc_pc);
+	err |= __get_user(usp, &usc->sc_usp);
+	wrusp(usp);
+	err |= restore_fpu_state(usc);
+	*pr2 = regs->a0;
+	return err;
+}
+
+asmlinkage int
+do_rt_sigreturn(void)
+{
+	unsigned long usp = rdusp();
+	struct rt_sigframe *frame = (struct rt_sigframe *)usp;
+	sigset_t set;
+	int a0;
+	struct pt_regs *regs = current_pt_regs();
+
+	if (verify_area(VERIFY_READ, frame, sizeof(*frame)))
+		goto badframe;
+	if (__copy_from_user(&set, &frame->uc.uc_sigmask, sizeof(set)))
+		goto badframe;
+
+	sigdelsetmask(&set, ~_BLOCKABLE);
+	spin_lock_irq(&current->sighand->siglock);
+	current->blocked = set;
+	recalc_sigpending( );
+	spin_unlock_irq(&current->sighand->siglock);
+
+	if (restore_sigframe(regs, &frame->uc.uc_mcontext, &a0))
+		goto badframe;
+
+	return a0;
+
+badframe:
+	force_sig(SIGSEGV, current);
+	return 0;
+}
+
+/*
+ * Set up a signal frame.
+ */
+
+static inline int save_fpu_state(struct sigcontext *sc, struct pt_regs *regs)
+{
+	int err = 0;
+#ifdef CONFIG_CPU_HAS_FPU
+	fpregset_t fpregs;
+	unsigned long flg;
+	unsigned long tmp1, tmp2, tmp3, tmp4;
+	int * fpgr;
+
+	local_irq_save(flg);
+	fpgr = &(fpregs.f_fpregs[0]);
+	__asm__ __volatile__("mfcr    %0, cr<1, 2> \n\r"
+			"mfcr    %1, cr<2, 2> \n\r"
+			: "=r"(fpregs.f_fcr), "=r"(fpregs.f_fesr));
+
+	__asm__ __volatile__(FMFVR_FPU_REGS(vr0, vr1)
+			STW_FPU_REGS(0, 4, 8, 12)
+			FMFVR_FPU_REGS(vr2, vr3)
+			STW_FPU_REGS(16, 20, 24, 28)
+			FMFVR_FPU_REGS(vr4, vr5)
+			STW_FPU_REGS(32, 36, 40, 44)
+			FMFVR_FPU_REGS(vr6, vr7)
+			STW_FPU_REGS(48, 52, 56, 60)
+			"addi    %4, 32 \n\r"
+			"addi    %4, 32 \n\r"
+			FMFVR_FPU_REGS(vr8, vr9)
+			STW_FPU_REGS(0, 4, 8, 12)
+			FMFVR_FPU_REGS(vr10, vr11)
+			STW_FPU_REGS(16, 20, 24, 28)
+			FMFVR_FPU_REGS(vr12, vr13)
+			STW_FPU_REGS(32, 36, 40, 44)
+			FMFVR_FPU_REGS(vr14, vr15)
+			STW_FPU_REGS(48, 52, 56, 60)
+			:"=a"(tmp1), "=a"(tmp2), "=a"(tmp3), "=a"(tmp4),
+			"+a"(fpgr));
+	local_irq_restore(flg);
+
+	err |= copy_to_user(&sc->sc_fcr, &fpregs, sizeof(fpregs));
+#endif
+	return err;
+}
+
+static inline int setup_sigframe(struct sigcontext *sc, struct pt_regs *regs,
+		unsigned long mask)
+{
+	int err = 0;
+	int i = 0;
+
+	err |= __put_user(mask, &sc->sc_mask);
+	err |= __put_user(rdusp(), &sc->sc_usp);
+	err |= __put_user(regs->a0, &sc->sc_a0);
+	err |= __put_user(regs->a1, &sc->sc_a1);
+	err |= __put_user(regs->a2, &sc->sc_a2);
+	err |= __put_user(regs->a3, &sc->sc_a3);
+	for(i = 0; i < 10; i++)
+	{
+		err |= __put_user(regs->regs[i], &sc->sc_regs[i]);
+	}
+	err |= __put_user(regs->r15, &sc->sc_r15);
+#if defined(__CSKYABIV2__)
+	for(i = 0; i < 16; i++)
+	{
+		err |= __put_user(regs->exregs[i], &sc->sc_exregs[i]);
+	}
+	err |= __put_user(regs->rhi, &sc->sc_rhi);
+	err |= __put_user(regs->rlo, &sc->sc_rlo);
+#endif
+	err |= __put_user(regs->sr, &sc->sc_sr);
+	err |= __put_user(regs->pc, &sc->sc_pc);
+	err |= save_fpu_state(sc, regs);
+
+	return err;
+}
+
+static inline void *
+get_sigframe(struct k_sigaction *ka, struct pt_regs *regs, size_t frame_size)
+{
+	unsigned long usp;
+
+	/* Default to using normal stack.  */
+	usp = rdusp();
+
+	/* This is the X/Open sanctioned signal stack switching.  */
+	if ((ka->sa.sa_flags & SA_ONSTACK) && !sas_ss_flags(usp)) {
+		if (!on_sig_stack(usp))
+			usp = current->sas_ss_sp + current->sas_ss_size;
+	}
+	return (void *)((usp - frame_size) & -8UL);
+}
+
+static int setup_rt_frame (int sig, struct k_sigaction *ka, siginfo_t *info,
+		sigset_t *set, struct pt_regs *regs)
+{
+	struct rt_sigframe *frame;
+	int err = 0;
+
+	struct csky_vdso *vdso = current->mm->context.vdso;
+
+	frame = get_sigframe(ka, regs, sizeof(*frame));
+	if (!frame)
+		return 1;
+
+	err |= __put_user(sig, &frame->sig);
+	err |= __put_user(&frame->info, &frame->pinfo);
+	err |= __put_user(&frame->uc, &frame->puc);
+	err |= copy_siginfo_to_user(&frame->info, info);
+
+	/* Create the ucontext.  */
+	err |= __put_user(0, &frame->uc.uc_flags);
+	err |= __put_user(0, &frame->uc.uc_link);
+	err |= __put_user((void *)current->sas_ss_sp,
+			&frame->uc.uc_stack.ss_sp);
+	err |= __put_user(sas_ss_flags(rdusp()),
+			&frame->uc.uc_stack.ss_flags);
+	err |= __put_user(current->sas_ss_size, &frame->uc.uc_stack.ss_size);
+	err |= setup_sigframe(&frame->uc.uc_mcontext, regs, 0);
+	err |= copy_to_user (&frame->uc.uc_sigmask, set, sizeof(*set));
+
+	if (err)
+		goto give_sigsegv;
+
+	/* Set up registers for signal handler */
+	wrusp ((unsigned long) frame);
+	regs->pc = (unsigned long) ka->sa.sa_handler;
+	regs->r15 = (unsigned long)vdso->rt_signal_retcode;
+
+adjust_stack:
+	regs->a0 = sig; /* first arg is signo */
+	regs->a1 = (unsigned long)(&(frame->info)); /* second arg is (siginfo_t*) */
+	regs->a2 = (unsigned long)(&(frame->uc));/* third arg pointer to ucontext */
+	return err;
+
+give_sigsegv:
+	if (sig == SIGSEGV)
+		ka->sa.sa_handler = SIG_DFL;
+	force_sig(SIGSEGV, current);
+	goto adjust_stack;
+}
+
+/*
+ * OK, we're invoking a handler
+ */
+static int
+handle_signal(int sig, struct k_sigaction *ka, siginfo_t *info,
+		sigset_t *oldset, struct pt_regs *regs)
+{
+	struct task_struct *tsk = current;
+	int ret;
+
+	/* set up the stack frame, regardless of SA_SIGINFO, and pass info anyway. */
+	ret = setup_rt_frame(sig, ka, info, oldset, regs);
+
+	if (ret != 0) {
+		force_sigsegv(sig, tsk);
+		return ret;
+	}
+
+	/* Block the signal if we were successful. */
+	spin_lock_irq(&current->sighand->siglock);
+	sigorsets(&current->blocked, &current->blocked, &ka->sa.sa_mask);
+	if (!(ka->sa.sa_flags & SA_NODEFER))
+		sigaddset(&current->blocked, sig);
+	recalc_sigpending();
+	spin_unlock_irq(&current->sighand->siglock);
+
+	return 0;
+}
+
+/*
+ * Note that 'init' is a special process: it doesn't get signals it doesn't
+ * want to handle. Thus you cannot kill init even with a SIGKILL even by
+ * mistake.
+ *
+ * Note that we go through the signals twice: once to check the signals
+ * that the kernel can handle, and then we build all the user-level signal
+ * handling stack-frames in one go after that.
+ */
+static void do_signal(struct pt_regs *regs, int syscall)
+{
+	unsigned int retval = 0, continue_addr = 0, restart_addr = 0;
+	struct ksignal ksig;
+
+	/*
+	 * We want the common case to go fast, which
+	 * is why we may in certain cases get here from
+	 * kernel mode. Just return without doing anything
+	 * if so.
+	 */
+	if (!user_mode(regs))
+		return;
+
+	current->thread.esp0 = (unsigned long)regs;
+
+	/*
+	 * If we were from a system call, check for system call restarting...
+	 */
+	if (syscall) {
+		continue_addr = regs->pc;
+#if defined(__CSKYABIV1__)
+		restart_addr = continue_addr - 2;
+#else
+		restart_addr = continue_addr - 4;
+#endif
+		retval = regs->a0;
+
+		/*
+		 * Prepare for system call restart.  We do this here so that a
+		 * debugger will see the already changed.
+		 */
+		switch (retval) {
+		case -ERESTARTNOHAND:
+		case -ERESTARTSYS:
+		case -ERESTARTNOINTR:
+			regs->a0 = regs->orig_a0;
+			regs->pc = restart_addr;
+			break;
+		case -ERESTART_RESTARTBLOCK:
+			regs->a0 = -EINTR;
+			break;
+		}
+	}
+
+	if (try_to_freeze())
+		goto no_signal;
+
+	/*
+	 * Get the signal to deliver.  When running under ptrace, at this
+	 * point the debugger may change all our registers ...
+	 */
+	if (get_signal(&ksig)) {
+		sigset_t *oldset;
+
+		/*
+		 * Depending on the signal settings we may need to revert the
+		 * decision to restart the system call.  But skip this if a
+		 * debugger has chosen to restart at a different PC.
+		 */
+		if (regs->pc == restart_addr) {
+			if (retval == -ERESTARTNOHAND
+					|| (retval == -ERESTARTSYS
+						&& !(ksig.ka.sa.sa_flags & SA_RESTART))) {
+				regs->a0 = -EINTR;
+				regs->pc = continue_addr;
+			}
+		}
+
+		if (test_thread_flag(TIF_RESTORE_SIGMASK))
+			oldset = &current->saved_sigmask;
+		else
+			oldset = &current->blocked;
+		/* Whee!  Actually deliver the signal.  */
+		if (handle_signal(ksig.sig, &ksig.ka, &ksig.info, oldset, regs) == 0) {
+			/*
+			 * A signal was successfully delivered; the saved
+			 * sigmask will have been stored in the signal frame,
+			 * and will be restored by sigreturn, so we can simply
+			 * clear the TIF_RESTORE_SIGMASK flag.
+			 */
+			if (test_thread_flag(TIF_RESTORE_SIGMASK))
+				clear_thread_flag(TIF_RESTORE_SIGMASK);
+		}
+		return;
+	}
+
+no_signal:
+	if (syscall) {
+		/*
+		 * Handle restarting a different system call.  As above,
+		 * if a debugger has chosen to restart at a different PC,
+		 * ignore the restart.
+		 */
+		if (retval == -ERESTART_RESTARTBLOCK
+				&& regs->pc == continue_addr) {
+#if defined(__CSKYABIV1__)
+			regs->regs[9] = __NR_restart_syscall;
+			regs->pc -= 2;
+#else
+			regs->regs[3] = __NR_restart_syscall;
+			regs->pc -= 4;
+#endif
+		}
+
+		/* If there's no signal to deliver, we just put the saved sigmask
+		 * back.
+		 */
+		if (test_thread_flag(TIF_RESTORE_SIGMASK)) {
+			clear_thread_flag(TIF_RESTORE_SIGMASK);
+			sigprocmask(SIG_SETMASK, &current->saved_sigmask, NULL);
+		}
+	}
+}
+
+asmlinkage void
+do_notify_resume(unsigned int thread_flags, struct pt_regs *regs, int syscall)
+{
+	if (thread_flags & _TIF_SIGPENDING)
+		do_signal(regs, syscall);
+
+	if (thread_flags & _TIF_NOTIFY_RESUME) {
+		clear_thread_flag(TIF_NOTIFY_RESUME);
+		tracehook_notify_resume(regs);
+	}
+}
diff --git a/arch/csky/kernel/syscall.c b/arch/csky/kernel/syscall.c
new file mode 100644
index 0000000..27a1a8d
--- /dev/null
+++ b/arch/csky/kernel/syscall.c
@@ -0,0 +1,63 @@
+#include <linux/syscalls.h>
+
+SYSCALL_DEFINE1(set_thread_area, unsigned long, addr)
+{
+	struct thread_info *ti = task_thread_info(current);
+
+#if defined(__CSKYABIV2__)
+	struct pt_regs *reg = current_pt_regs();
+	reg->exregs[15] = (long)addr;
+#endif
+	ti->tp_value = addr;
+
+	return 0;
+}
+
+SYSCALL_DEFINE6(mmap2,
+	unsigned long, addr,
+	unsigned long, len,
+	unsigned long, prot,
+	unsigned long, flags,
+	unsigned long, fd,
+	off_t, offset)
+{
+	if (unlikely(offset & (~PAGE_MASK >> 12)))
+		return -EINVAL;
+	return sys_mmap_pgoff(addr, len, prot, flags, fd,
+		offset >> (PAGE_SHIFT - 12));
+}
+
+struct mmap_arg_struct {
+	unsigned long addr;
+	unsigned long len;
+	unsigned long prot;
+	unsigned long flags;
+	unsigned long fd;
+	unsigned long offset;
+};
+
+SYSCALL_DEFINE1(mmap,
+	struct mmap_arg_struct *, arg)
+{
+	struct mmap_arg_struct a;
+
+	if (copy_from_user(&a, arg, sizeof(a)))
+		return -EINVAL;
+
+	if (unlikely(a.offset & ~PAGE_MASK))
+		return -EINVAL;
+
+	return sys_mmap_pgoff(a.addr, a.len, a.prot, a.flags, a.fd, a.offset >> PAGE_SHIFT);
+}
+
+/*
+ * for abiv1 the 64bits args should be even th, So we need mov the advice forward.
+ */
+SYSCALL_DEFINE4(csky_fadvise64_64,
+	int, fd,
+	int, advice,
+	loff_t, offset,
+	loff_t, len)
+{
+	return sys_fadvise64_64(fd, offset, len, advice);
+}
diff --git a/arch/csky/kernel/syscall_table.c b/arch/csky/kernel/syscall_table.c
new file mode 100644
index 0000000..f71b09f
--- /dev/null
+++ b/arch/csky/kernel/syscall_table.c
@@ -0,0 +1,10 @@
+#include <linux/syscalls.h>
+#include <asm/syscalls.h>
+
+#undef __SYSCALL
+#define __SYSCALL(nr, call) [nr] = (call),
+
+void * const sys_call_table[__NR_syscalls] __page_aligned_data = {
+	[0 ... __NR_syscalls - 1] = sys_ni_syscall,
+#include <asm/unistd.h>
+};
diff --git a/arch/csky/kernel/time.c b/arch/csky/kernel/time.c
new file mode 100644
index 0000000..8334a75
--- /dev/null
+++ b/arch/csky/kernel/time.c
@@ -0,0 +1,9 @@
+#include <linux/clk-provider.h>
+#include <linux/clocksource.h>
+
+void __init time_init(void)
+{
+	of_clk_init(NULL);
+	clocksource_probe();
+}
+
diff --git a/arch/csky/kernel/timer-nationalchip.c b/arch/csky/kernel/timer-nationalchip.c
new file mode 100644
index 0000000..2641c19
--- /dev/null
+++ b/arch/csky/kernel/timer-nationalchip.c
@@ -0,0 +1,147 @@
+#include <linux/kernel.h>
+#include <linux/sched.h>
+#include <linux/param.h>
+#include <linux/init.h>
+#include <linux/interrupt.h>
+#include <linux/profile.h>
+#include <linux/irq.h>
+#include <linux/rtc.h>
+#include <linux/sizes.h>
+#include <linux/clocksource.h>
+#include <linux/clockchips.h>
+#include <asm/irq.h>
+#include <asm/io.h>
+#include <asm/delay.h>
+#include <linux/of.h>
+#include <linux/of_address.h>
+#include <linux/of_irq.h>
+#include <linux/sched_clock.h>
+
+#define NC_VA_COUNTER_1_STATUS		(void *)(timer_reg + 0x00)
+#define NC_VA_COUNTER_1_VALUE		(void *)(timer_reg + 0x04)
+#define NC_VA_COUNTER_1_CONTROL		(void *)(timer_reg + 0x10)
+#define NC_VA_COUNTER_1_CONFIG		(void *)(timer_reg + 0x20)
+#define NC_VA_COUNTER_1_PRE		(void *)(timer_reg + 0x24)
+#define NC_VA_COUNTER_1_INI		(void *)(timer_reg + 0x28)
+#define NC_VA_COUNTER_2_STATUS		(void *)(timer_reg + 0x40)
+#define NC_VA_COUNTER_2_VALUE		(void *)(timer_reg + 0x44)
+#define NC_VA_COUNTER_2_CONTROL		(void *)(timer_reg + 0x50)
+#define NC_VA_COUNTER_2_CONFIG		(void *)(timer_reg + 0x60)
+#define NC_VA_COUNTER_2_PRE		(void *)(timer_reg + 0x64)
+#define NC_VA_COUNTER_2_INI		(void *)(timer_reg + 0x68)
+#define NC_VA_COUNTER_3_STATUS		(void *)(timer_reg + 0x80)
+#define NC_VA_COUNTER_3_VALUE		(void *)(timer_reg + 0x84)
+#define NC_VA_COUNTER_3_CONTROL		(void *)(timer_reg + 0x90)
+#define NC_VA_COUNTER_3_CONFIG		(void *)(timer_reg + 0xa0)
+#define NC_VA_COUNTER_3_PRE		(void *)(timer_reg + 0xa4)
+#define NC_VA_COUNTER_3_INI		(void *)(timer_reg + 0xa8)
+
+static unsigned int timer_reg;
+
+static inline void timer_reset(void)
+{
+	__raw_writel(0x1,	NC_VA_COUNTER_1_CONTROL);
+	__raw_writel(0x0,	NC_VA_COUNTER_1_CONTROL);
+	__raw_writel(0x3,	NC_VA_COUNTER_1_CONFIG);
+	__raw_writel(26,	NC_VA_COUNTER_1_PRE);
+}
+
+static irqreturn_t timer_interrupt(int irq, void *dev_id)
+{
+	struct clock_event_device *dev = (struct clock_event_device *) dev_id;
+
+	__raw_writel(1, NC_VA_COUNTER_1_STATUS);
+
+	dev->event_handler(dev);
+
+	return IRQ_HANDLED;
+}
+
+static int nc_timer_set_periodic(struct clock_event_device *dev)
+{
+	timer_reset();
+
+	__raw_writel(0xFFFFD8EF, NC_VA_COUNTER_1_INI);
+	__raw_writel(0x2, NC_VA_COUNTER_1_CONTROL);
+
+	return 0;
+}
+
+static int nc_timer_set_next_event(unsigned long delta, struct clock_event_device *evt)
+{
+	__raw_writel(0x1,		NC_VA_COUNTER_1_CONTROL);
+	__raw_writel(ULONG_MAX - delta, NC_VA_COUNTER_1_INI);
+	__raw_writel(0x2,		NC_VA_COUNTER_1_CONTROL);
+	return 0;
+}
+
+static int nc_timer_shutdown(struct clock_event_device *dev)
+{
+	__raw_writel(0x0, NC_VA_COUNTER_1_CONTROL);
+	__raw_writel(0x0, NC_VA_COUNTER_1_CONFIG);
+
+	return 0;
+}
+
+static struct clock_event_device nc_ced = {
+	.name			= "nationalchip-clkevent",
+	.features		= CLOCK_EVT_FEAT_PERIODIC
+				| CLOCK_EVT_FEAT_ONESHOT,
+	.rating			= 200,
+	.set_state_shutdown	= nc_timer_shutdown,
+	.set_state_periodic	= nc_timer_set_periodic,
+	.set_next_event		= nc_timer_set_next_event,
+};
+
+static u64 notrace nc_sched_clock_read(void)
+{
+	return (u64) __raw_readl(NC_VA_COUNTER_2_VALUE);
+}
+
+static void nc_csd_enable(void)
+{
+	__raw_writel(0x1, NC_VA_COUNTER_2_CONTROL);
+	__raw_writel(0x0, NC_VA_COUNTER_2_CONTROL);
+	__raw_writel(0x1, NC_VA_COUNTER_2_CONFIG);
+
+	__raw_writel(26,NC_VA_COUNTER_2_PRE);
+	__raw_writel(0, NC_VA_COUNTER_2_INI);
+	__raw_writel(0x2, NC_VA_COUNTER_2_CONTROL);
+}
+
+static int __init nc_timer_init(struct device_node *np)
+{
+	unsigned int irq;
+	unsigned int freq;
+
+	/* parse from devicetree */
+	timer_reg = (unsigned int) of_iomap(np, 0);
+	if (!timer_reg)
+		panic("%s, of_iomap err.\n", __func__);
+
+	irq = irq_of_parse_and_map(np, 0);
+	if (!irq)
+		panic("%s, irq_parse err.\n", __func__);
+
+	if (of_property_read_u32(np, "clock-frequency", &freq))
+		panic("%s, clock-frequency error.\n", __func__);
+
+	pr_info("Nationalchip Timer Init, reg: %x, irq: %d, freq: %d.\n",
+		timer_reg, irq, freq);
+
+	/* setup irq */
+	if (request_irq(irq, timer_interrupt, IRQF_TIMER, np->name, &nc_ced))
+		panic("%s timer_interrupt error.\n", __func__);
+
+	/* register */
+	clockevents_config_and_register(&nc_ced, freq, 1, ULONG_MAX);
+
+	nc_csd_enable();
+	clocksource_mmio_init(NC_VA_COUNTER_2_VALUE, "nationalchip-clksource", freq, 200, 32, clocksource_mmio_readl_up);
+
+	sched_clock_register(nc_sched_clock_read, 32, freq);
+
+	return 0;
+}
+CLOCKSOURCE_OF_DECLARE(nc_timer, "nationalchip,timer-v1", nc_timer_init);
+
diff --git a/arch/csky/kernel/traps.c b/arch/csky/kernel/traps.c
new file mode 100644
index 0000000..4ba1760
--- /dev/null
+++ b/arch/csky/kernel/traps.c
@@ -0,0 +1,540 @@
+#include <linux/sched.h>
+#include <linux/signal.h>
+#include <linux/kernel.h>
+#include <linux/mm.h>
+#include <linux/module.h>
+#include <linux/user.h>
+#include <linux/string.h>
+#include <linux/linkage.h>
+#include <linux/init.h>
+#include <linux/ptrace.h>
+#include <linux/kallsyms.h>
+#include <linux/rtc.h>
+
+#include <asm/setup.h>
+#include <asm/fpu.h>
+#include <asm/uaccess.h>
+#include <asm/traps.h>
+#include <asm/pgalloc.h>
+#include <asm/siginfo.h>
+#include <asm/misc_csky.h>
+
+#include <asm/mmu_context.h>
+
+extern void csky_tlb_init(void);
+void show_registers(struct pt_regs *fp);
+/* assembler routines */
+asmlinkage void buserr(void);
+asmlinkage void alignment(void);
+asmlinkage void trap(void);
+asmlinkage void trap1(void);
+asmlinkage void trap2(void);
+asmlinkage void trap3(void);
+asmlinkage void system_call(void);
+asmlinkage void inthandler(void);
+asmlinkage void autohandler(void);
+asmlinkage void fastautohandler(void);
+
+asmlinkage void handle_tlbinvalidl(void);
+asmlinkage void handle_tlbinvalids(void);
+asmlinkage void handle_tlbmodified(void);
+asmlinkage void handle_tlbmiss(void);
+asmlinkage void handle_fpe(void);
+asmlinkage void handle_illegal(void);
+
+void __init per_cpu_trap_init(void)
+{
+	unsigned int cpu = smp_processor_id();
+
+	csky_tlb_init();
+	cpu_data[cpu].asid_cache = ASID_FIRST_VERSION;
+	current_cpu_data.asid_cache = ASID_FIRST_VERSION;
+
+	TLBMISS_HANDLER_SETUP_PGD(swapper_pg_dir);
+
+	atomic_inc(&init_mm.mm_count);
+	current->active_mm = &init_mm;
+	BUG_ON(current->mm);
+}
+
+extern e_vector vec_base;
+
+void __init trap_init (void)
+{
+	int i;
+	e_vector *_ramvec = &vec_base;
+
+	__asm__ __volatile__(
+		"mtcr %0, vbr\n"
+		::"r"(_ramvec));
+
+	per_cpu_trap_init();
+
+	  /*
+	 *      There is a common trap handler and common interrupt
+	 *      handler that handle almost every vector. We treat
+	 *      the system call and bus error special, they get their
+	 *      own first level handlers.
+	 */
+	for(i = 1; (i <= 31); i++)
+	{
+		_ramvec[i] = trap;
+	}
+	for(; (i < 128); i++)
+	{
+		_ramvec[i] = inthandler;
+	}
+
+	_ramvec[VEC_ACCESS] = buserr;
+	_ramvec[VEC_ALIGN] = alignment;
+	_ramvec[VEC_TRAP0] = system_call;
+	_ramvec[VEC_TRAP2] = trap2;
+	_ramvec[VEC_TRAP3] = trap3;
+	_ramvec[VEC_AUTOVEC] = autohandler;
+
+	_ramvec[VEC_TLBINVALIDL] = handle_tlbinvalidl;
+	_ramvec[VEC_TLBINVALIDS] = handle_tlbinvalids;
+	_ramvec[VEC_TLBMODIFIED] = handle_tlbmodified;
+	_ramvec[VEC_TLBMISS] = (void *)((unsigned int)handle_tlbmiss | 0x1);
+	_ramvec[VEC_ILLEGAL] = handle_illegal;
+	_ramvec[VEC_FPE] = handle_fpe;
+}
+
+void die_if_kernel(char *,struct pt_regs *,int);
+asmlinkage int do_page_fault(struct pt_regs *regs, unsigned long address,
+                             unsigned long error_code);
+
+asmlinkage void trap_c(int vector, struct frame *fp);
+asmlinkage void handle_fpe_c(unsigned long fesr, struct pt_regs * regs);
+asmlinkage void handle_illegal_c(struct pt_regs * regs);
+
+asmlinkage void buserr_c(struct frame *fp)
+{
+	printk("%s(%d): Bus Error Trap\n", __FILE__, __LINE__);
+	show_registers((struct pt_regs *) fp);
+	/* Only set esp0 if coming from user mode */
+	if (user_mode(&fp->ptregs)){
+		current->thread.esp0 = (unsigned long) fp;
+    } else{
+		die_if_kernel("Kernel mode BUS error", (struct pt_regs *)fp, 0);
+    }
+	force_sig(SIGSEGV, current);
+}
+
+int kstack_depth_to_print = 48;
+
+/* MODULE_RANGE is a guess of how much space is likely to be
+   vmalloced.  */
+#define MODULE_RANGE (8*1024*1024)
+
+void show_trace(unsigned long *stack)
+{
+        unsigned long *endstack;
+        unsigned long addr;
+        int i;
+
+        printk("Call Trace:");
+        addr = (unsigned long)stack + THREAD_SIZE - 1;
+        endstack = (unsigned long *)(addr & -THREAD_SIZE);
+        i = 0;
+        while (stack + 1 <= endstack) {
+                addr = *stack++;
+                /*
+                 * If the address is either in the text segment of the
+                 * kernel, or in the region which contains vmalloc'ed
+                 * memory, it *may* be the address of a calling
+                 * routine; if so, print it so that someone tracing
+                 * down the cause of the crash will be able to figure
+                 * out the call path that was taken.
+                 */
+                if (__kernel_text_address(addr)) {
+#ifndef CONFIG_KALLSYMS
+                        if (i % 5 == 0)
+                                printk("\n       ");
+#endif
+                        printk(" [<%08lx>] %pS\n", addr, (void *)addr);
+                        i++;
+                }
+        }
+        printk("\n");
+}
+
+void show_stack(struct task_struct *task, unsigned long *stack)
+{
+	  unsigned long *p;
+        unsigned long *endstack;
+        int i;
+
+        if (!stack) {
+                if (task)
+                        stack = (unsigned long *)task->thread.esp0;
+                else
+                        stack = (unsigned long *)&stack;
+        }
+        endstack = (unsigned long *)(((unsigned long)stack + THREAD_SIZE - 1) & -THREAD_SIZE);
+
+        printk("Stack from %08lx:", (unsigned long)stack);
+        p = stack;
+        for (i = 0; i < kstack_depth_to_print; i++) {
+                if (p + 1 > endstack)
+                        break;
+                if (i % 8 == 0)
+                        printk("\n       ");
+                printk(" %08lx", *p++);
+        }
+        printk("\n");
+        show_trace(stack);
+}
+
+/*
+ * The architecture-independent backtrace generator
+ */
+void dump_stack(void)
+{
+	unsigned long stack;
+
+	show_trace(&stack);
+}
+EXPORT_SYMBOL(dump_stack);
+
+void bad_super_trap (int vector, struct frame *fp)
+{
+	console_verbose();
+
+	printk("Kernel: Bad trap from supervisor state, vector = %d\n", vector);
+	printk("Current process id is %d\n", current->pid);
+	show_registers((struct pt_regs *)fp);
+	panic("Trap from supervisor state\n");
+}
+
+/* use as fpc control reg read/write in glibc. */
+int hand_fpcr_rdwr(struct pt_regs * regs)
+{
+	mm_segment_t fs;
+	unsigned long instrptr, regx = 0;
+	unsigned int fault;
+#if defined(__CSKYABIV1__)
+	unsigned long index_regx = 0, index_fpregx = 0;
+	u16 tinstr = 0;
+
+	instrptr = instruction_pointer(regs);
+
+	fs = get_fs();
+	set_fs(KERNEL_DS);
+	fault = __get_user(tinstr, (u16 *)(instrptr & ~1));
+	set_fs(fs);
+	if (fault) {
+		goto bad_or_fault;
+	}
+
+	index_regx = tinstr & 0x7;
+	index_fpregx = ((tinstr >> 3) & 0x17);
+	tinstr = tinstr >> 8;
+	if(tinstr == 0x6f)
+	{
+		regx = read_pt_regs(index_regx, regs);
+		if(index_fpregx == 1) {
+			write_fpcr(regx);
+		}
+		else if(index_fpregx == 4) {
+			write_fpesr(regx);
+		} else
+			goto bad_or_fault;
+
+		regs->pc +=2;
+		return 1;
+	}
+	else if(tinstr == 0x6b)
+	{
+		if(index_fpregx == 1) {
+			regx = read_fpcr();
+		}
+		else if(index_fpregx == 2) { /* need test fpu is busy */
+			regx = read_fpsr();
+		}
+		else if(index_fpregx == 4) {
+			regx = read_fpesr();
+		} else
+			goto bad_or_fault;
+
+		write_pt_regs(regx, index_regx, regs);
+		regs->pc +=2;
+		return 1;
+	}
+#else
+	u16 instr_hi, instr_low;
+	unsigned long index_regx = 0, index_fpregx_prev = 0, index_fpregx_next = 0;
+	unsigned long tinstr = 0;
+
+	instrptr = instruction_pointer(regs);
+
+	/* CSKYV2's 32 bit instruction may not align 4 words */
+	fs = get_fs();
+	set_fs(KERNEL_DS);
+	fault = __get_user(instr_low, (u16 *)(instrptr & ~1));
+	set_fs(fs);
+	if (fault) {
+		goto bad_or_fault;
+	}
+
+	fs = get_fs();
+	set_fs(KERNEL_DS);
+	fault = __get_user(instr_hi, (u16 *)((instrptr + 2) & ~1));
+	set_fs(fs);
+	if (fault) {
+		goto bad_or_fault;
+	}
+
+	tinstr = instr_hi | ((unsigned long)instr_low << 16);
+
+	index_fpregx_next = ((tinstr >> 21) & 0x1F);
+
+	/* just want to handle instruction which opration cr<1, 2> or cr<2, 2> */
+	if(index_fpregx_next != 2){
+		goto bad_or_fault;
+	}
+
+/*
+ * define four macro to distinguish the instruction is mfcr or mtcr.
+ */
+#define MTCR_MASK 0xFC00FFE0
+#define MFCR_MASK 0xFC00FFE0
+#define MTCR_DISTI 0xC0006420
+#define MFCR_DISTI 0xC0006020
+
+	if ((tinstr & MTCR_MASK) == MTCR_DISTI)
+	{
+		index_regx = (tinstr >> 16) & 0x1F;
+		index_fpregx_prev = tinstr & 0x1F;
+
+		regx = read_pt_regs(index_regx, regs);
+
+		if(index_fpregx_prev == 1) {
+			write_fpcr(regx);
+		} else if (index_fpregx_prev == 2) {
+			write_fpesr(regx);
+		} else {
+			goto bad_or_fault;
+		}
+
+		regs->pc +=4;
+		return 1;
+	} else if ((tinstr & MFCR_MASK) == MFCR_DISTI) {
+		index_regx = tinstr & 0x1F;
+		index_fpregx_prev = ((tinstr >> 16) & 0x1F);
+
+		if (index_fpregx_prev == 1) {
+			regx = read_fpcr();
+		} else if (index_fpregx_prev == 2) {
+			regx = read_fpesr();
+		} else {
+			goto bad_or_fault;
+		}
+
+		write_pt_regs(regx, index_regx, regs);
+
+		regs->pc +=4;
+		return 1;
+	}
+#endif /* define __CSKYABIV1__ */
+bad_or_fault:
+	return 0;
+}
+
+asmlinkage void trap_c(int vector, struct frame *fp)
+{
+	int sig;
+	siginfo_t info;
+
+	/* send the appropriate signal to the user program */
+	switch (vector) {
+		case VEC_ZERODIV:
+			sig = SIGFPE;
+			break;
+
+		case VEC_PRIV:  /* some reg fcr of ck610 only R/W in super mode. */
+			sig = SIGILL;
+			if(hand_fpcr_rdwr((struct pt_regs *)fp))
+				return;
+			break;
+
+		case VEC_TRACE:  /* ptrace single step */
+			info.si_code = TRAP_TRACE;
+			sig = SIGTRAP;
+			break;
+
+		    /* fp->ptregs.sr &= ~PS_T */
+		case VEC_TRAP1:    /* gdb server breakpoint */
+		case VEC_BREAKPOINT: /* breakpoint */
+			info.si_code = TRAP_BRKPT;
+			sig = SIGTRAP;
+			break;
+
+		default:
+			sig = SIGILL;
+			break;
+	}
+	send_sig(sig, current, 0);
+}
+
+asmlinkage void handle_fpe_c(unsigned long fesr, struct pt_regs * regs)
+{
+	int sig;
+	siginfo_t info;
+
+	if(fesr & FPE_ILLE){
+		info.si_code = ILL_ILLOPC;
+		sig = SIGILL;
+	}
+	else if(fesr & FPE_IDC){
+		info.si_code = ILL_ILLOPN;
+		sig = SIGILL;
+	}
+	else if(fesr & FPE_FEC){
+		sig = SIGFPE;
+		if(fesr & FPE_IOC){
+			info.si_code = FPE_FLTINV;
+		}
+		else if(fesr & FPE_DZC){
+			info.si_code = FPE_FLTDIV;
+		}
+		else if(fesr & FPE_UFC){
+			info.si_code = FPE_FLTUND;
+		}
+		else if(fesr & FPE_OFC){
+			info.si_code = FPE_FLTOVF;
+		}
+		else if(fesr & FPE_IXC){
+			info.si_code = FPE_FLTRES;
+		}
+		else {
+		info.si_code = __SI_FAULT;
+		}
+	}
+	else {
+		info.si_code = __SI_FAULT;
+		sig = SIGFPE;
+	}
+	info.si_signo = SIGFPE;
+	info.si_errno = 0;
+	info.si_addr = (void *)regs->pc;
+	force_sig_info(sig, &info, current);
+}
+
+
+asmlinkage void handle_illegal_c(struct pt_regs * regs)
+{
+	int sig;
+	sig = SIGILL;
+	send_sig(sig, current, 0);
+}
+
+asmlinkage void set_esp0 (unsigned long ssp)
+{
+	current->thread.esp0 = ssp;
+}
+
+void show_trace_task(struct task_struct *tsk)
+{
+	/* DAVIDM: we can do better, need a proper stack dump */
+	printk("STACK ksp=0x%lx, usp=0x%lx\n", tsk->thread.ksp, tsk->thread.usp);
+}
+
+void die_if_kernel (char *str, struct pt_regs *fp, int nr)
+{
+	if (!(fp->sr & PS_S))
+		return;
+
+	console_verbose();
+	printk("%s: %08x\n",str,nr);
+        show_registers(fp);
+        add_taint(TAINT_DIE, LOCKDEP_NOW_UNRELIABLE);
+	do_exit(SIGSEGV);
+}
+
+/*
+ *      Generic dumping code. Used for panic and debug.
+ */
+void show_registers(struct pt_regs *fp)
+{
+	unsigned long   *sp;
+	unsigned char   *tp;
+	int             i;
+
+	printk("\nCURRENT PROCESS:\n\n");
+	printk("COMM=%s PID=%d\n", current->comm, current->pid);
+
+	if (current->mm) {
+		printk("TEXT=%08x-%08x DATA=%08x-%08x BSS=%08x-%08x\n",
+		        (int) current->mm->start_code,
+		        (int) current->mm->end_code,
+		        (int) current->mm->start_data,
+		        (int) current->mm->end_data,
+		        (int) current->mm->end_data,
+		        (int) current->mm->brk);
+		printk("USER-STACK=%08x  KERNEL-STACK=%08x\n\n",
+		        (int) current->mm->start_stack,
+		        (int) (((unsigned long) current) + 2 * PAGE_SIZE));
+	}
+
+	printk("PC: 0x%08lx\n", (long)fp->pc);
+	printk("orig_a0: 0x%08lx\n", fp->orig_a0);
+	printk("PSR: 0x%08lx\n", (long)fp->sr);
+	/*
+	 * syscallr1->orig_a0
+	 * please refer asm/ptrace.h
+	 */
+#if defined(__CSKYABIV2__)
+	printk("r0: 0x%08lx  r1: 0x%08lx  r2: 0x%08lx  r3: 0x%08lx\n",
+		fp->a0, fp->a1, fp->a2, fp->a3);
+	printk("r4: 0x%08lx  r5: 0x%08lx    r6: 0x%08lx    r7: 0x%08lx\n",
+		fp->regs[0], fp->regs[1], fp->regs[2], fp->regs[3]);
+	printk("r8: 0x%08lx  r9: 0x%08lx   r10: 0x%08lx   r11: 0x%08lx\n",
+		fp->regs[4], fp->regs[5], fp->regs[6], fp->regs[7]);
+	printk("r12 0x%08lx  r13: 0x%08lx   r15: 0x%08lx\n",
+		fp->regs[8], fp->regs[9], fp->r15);
+#else
+	printk("r2: 0x%08lx   r3: 0x%08lx   r4: 0x%08lx   r5: 0x%08lx\n",
+		fp->a0, fp->a1, fp->a2, fp->a3);
+	printk("r6: 0x%08lx   r7: 0x%08lx   r8: 0x%08lx   r9: 0x%08lx\n",
+		fp->regs[0], fp->regs[1], fp->regs[2], fp->regs[3]);
+	printk("r10: 0x%08lx   r11: 0x%08lx   r12: 0x%08lx   r13: 0x%08lx\n",
+		fp->regs[4], fp->regs[5], fp->regs[6], fp->regs[7]);
+	printk("r14 0x%08lx   r1: 0x%08lx   r15: 0x%08lx\n",
+		fp->regs[8], fp->regs[9], fp->r15);
+#endif
+#if defined(__CSKYABIV2__)
+	printk("r16:0x%08lx   r17: 0x%08lx   r18: 0x%08lx    r19: 0x%08lx\n",
+                fp->exregs[0], fp->exregs[1], fp->exregs[2], fp->exregs[3]);
+	printk("r20 0x%08lx   r21: 0x%08lx   r22: 0x%08lx    r23: 0x%08lx\n",
+		fp->exregs[4], fp->exregs[5], fp->exregs[6], fp->exregs[7]);
+	printk("r24 0x%08lx   r25: 0x%08lx   r26: 0x%08lx    r27: 0x%08lx\n",
+		fp->exregs[8], fp->exregs[9], fp->exregs[10], fp->exregs[11]);
+	printk("r28 0x%08lx   r29: 0x%08lx   r30: 0x%08lx    r31: 0x%08lx\n",
+		fp->exregs[12], fp->exregs[13], fp->exregs[14], fp->exregs[15]);
+	printk("hi 0x%08lx     lo: 0x%08lx \n",
+                fp->rhi, fp->rlo);
+#endif
+
+	printk("\nCODE:");
+	tp = ((unsigned char *) fp->pc) - 0x20;
+	tp += ((int)tp % 4) ? 2 : 0;
+	for (sp = (unsigned long *) tp, i = 0; (i < 0x40);  i += 4) {
+		if ((i % 0x10) == 0)
+		        printk("\n%08x: ", (int) (tp + i));
+		printk("%08x ", (int) *sp++);
+	}
+	printk("\n");
+
+	printk("\nKERNEL STACK:");
+	tp = ((unsigned char *) fp) - 0x40;
+	for (sp = (unsigned long *) tp, i = 0; (i < 0xc0); i += 4) {
+		if ((i % 0x10) == 0)
+		        printk("\n%08x: ", (int) (tp + i));
+		printk("%08x ", (int) *sp++);
+	}
+	printk("\n");
+
+	return;
+}
+
diff --git a/arch/csky/kernel/vdso.c b/arch/csky/kernel/vdso.c
new file mode 100644
index 0000000..3cad6a9
--- /dev/null
+++ b/arch/csky/kernel/vdso.c
@@ -0,0 +1,110 @@
+#include <linux/kernel.h>
+#include <linux/err.h>
+#include <linux/sched.h>
+#include <linux/mm.h>
+#include <linux/init.h>
+#include <linux/binfmts.h>
+#include <linux/elf.h>
+#include <linux/vmalloc.h>
+#include <linux/unistd.h>
+
+#include <asm/vdso.h>
+#include <asm/uaccess.h>
+#include <asm/cacheflush.h>
+
+static struct page *vdso_page;
+
+static int __init init_vdso(void)
+{
+	struct csky_vdso *vdso;
+	int err = 0;
+
+	vdso_page = alloc_page(GFP_KERNEL);
+	if (!vdso_page)
+		panic("Cannot allocate vdso");
+
+	vdso = vmap(&vdso_page, 1, 0, PAGE_KERNEL);
+	if (!vdso)
+		panic("Cannot map vdso");
+
+	clear_page(vdso);
+
+#if defined(__CSKYABIV1__)
+/*
+ * FIXME:
+ * __NR_rt_sigreturn must be 173
+ * Because gcc/config/csky/linux-unwind.h
+ * use hard code design,
+ * and didn't use our kernel headers.
+ */
+	err |= __put_user(0x6000 + (127 << 4)+1, (vdso->rt_signal_retcode + 0));
+	err |= __put_user(0x2000 + (31  << 4)+1, (vdso->rt_signal_retcode + 1));
+	err |= __put_user(0x2000 + ((173 - 127 - 33)  << 4)+1,
+					(vdso->rt_signal_retcode + 2));
+	err |= __put_user(0x08, (vdso->rt_signal_retcode + 3));
+#else
+	/*
+	 * FIXME: For CSKY V2 ISA, we mast write instruction in half word, because 
+	 *  the CPU load instruction by half word and ignore endian format. So the
+	 *  high half word in 32 bit instruction mast local in low address.
+	 *
+	 * movi r7, _NR_rt_sigreturn; trap #0 
+	 */
+	err |= __put_user(0xEA00 + 7, (vdso->rt_signal_retcode + 0));
+	err |= __put_user(__NR_rt_sigreturn, (vdso->rt_signal_retcode + 1));
+	err |= __put_user(0xC000, (vdso->rt_signal_retcode + 2));
+	err |= __put_user(0x2020, (vdso->rt_signal_retcode + 3));
+#endif
+
+	if (err) panic("Cannot set signal return code, err: %x.", err);
+
+	cache_op_range((unsigned long)vdso, ((unsigned long)vdso) + 16, DATA_CACHE|CACHE_CLR, 0);
+
+	vunmap(vdso);
+
+	return 0;
+}
+subsys_initcall(init_vdso);
+
+int arch_setup_additional_pages(struct linux_binprm *bprm, int uses_interp)
+{
+	int ret;
+	unsigned long addr;
+	struct mm_struct *mm = current->mm;
+
+	down_write(&mm->mmap_sem);
+
+	/* gary why ? */
+	addr = get_unmapped_area(NULL, STACK_TOP, PAGE_SIZE, 0, 0);
+	if (IS_ERR_VALUE(addr)) {
+		ret = addr;
+		goto up_fail;
+	}
+
+	ret = install_special_mapping(
+			mm,
+			addr,
+			PAGE_SIZE,
+			VM_READ|VM_EXEC|VM_MAYREAD|VM_MAYWRITE|VM_MAYEXEC,
+			&vdso_page);
+	if (ret)
+		goto up_fail;
+
+	mm->context.vdso = (void *)addr;
+
+up_fail:
+	up_write(&mm->mmap_sem);
+	return ret;
+}
+
+const char *arch_vma_name(struct vm_area_struct *vma)
+{
+	if (vma->vm_mm == NULL)
+		return NULL;
+
+	if (vma->vm_start == (long)vma->vm_mm->context.vdso)
+		return "[vdso]";
+	else
+		return NULL;
+}
+
diff --git a/arch/csky/kernel/vmlinux.lds.S b/arch/csky/kernel/vmlinux.lds.S
new file mode 100644
index 0000000..dfb8ef9
--- /dev/null
+++ b/arch/csky/kernel/vmlinux.lds.S
@@ -0,0 +1,65 @@
+#include <asm/vmlinux.lds.h>
+#include <asm/page.h>
+
+OUTPUT_ARCH(csky)
+ENTRY(_start)
+
+#ifndef __cskyBE__
+jiffies = jiffies_64;
+#else
+jiffies = jiffies_64 + 4;
+#endif
+
+#define VBR_BASE \
+	. = ALIGN(1024); \
+	VMLINUX_SYMBOL(vec_base) = .; \
+	. += 512;
+
+SECTIONS
+{
+	. = PAGE_OFFSET + CONFIG_RAM_BASE;
+	_text = .;
+	HEAD_TEXT_SECTION
+
+	_stext = .;
+	.text : AT(ADDR(.text) - LOAD_OFFSET) {
+		IRQENTRY_TEXT
+		SOFTIRQENTRY_TEXT
+		TEXT_TEXT
+		SCHED_TEXT
+		CPUIDLE_TEXT
+		LOCK_TEXT
+		KPROBES_TEXT
+		*(.fixup)
+		*(.gnu.warning)
+	} = 0
+	_etext = .;
+
+	/* __init_begin __init_end must be page aligned for free_initmem */
+	. = ALIGN(PAGE_SIZE);
+	__init_begin = .;
+
+	INIT_TEXT_SECTION(PAGE_SIZE)
+	INIT_DATA_SECTION(PAGE_SIZE)
+	PERCPU_SECTION(L1_CACHE_BYTES)
+
+	. = ALIGN(PAGE_SIZE);
+	__init_end = .;
+
+	_sdata = .;
+	RO_DATA_SECTION(PAGE_SIZE)
+	RW_DATA_SECTION(L1_CACHE_BYTES, PAGE_SIZE, THREAD_SIZE)
+	_edata = .;
+
+	NOTES
+	EXCEPTION_TABLE(L1_CACHE_BYTES)
+	BSS_SECTION(L1_CACHE_BYTES, PAGE_SIZE, L1_CACHE_BYTES)
+	VBR_BASE
+	_end = . ;
+
+	STABS_DEBUG
+	DWARF_DEBUG
+
+	DISCARDS
+}
+
diff --git a/arch/csky/lib/Makefile b/arch/csky/lib/Makefile
new file mode 100644
index 0000000..b7a2eb6
--- /dev/null
+++ b/arch/csky/lib/Makefile
@@ -0,0 +1,6 @@
+
+lib-y  := ashldi3.o ashrdi3.o lshrdi3.o muldi3.o \
+	 checksum.o memset.o usercopy.o delay.o
+
+# more
+obj-y  += ucmpdi2.o
diff --git a/arch/csky/lib/ashldi3.c b/arch/csky/lib/ashldi3.c
new file mode 100644
index 0000000..cc43c61
--- /dev/null
+++ b/arch/csky/lib/ashldi3.c
@@ -0,0 +1,31 @@
+#include "math-64bits.h"
+
+DItype
+__ashldi3 (DItype u, word_type b)
+{
+	DIunion w;
+	word_type bm;
+	DIunion uu;
+
+	if (b == 0)
+	        return u;
+
+	uu.ll = u;
+
+	bm = (sizeof (SItype) * BITS_PER_UNIT) - b;
+	if (bm <= 0)
+	{
+	        w.s.low = 0;
+	        w.s.high = (USItype)uu.s.low << -bm;
+	}
+	else
+	{
+	        USItype carries = (USItype)uu.s.low >> bm;
+	        w.s.low = (USItype)uu.s.low << b;
+	        w.s.high = ((USItype)uu.s.high << b) | carries;
+	}
+
+	return w.ll;
+}
+ 
+
diff --git a/arch/csky/lib/ashrdi3.c b/arch/csky/lib/ashrdi3.c
new file mode 100644
index 0000000..553705b
--- /dev/null
+++ b/arch/csky/lib/ashrdi3.c
@@ -0,0 +1,28 @@
+#include "math-64bits.h"
+
+DItype
+__ashrdi3 (DItype u, word_type b)
+{
+	DIunion w;
+	word_type bm;
+	DIunion uu;
+
+	if (b == 0)
+		return u;
+
+	uu.ll = u;
+
+	bm = (sizeof (SItype) * BITS_PER_UNIT) - b;
+	if (bm <= 0) {
+		/* w.s.high = 1..1 or 0..0 */
+		w.s.high = uu.s.high >> (sizeof (SItype) * BITS_PER_UNIT - 1);
+		w.s.low = uu.s.high >> -bm;
+	}
+	else {
+		USItype carries = (USItype)uu.s.high << bm;
+		w.s.high = uu.s.high >> b;
+		w.s.low = ((USItype)uu.s.low >> b) | carries;
+	}
+
+	return w.ll;
+}
diff --git a/arch/csky/lib/checksum.c b/arch/csky/lib/checksum.c
new file mode 100644
index 0000000..033b1f5
--- /dev/null
+++ b/arch/csky/lib/checksum.c
@@ -0,0 +1,150 @@
+#include <linux/module.h>
+#include <net/checksum.h>
+#include <asm/byteorder.h>
+
+static inline unsigned short from32to16(unsigned long x)
+{
+	/* add up 16-bit and 16-bit for 16+c bit */
+	x = (x & 0xffff) + (x >> 16);
+	/* add up carry.. */
+	x = (x & 0xffff) + (x >> 16);
+	return x;
+}
+
+static unsigned int do_csum(const unsigned char *buff, int len)
+{
+	int odd, count;
+	unsigned long result = 0;
+	
+	if (len <= 0)
+		goto out;
+	odd = 1 & (unsigned long) buff;
+	if (odd) {
+#ifdef __LITTLE_ENDIAN
+		result += (*buff << 8);
+#else
+		result = *buff;
+#endif
+		len--;
+		buff++;
+	}
+	count = len >> 1;       /* nr of 16-bit words.. */
+	if (count) {
+		if (2 & (unsigned long) buff) {
+			result += *(unsigned short *) buff;
+			count--;
+			len -= 2;
+			buff += 2;
+		}
+		count >>= 1;        /* nr of 32-bit words.. */
+		if (count) {
+			unsigned long carry = 0;
+			do {
+				unsigned long w = *(unsigned int *) buff;
+				count--;
+				buff += 4;
+				result += carry;
+				result += w;
+				carry = (w > result);
+			} while (count);
+			result += carry;
+			result = (result & 0xffff) + (result >> 16);
+		}
+		if (len & 2) {
+			result += *(unsigned short *) buff;
+			buff += 2;
+		}
+	}
+	if (len & 1)
+#ifdef __LITTLE_ENDIAN
+		result += *buff;
+#else
+		result += (*buff << 8);
+#endif
+	result = from32to16(result);
+	if (odd)
+		result = ((result >> 8) & 0xff) | ((result & 0xff) << 8);
+out:
+	return result;
+}
+
+/*
+ *	This is a version of ip_compute_csum() optimized for IP headers,
+ *	which always checksum on 4 octet boundaries.
+ */
+__sum16 ip_fast_csum(const void *iph, unsigned int ihl)
+{
+	return (__force __sum16)~do_csum(iph, ihl*4);
+}
+
+EXPORT_SYMBOL(ip_fast_csum);
+
+/*
+ * computes the checksum of a memory block at buff, length len,
+ * and adds in "sum" (32-bit)
+ *
+ * returns a 32-bit number suitable for feeding into itself
+ * or csum_tcpudp_magic
+ *
+ * this function must be called with even lengths, except
+ * for the last fragment, which may be odd
+ *
+ * it's best to have buff aligned on a 32-bit boundary
+ */
+__wsum csum_partial(const void *buff, int len, __wsum wsum)
+{
+	unsigned int sum = (__force unsigned int)wsum;
+	unsigned int result = do_csum(buff, len);
+
+	/* add in old sum, and carry.. */
+	result += sum;
+	if (sum > result)
+		result += 1;
+	return (__force __wsum)result;
+}
+
+EXPORT_SYMBOL(csum_partial);
+
+/*
+ * this routine is used for miscellaneous IP-like checksums, mainly
+ * in icmp.c
+ */
+__sum16 ip_compute_csum(const void *buff, int len)
+{
+	return (__force __sum16)~do_csum(buff,len);
+}
+
+EXPORT_SYMBOL(ip_compute_csum);
+
+/*
+ * copy from fs while checksumming, otherwise like csum_partial
+ */
+__wsum
+csum_partial_copy_from_user(const void __user *src, void *dst, int len,
+			    __wsum sum, int *csum_err)
+{
+	int missing;
+
+	missing = __copy_from_user(dst, src, len);
+	if (missing) {
+		memset(dst + len - missing, 0, missing);
+		*csum_err = -EFAULT;
+	} else
+		*csum_err = 0;
+
+	return csum_partial(dst, len, sum);
+}
+
+EXPORT_SYMBOL(csum_partial_copy_from_user);
+
+/*
+ * copy from ds while checksumming, otherwise like csum_partial
+ */
+__wsum
+csum_partial_copy(const void *src, void *dst, int len, __wsum sum)
+{
+	memcpy(dst, src, len);
+	return csum_partial(dst, len, sum);
+}
+
+EXPORT_SYMBOL(csum_partial_copy);
diff --git a/arch/csky/lib/delay.c b/arch/csky/lib/delay.c
new file mode 100644
index 0000000..4dfeb0b
--- /dev/null
+++ b/arch/csky/lib/delay.c
@@ -0,0 +1,43 @@
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/init.h>
+
+void __delay(unsigned long loops)
+{
+       __asm__ __volatile__ (
+#ifdef __CSKYABIV1__
+				".balignw 4, 0x1200\n\t"
+#else /* __CSKYABIV1__ */
+                                ".balignw 4, 0x6c8b\n\t"
+				"mov r0, r0\n\t"
+#endif
+                                "1: declt  %0\n\t"
+                                "bf   1b"
+                                  : "=r" (loops)
+	                          : "0" (loops) );
+}
+EXPORT_SYMBOL(__delay);
+
+extern unsigned long loops_per_jiffy;
+
+void __const_udelay(unsigned long xloops)
+{
+	unsigned long long loops;
+
+	loops = (unsigned long long)xloops * loops_per_jiffy * HZ;
+
+	__delay(loops >> 32);
+}
+EXPORT_SYMBOL(__const_udelay);
+
+void __udelay(unsigned long usecs)
+{
+	__const_udelay(usecs * 0x10C7UL); /* 2**32 / 1000000 (rounded up) */
+}
+EXPORT_SYMBOL(__udelay);
+
+void __ndelay(unsigned long nsecs)
+{
+	__const_udelay(nsecs * 0x5UL); /* 2**32 / 1000000000 (rounded up) */
+}
+EXPORT_SYMBOL(__ndelay);
diff --git a/arch/csky/lib/lshrdi3.c b/arch/csky/lib/lshrdi3.c
new file mode 100644
index 0000000..6dbb332
--- /dev/null
+++ b/arch/csky/lib/lshrdi3.c
@@ -0,0 +1,30 @@
+#include "math-64bits.h"
+
+DItype
+__lshrdi3 (DItype u, word_type b)
+{
+	DIunion w;
+	word_type bm;
+	DIunion uu;
+
+	if (b == 0)
+		return u;
+
+	uu.ll = u;
+
+	bm = (sizeof (SItype) * BITS_PER_UNIT) - b;
+	if (bm <= 0)
+	{
+		w.s.high = 0;
+		w.s.low = (USItype)uu.s.high >> -bm;
+	}
+	else
+	{
+		USItype carries = (USItype)uu.s.high << bm;
+		w.s.high = (USItype)uu.s.high >> b;
+		w.s.low = ((USItype)uu.s.low >> b) | carries;
+	}
+
+	return w.ll;
+}
+
diff --git a/arch/csky/lib/math-64bits.h b/arch/csky/lib/math-64bits.h
new file mode 100644
index 0000000..34ab71e
--- /dev/null
+++ b/arch/csky/lib/math-64bits.h
@@ -0,0 +1,31 @@
+#ifndef __CSKY_MATH_64BITS_H__
+#define __CSKY_MATH_64BITS_H__
+
+#include <asm/byteorder.h>
+
+#define BITS_PER_UNIT 8
+
+typedef          int SItype     __attribute__ ((mode (SI)));
+typedef unsigned int USItype    __attribute__ ((mode (SI)));
+typedef          int DItype     __attribute__ ((mode (DI)));
+typedef int word_type __attribute__ ((mode (__word__)));
+
+#ifdef __BIG_ENDIAN
+struct DIstruct {
+    SItype high, low;
+};
+#elif defined(__LITTLE_ENDIAN)
+struct DIstruct {
+    SItype low, high;
+};
+#else
+#error I feel sick.
+#endif
+
+typedef union
+{
+    struct DIstruct s;
+    DItype ll;
+} DIunion;
+
+#endif /* __CSKY_MATH_64BITS_H__ */
diff --git a/arch/csky/lib/memset.c b/arch/csky/lib/memset.c
new file mode 100644
index 0000000..94f3b29
--- /dev/null
+++ b/arch/csky/lib/memset.c
@@ -0,0 +1,43 @@
+#include <linux/types.h>
+
+/*
+ * memory set function.
+ */
+void *memset(void *dest, int c, size_t l)
+{
+	char	*d = dest;
+	int	ch = c;
+	int	tmp;
+
+	if ((long)d & 0x3)
+	{
+		while (l--) *d++ = ch;
+	}
+	else
+	{
+		ch &= 0xff;
+		tmp = (ch | ch << 8 | ch << 16 | ch << 24);
+
+		while (l >= 16)
+		{
+			*(((long *)d)) = tmp;
+			*(((long *)d)+1) = tmp;
+			*(((long *)d)+2) = tmp;
+			*(((long *)d)+3) = tmp;
+			l -= 16;
+			d += 16;
+		}
+		while (l > 3)
+		{
+			*(((long *)d)) = tmp;
+			d = d + 4;
+			l -= 4;
+		}
+		while (l)
+		{
+			*d++ = ch;
+			l--;
+		}
+	}
+	return dest;
+}
diff --git a/arch/csky/lib/muldi3.c b/arch/csky/lib/muldi3.c
new file mode 100644
index 0000000..141c9cf
--- /dev/null
+++ b/arch/csky/lib/muldi3.c
@@ -0,0 +1,57 @@
+#include "math-64bits.h"
+
+#ifndef W_TYPE_SIZE
+#define W_TYPE_SIZE 32
+#define UWtype      USItype
+#define UHWtype     USItype
+#define UDWtype     UDItype
+#endif
+
+#define __ll_B ((UWtype) 1 << (W_TYPE_SIZE / 2))
+#define __ll_lowpart(t) ((UWtype) (t) & (__ll_B - 1))
+#define __ll_highpart(t) ((UWtype) (t) >> (W_TYPE_SIZE / 2))
+
+
+#define umul_ppmm(w1, w0, u, v)                     \
+  do {                                              \
+    UWtype __x0, __x1, __x2, __x3;                  \
+    UHWtype __ul, __vl, __uh, __vh;                 \
+                                                    \
+    __ul = __ll_lowpart (u);                        \
+    __uh = __ll_highpart (u);                       \
+    __vl = __ll_lowpart (v);                        \
+    __vh = __ll_highpart (v);                       \
+                                                    \
+    __x0 = (UWtype) __ul * __vl;                    \
+    __x1 = (UWtype) __ul * __vh;                    \
+    __x2 = (UWtype) __uh * __vl;                    \
+    __x3 = (UWtype) __uh * __vh;                    \
+                                                    \
+    __x1 += __ll_highpart (__x0);/* this can't give carry */             \
+    __x1 += __x2;                /* but this indeed can */               \
+    if (__x1 < __x2)             /* did we get it? */                    \
+      __x3 += __ll_B;            /* yes, add it in the proper pos.  */   \
+                                                                         \
+    (w1) = __x3 + __ll_highpart (__x1);                                  \
+    (w0) = __ll_lowpart (__x1) * __ll_B + __ll_lowpart (__x0);           \
+  } while (0)
+
+#define __umulsidi3(u, v) \
+  ({DIunion __w;                                                        \
+    umul_ppmm (__w.s.high, __w.s.low, u, v);                            \
+    __w.ll; })
+
+DItype
+__muldi3 (DItype u, DItype v)
+{
+	DIunion w;
+	DIunion uu, vv;
+
+	uu.ll = u,
+  	vv.ll = v;
+
+	w.ll = __umulsidi3 (uu.s.low, vv.s.low);
+  	w.s.high += ((USItype) uu.s.low * (USItype) vv.s.high
+               + (USItype) uu.s.high * (USItype) vv.s.low);
+	return w.ll;
+}
diff --git a/arch/csky/lib/ucmpdi2.c b/arch/csky/lib/ucmpdi2.c
new file mode 100644
index 0000000..5425485
--- /dev/null
+++ b/arch/csky/lib/ucmpdi2.c
@@ -0,0 +1,39 @@
+#include <linux/module.h>
+
+typedef int word_type __attribute__ ((mode (__word__)));
+
+#ifdef __BIG_ENDIAN
+struct DWstruct {
+	int high, low;
+};
+#elif defined(__LITTLE_ENDIAN)
+struct DWstruct {
+	int low, high;
+};
+#else
+#error I feel sick.
+#endif
+
+typedef union {
+	struct DWstruct s;
+	long long ll;
+} DWunion;
+
+
+word_type __ucmpdi2(unsigned long long a, unsigned long long b)
+{
+	const DWunion au = {.ll = a};
+	const DWunion bu = {.ll = b};
+
+	if ((unsigned int) au.s.high < (unsigned int) bu.s.high)
+		return 0;
+	else if ((unsigned int) au.s.high > (unsigned int) bu.s.high)
+		return 2;
+	if ((unsigned int) au.s.low < (unsigned int) bu.s.low)
+		return 0;
+	else if ((unsigned int) au.s.low > (unsigned int) bu.s.low)
+		return 2;
+	return 1;
+}
+
+EXPORT_SYMBOL(__ucmpdi2);
diff --git a/arch/csky/lib/usercopy.c b/arch/csky/lib/usercopy.c
new file mode 100644
index 0000000..ac613c1
--- /dev/null
+++ b/arch/csky/lib/usercopy.c
@@ -0,0 +1,253 @@
+#include <asm/uaccess.h>
+#include <linux/types.h>
+
+
+unsigned long __generic_copy_from_user(void *to, const void *from, 
+							unsigned long n)
+{
+	if (access_ok(VERIFY_READ, from, n)) {
+		__copy_user_zeroing(to,from,n); 
+	}
+	else/* security hole - plug it */
+		memset(to,0, n);
+	return n;
+
+}
+
+unsigned long __generic_copy_to_user(void *to, const void *from,
+							unsigned long n)
+{
+	if (access_ok(VERIFY_WRITE, to, n)) {
+		__copy_user(to,from,n);
+	}
+	return n;
+
+}
+
+
+/*
+ * copy a null terminated string from userspace.	
+ */
+#define __do_strncpy_from_user(dst,src,count,res)       \
+do{                                                     \
+        int tmp;                                        \
+        long faultres;                                  \
+        __asm__ __volatile__(                           \
+        "       cmpnei  %3, 0           \n"             \
+        "       bf      4f              \n"             \
+        "1:     cmpnei  %1, 0          	\n"             \
+        "       bf      5f              \n"             \
+        "2:     ldb     %4, (%3, 0)     \n"             \
+        "       stb     %4, (%2, 0)     \n"             \
+        "       cmpnei  %4, 0           \n"             \
+        "       bf      3f              \n"             \
+        "       addi    %3,  1          \n"             \
+        "       addi    %2,  1          \n"             \
+        "       subi    %1,  1          \n"             \
+        "       br      1b              \n"             \
+        "3:     subu	%0, %1          \n"             \
+        "       br      5f              \n"             \
+        "4:     mov     %0, %5          \n"             \
+        "       br      5f              \n"             \
+        ".section __ex_table, \"a\"     \n"             \
+        ".align   2                     \n"             \
+        ".long    2b, 4b                \n"             \
+        ".previous                      \n"             \
+        "5:                             \n"             \
+          :"=r"(res),"=r"(count),"=r"(dst),"=r"(src), "=r"(tmp),"=r"(faultres) \
+          : "5"(-EFAULT),"0"(count), "1"(count), "2"(dst),"3"(src)     	       \
+          : "memory" );	                                \
+} while(0)		
+
+/*
+ * __strncpy_from_user: - Copy a NUL terminated string from userspace, with less checking.
+ * @dst:   Destination address, in kernel space.  This buffer must be at
+ *         least @count bytes long.
+ * @src:   Source address, in user space.
+ * @count: Maximum number of bytes to copy, including the trailing NUL.
+ * 
+ * Copies a NUL-terminated string from userspace to kernel space.
+ * Caller must check the specified block with access_ok() before calling
+ * this function.
+ *
+ * On success, returns the length of the string (not including the trailing
+ * NUL).
+ *
+ * If access to userspace fails, returns -EFAULT (some data may have been
+ * copied).
+ *
+ * If @count is smaller than the length of the string, copies @count bytes
+ * and returns @count.
+ */
+long
+__strncpy_from_user(char *dst, const char *src, long count)
+{
+	long res;
+	__do_strncpy_from_user(dst, src, count, res);
+	return res;
+}
+/*
+ * strncpy_from_user: - Copy a NUL terminated string from userspace.
+ * @dst:   Destination address, in kernel space.  This buffer must be at
+ *         least @count bytes long.
+ * @src:   Source address, in user space.
+ * @count: Maximum number of bytes to copy, including the trailing NUL.
+ * 
+ * Copies a NUL-terminated string from userspace to kernel space.
+ *
+ * On success, returns the length of the string (not including the trailing
+ * NUL).
+ *
+ * If access to userspace fails, returns -EFAULT (some data may have been
+ * copied).
+ *
+ * If @count is smaller than the length of the string, copies @count bytes
+ * and returns @count.
+ */
+long
+strncpy_from_user(char *dst, const char *src, long count)
+{
+	long res = -EFAULT;
+	if (access_ok(VERIFY_READ, src, 1))
+		__do_strncpy_from_user(dst, src, count, res);
+	return res;
+}
+
+/*
+ * strlen_user: - Get the size of a string in user space.
+ * @str: The string to measure.
+ * @n:   The maximum valid length
+ *
+ * Get the size of a NUL-terminated string in user space.
+ *
+ * Returns the size of the string INCLUDING the terminating NUL.
+ * On exception, returns 0.
+ * If the string is too long, returns a value greater than @n.
+ */
+long strnlen_user(const char *s, long n)
+{
+
+	unsigned long res,tmp;
+	if(s){
+		__asm__ __volatile__(
+        "       cmpnei  %1, 0           \n"
+        "       bf      3f              \n"
+        "1:     cmpnei  %0, 0           \n"              
+        "       bf      3f              \n"
+        "2:     ldb     %3, (%1, 0)     \n"             
+        "       cmpnei  %3, 0           \n"             
+        "       bf      3f              \n"             
+        "       subi    %0,  1          \n"             
+        "       addi    %1,  1          \n"             
+        "       br      1b              \n"
+        "3:     subu    %2, %0          \n"
+        "       addi    %2,  1          \n"             
+        "       br      5f              \n"             
+        "4:     movi    %0, 0           \n"             
+        "       br      5f              \n"             
+        ".section __ex_table, \"a\"     \n"             
+        ".align   2                     \n"
+        ".long    2b, 4b                \n"             
+        ".previous                      \n"             
+        "5:                             \n"             
+        :"=r"(n),"=r"(s), "=r"(res), "=r"(tmp)   
+        : "0"(n), "1"(s), "2"(n)      
+        : "cc" );
+		return res;     
+	}
+	return 0;     
+}
+
+#define __do_clear_user(addr, size)                             \
+do {                                                            \
+	int __d0;                                               \
+	int zvalue;                                             \
+	int tmp;                                                \
+	__asm__ __volatile__(                                   \
+		"0:     cmpnei  %1, 0           \n"             \
+		"       bf      7f              \n"             \
+		"       mov     %3, %1          \n"             \
+		"       andi    %3, 3           \n"             \
+		"       cmpnei  %3, 0           \n"             \
+		"       bf      1f              \n"             \
+		"       br      5f              \n"             \
+		"1:     cmplti  %0, 32          \n"   /* 4W */  \
+		"       bt      3f              \n"             \
+		"8:     stw     %2, (%1, 0)     \n"             \
+		"10:    stw     %2, (%1, 4)     \n"             \
+		"11:    stw     %2, (%1, 8)     \n"             \
+		"12:    stw     %2, (%1, 12)    \n"             \
+		"13:    stw     %2, (%1, 16)    \n"             \
+		"14:    stw     %2, (%1, 20)    \n"             \
+		"15:    stw     %2, (%1, 24)    \n"             \
+		"16:    stw     %2, (%1, 28)    \n"             \
+		"       addi    %1, 32          \n"             \
+		"       subi    %0, 32          \n"             \
+		"       br      1b              \n"             \
+		"3:     cmplti  %0, 4           \n"  /* 1W */   \
+		"       bt      5f              \n"             \
+		"4:     stw     %2, (%1, 0)     \n"             \
+		"       addi    %1, 4           \n"             \
+		"       subi    %0, 4           \n"             \
+		"       br      3b              \n"             \
+		"5:     cmpnei  %0, 0           \n"  /* 1B */   \
+		"9:     bf      7f              \n"             \
+		"6:     stb     %2, (%1, 0)     \n"             \
+		"       addi    %1,  1          \n"             \
+		"       subi    %0,  1          \n"             \
+		"       br      5b              \n"             \
+		".section __ex_table,\"a\"      \n"             \
+		".align   2                     \n"             \
+		".long    8b, 9b                \n"             \
+		".long    10b, 9b                \n"            \
+		".long    11b, 9b                \n"            \
+		".long    12b, 9b                \n"            \
+		".long    13b, 9b                \n"            \
+		".long    14b, 9b                \n"            \
+		".long    15b, 9b                \n"            \
+		".long    16b, 9b                \n"            \
+		".long    4b, 9b                \n"             \
+		".long    6b, 9b                \n"             \
+		".previous                      \n"             \
+		"7:                             \n"             \
+		: "=r"(size), "=r" (__d0), "=r"(zvalue), "=r"(tmp)    \
+		: "0"(size), "1"(addr), "2"(0)                  \
+		: "memory"                                      \
+	);                                                      \
+} while (0)
+
+/*
+ * clear_user: - Zero a block of memory in user space.
+ * @to:   Destination address, in user space.
+ * @n:    Number of bytes to zero.
+ *
+ * Zero a block of memory in user space.
+ *
+ * Returns number of bytes that could not be cleared.
+ * On success, this will be zero.
+ */	
+unsigned long 
+clear_user(void __user *to, unsigned long n)
+{
+	if (access_ok(VERIFY_WRITE, to, n))
+		__do_clear_user(to, n);
+	return n;
+}
+/*
+ * __clear_user: - Zero a block of memory in user space, with less checking.
+ * @to:   Destination address, in user space.
+ * @n:    Number of bytes to zero.
+ *
+ * Zero a block of memory in user space.  Caller must check
+ * the specified block with access_ok() before calling this function.
+ *
+ * Returns number of bytes that could not be cleared.
+ * On success, this will be zero.
+ */
+unsigned long
+__clear_user(void __user *to, unsigned long n)
+{
+	__do_clear_user(to, n);
+	return n;
+}
+                 
diff --git a/arch/csky/mm/Makefile b/arch/csky/mm/Makefile
new file mode 100644
index 0000000..e985a9c
--- /dev/null
+++ b/arch/csky/mm/Makefile
@@ -0,0 +1,6 @@
+obj-y := 			cache.o
+obj-y +=			init.o
+obj-y +=			ioremap.o
+obj-y +=			fault.o
+obj-y +=			dma-mapping.o
+obj-$(CONFIG_HIGHMEM) +=	highmem.o
diff --git a/arch/csky/mm/cache.c b/arch/csky/mm/cache.c
new file mode 100644
index 0000000..d7c54f7
--- /dev/null
+++ b/arch/csky/mm/cache.c
@@ -0,0 +1,143 @@
+#include <linux/kernel.h>
+#include <linux/mm.h>
+#include <linux/fs.h>
+#include <linux/syscalls.h>
+#include <linux/spinlock.h>
+#include <asm/uaccess.h>
+#include <asm/page.h>
+#include <asm/cache.h>
+#include <asm/cacheflush.h>
+#include <asm/cachectl.h>
+#include <abi/reg_ops.h>
+
+static DEFINE_SPINLOCK(cache_lock);
+
+#define __cache_op_line(i, value) \
+	__asm__ __volatile__( \
+		"mtcr	%0, cr22\n\t" \
+		"mtcr	%1, cr17\n\t" \
+		::"r"(i), "r"(value))
+
+#define CCR2_L2E (1 << 3)
+void
+cache_op_line(unsigned int i, unsigned int value)
+{
+	unsigned long flags;
+	spin_lock_irqsave(&cache_lock, flags);
+	__cache_op_line(i, value | CACHE_CLR | CACHE_OMS);
+	spin_unlock_irqrestore(&cache_lock, flags);
+
+	if (mfcr_ccr2() & CCR2_L2E)
+		L1_SYNC;
+	else
+		__asm__ __volatile__("sync\n\t");
+}
+
+void
+cache_op_all(unsigned int value, unsigned int l2)
+{
+	__asm__ __volatile__(
+		"mtcr	%0, cr17\n\t"
+		::"r"(value | CACHE_CLR));
+
+	if (mfcr_ccr2() & CCR2_L2E) {
+		L1_SYNC;
+		if (l2) goto flush_l2;
+	} else
+		__asm__ __volatile__("sync\n\t");
+
+	return;
+flush_l2:
+	__asm__ __volatile__(
+		"mtcr	%0, cr24\n\t"
+		"sync\n\t"
+		::"r"(value));
+}
+
+#define FLUSH_MAX PAGE_SIZE
+
+void
+cache_op_range(
+	unsigned int start,
+	unsigned int end,
+	unsigned int value,
+	unsigned int l2)
+{
+	unsigned long i, flags;
+	unsigned int val = value | CACHE_CLR | CACHE_OMS;
+	unsigned int l2_en = mfcr_ccr2() & CCR2_L2E;
+
+	if (unlikely((end - start) >= FLUSH_MAX) ||
+	    unlikely(start < PAGE_OFFSET) ||
+	    unlikely(start >= PAGE_OFFSET + LOWMEM_LIMIT)) {
+		cache_op_all(value, l2);
+		return;
+	}
+
+
+	for(i = start; i < end; i += L1_CACHE_BYTES) {
+		spin_lock_irqsave(&cache_lock, flags);
+		__cache_op_line(i, val);
+		if (l2_en) {
+			L1_SYNC;
+			if (l2) __asm__ __volatile__(
+				"mtcr	%0, cr24\n\t"
+				::"r"(val));
+		}
+		spin_unlock_irqrestore(&cache_lock, flags);
+	}
+
+	if(l2_en && !l2) return;
+
+	__asm__ __volatile__("sync\n\t");
+}
+
+SYSCALL_DEFINE3(cacheflush,
+		void __user *, addr,
+		unsigned long, bytes,
+		int, cache)
+{
+	switch(cache) {
+	case ICACHE:
+		cache_op_range(0, FLUSH_MAX, INS_CACHE|
+					CACHE_INV, 0);
+		break;
+	case DCACHE:
+		cache_op_range(0, FLUSH_MAX, DATA_CACHE|
+					CACHE_CLR|CACHE_INV, 0);
+		break;
+	case BCACHE:
+		cache_op_range(0, FLUSH_MAX, DATA_CACHE|INS_CACHE|
+					CACHE_CLR|CACHE_INV, 0);
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
+void __update_cache(struct vm_area_struct *vma, unsigned long address,
+	pte_t pte)
+{
+	unsigned long addr;
+	struct page *page;
+	unsigned long pfn;
+
+	pfn = pte_pfn(pte);
+	if (unlikely(!pfn_valid(pfn)))
+		return;
+
+	page = pfn_to_page(pfn);
+	addr = (unsigned long) page_address(page);
+
+	if (vma->vm_flags & VM_EXEC ||
+	    pages_do_alias(addr, address & PAGE_MASK))
+		cache_op_all(
+			DATA_CACHE|
+			CACHE_CLR|
+			CACHE_INV, 0);
+
+	clear_bit(PG_arch_1, &(page)->flags);
+}
+
diff --git a/arch/csky/mm/dma-mapping.c b/arch/csky/mm/dma-mapping.c
new file mode 100644
index 0000000..1dfa6cf
--- /dev/null
+++ b/arch/csky/mm/dma-mapping.c
@@ -0,0 +1,285 @@
+#include <linux/types.h>
+#include <linux/mm.h>
+#include <linux/dma-mapping.h>
+#include <linux/scatterlist.h>
+#include <linux/io.h>
+#include <linux/cache.h>
+#include <asm/cache.h>
+
+/*
+ * Some SOC set the ram and io in a seperate addr, then uncached ram couldn't be
+ * reached Directlly. We must use remap to fit it, but it will cause problem when
+ * some dma_alloc happens in irq/soft-irq context. eg: LC-235 in jira.
+ */
+#define BUGFIX_LC235
+
+static void *csky_dma_alloc(
+	struct device *dev,
+	size_t size,
+	dma_addr_t *dma_handle,
+	gfp_t gfp,
+	unsigned long attrs
+	)
+{
+	unsigned long ret;
+	void * vaddr;
+#ifndef BUGFIX_LC235
+	struct page *page;
+	pgprot_t prot;
+#endif
+
+	if (DMA_ATTR_NON_CONSISTENT & attrs)
+		panic("csky %s panic DMA_ATTR_NON_CONSISTENT.\n", __func__);
+
+	ret =  __get_free_pages((gfp | __GFP_NORETRY) & (~__GFP_HIGHMEM), get_order(size));
+	if (!ret) {
+		pr_err("csky %s no more free pages, %ld.\n", __func__, ret);
+		return NULL;
+	}
+
+	memset((void *)ret, 0, size);
+
+	cache_op_range(ret, ret + size,
+		DATA_CACHE|CACHE_CLR|CACHE_INV, 1);
+
+	*dma_handle = virt_to_phys((void*)ret);
+#ifndef BUGFIX_LC235
+	prot = __pgprot(_PAGE_PRESENT | __READABLE | __WRITEABLE |
+			_PAGE_GLOBAL | _CACHE_UNCACHED);
+
+	page = virt_to_page(ret);
+
+	vaddr = dma_common_contiguous_remap(page, PAGE_ALIGN(size), VM_USERMAP,
+			prot, __builtin_return_address(0));
+	if (!vaddr) {
+		BUG();
+	}
+#else
+	vaddr = (void *) UNCACHE_ADDR(ret);
+#endif
+
+	return vaddr;
+}
+
+static void csky_dma_free(
+	struct device *dev,
+	size_t size,
+	void *vaddr,
+	dma_addr_t dma_handle,
+	unsigned long attrs
+	)
+{
+	unsigned long addr = (unsigned long)phys_to_virt(dma_handle);
+
+#ifndef BUGFIX_LC235
+	vunmap(vaddr);
+#endif
+	free_pages(addr, get_order(size));
+}
+
+static inline void __dma_sync(
+	unsigned long addr,
+	size_t size,
+	enum dma_data_direction direction)
+{
+	switch (direction) {
+	case DMA_TO_DEVICE:
+		cache_op_range(
+			addr, addr+size,
+			DATA_CACHE|
+			CACHE_CLR, 1);
+		break;
+
+	case DMA_FROM_DEVICE:
+	case DMA_BIDIRECTIONAL:
+		cache_op_range(
+			addr, addr+size,
+			DATA_CACHE|
+			CACHE_CLR|
+			CACHE_INV, 1);
+		break;
+
+	default:
+		BUG();
+	}
+}
+
+static int csky_dma_map_sg(
+	struct device *dev,
+	struct scatterlist *sg,
+	int nents,
+	enum dma_data_direction direction,
+	unsigned long attrs
+	)
+{
+	int i;
+
+	BUG_ON(direction == DMA_NONE);
+
+	for (i = 0; i < nents; i++, sg++) {
+		unsigned long addr;
+
+		addr = (unsigned long) sg_virt(sg);
+		if (addr)
+			__dma_sync(addr, sg->length, direction);
+		sg->dma_address = virt_to_phys((void *)addr);
+	}
+
+	return nents;
+}
+
+void csky_dma_unmap_sg(
+	struct device *dev,
+	struct scatterlist *sg,
+	int nhwentries,
+	enum dma_data_direction direction,
+	unsigned long attrs
+	)
+{
+	unsigned long addr;
+	int i;
+
+	BUG_ON(direction == DMA_NONE);
+
+	for (i = 0; i < nhwentries; i++, sg++) {
+		if (direction != DMA_TO_DEVICE) {
+			addr = (unsigned long) sg_virt(sg);
+			if (addr)
+				__dma_sync(addr, sg->length, direction);
+		}
+	}
+}
+
+static dma_addr_t csky_dma_map_page(
+	struct device *dev,
+	struct page *page,
+	unsigned long offset,
+	size_t size,
+	enum dma_data_direction direction,
+	unsigned long attrs
+	)
+{
+	unsigned long addr;
+
+	BUG_ON(direction == DMA_NONE);
+
+	addr = (unsigned long) page_address(page) + offset;
+
+	__dma_sync(addr, size, direction);
+
+	return page_to_phys(page) + offset;
+}
+
+static void csky_dma_unmap_page(
+	struct device *dev,
+	dma_addr_t dma_handle,
+	size_t size,
+	enum dma_data_direction direction,
+	unsigned long attrs
+	)
+{
+	unsigned long addr;
+
+	BUG_ON(direction == DMA_NONE);
+
+	addr = (unsigned long)phys_to_virt((unsigned long)dma_handle);
+	__dma_sync(addr, size, direction);
+}
+
+static void csky_dma_sync_single_for_cpu(
+	struct device *dev,
+	dma_addr_t dma_handle,
+	size_t size,
+	enum dma_data_direction direction
+	)
+{
+	unsigned long addr;
+
+	BUG_ON(direction == DMA_NONE);
+
+	addr = (unsigned long)phys_to_virt((unsigned long)dma_handle);
+	__dma_sync(addr, size, direction);
+}
+
+static void csky_dma_sync_single_for_device(
+	struct device *dev,
+	dma_addr_t dma_handle,
+	size_t size,
+	enum dma_data_direction direction
+	)
+{
+	unsigned long addr;
+
+	BUG_ON(direction == DMA_NONE);
+
+	addr = (unsigned long)phys_to_virt((unsigned long)dma_handle);
+	__dma_sync(addr, size, direction);
+}
+
+static void csky_dma_sync_sg_for_cpu(
+	struct device *dev,
+	struct scatterlist *sg,
+	int nelems,
+	enum dma_data_direction direction
+	)
+{
+	int i;
+
+	BUG_ON(direction == DMA_NONE);
+
+	/* Make sure that gcc doesn't leave the empty loop body.  */
+	for (i = 0; i < nelems; i++, sg++) {
+		__dma_sync((unsigned long)page_address(sg_page(sg)),
+				sg->length, direction);
+	}
+}
+
+static void csky_dma_sync_sg_for_device(
+	struct device *dev,
+	struct scatterlist *sg,
+	int nelems,
+	enum dma_data_direction direction
+	)
+{
+	int i;
+
+	BUG_ON(direction == DMA_NONE);
+
+	/* Make sure that gcc doesn't leave the empty loop body.  */
+	for (i = 0; i < nelems; i++, sg++) {
+		__dma_sync((unsigned long)page_address(sg_page(sg)),
+				sg->length, direction);
+	}
+}
+
+int csky_dma_mapping_error(struct device *dev, dma_addr_t dma_addr)
+{
+	return 0;
+}
+
+int csky_dma_supported(struct device *dev, u64 mask)
+{
+	return 1;
+}
+
+struct dma_map_ops csky_dma_map_ops = {
+	.alloc			= csky_dma_alloc,
+	.free			= csky_dma_free,
+	.mmap			= NULL,
+	.get_sgtable		= NULL,
+	.map_page		= csky_dma_map_page,
+	.unmap_page		= csky_dma_unmap_page,
+
+	.map_sg			= csky_dma_map_sg,
+	.unmap_sg		= csky_dma_unmap_sg,
+	.sync_single_for_cpu	= csky_dma_sync_single_for_cpu,
+	.sync_single_for_device	= csky_dma_sync_single_for_device,
+	.sync_sg_for_cpu	= csky_dma_sync_sg_for_cpu,
+	.sync_sg_for_device	= csky_dma_sync_sg_for_device,
+
+	.mapping_error		= csky_dma_mapping_error,
+	.dma_supported		= csky_dma_supported,
+	.set_dma_mask		= NULL,
+};
+EXPORT_SYMBOL(csky_dma_map_ops);
+
diff --git a/arch/csky/mm/fault.c b/arch/csky/mm/fault.c
new file mode 100755
index 0000000..9570ec8
--- /dev/null
+++ b/arch/csky/mm/fault.c
@@ -0,0 +1,265 @@
+#include <linux/signal.h>
+#include <linux/module.h>
+#include <linux/sched.h>
+#include <linux/interrupt.h>
+#include <linux/kernel.h>
+#include <linux/errno.h>
+#include <linux/string.h>
+#include <linux/types.h>
+#include <linux/ptrace.h>
+#include <linux/mman.h>
+#include <linux/mm.h>
+#include <linux/smp.h>
+#include <linux/version.h>
+#include <linux/vt_kern.h>
+#include <linux/kernel.h>
+
+#include <asm/hardirq.h>
+#include <asm/mmu_context.h>
+#include <asm/uaccess.h>
+#include <asm/traps.h>
+#include <asm/page.h>
+
+extern void die_if_kernel(char *, struct pt_regs *, long);
+
+static inline int delay_slot(struct pt_regs *regs)
+{
+        return 0;
+}
+
+static inline unsigned long exception_epc(struct pt_regs *regs)
+{
+        if (!delay_slot(regs))
+                return regs->pc;
+
+        return regs->pc + 4;
+}
+
+int fixup_exception(struct pt_regs *regs)
+{
+        const struct exception_table_entry *fixup;
+
+        fixup = search_exception_tables(exception_epc(regs));
+        if (fixup) {
+                regs->pc = fixup->nextinsn;
+
+                return 1;
+        }
+
+        return 0;
+}
+
+/*
+ * This routine handles page faults.  It determines the address,
+ * and the problem, and then passes it off to one of the appropriate
+ * routines.
+ */
+asmlinkage void do_page_fault(struct pt_regs *regs, unsigned long write,
+                              unsigned long address)
+{
+        struct vm_area_struct * vma = NULL;
+        struct task_struct *tsk = current;
+        struct mm_struct *mm = tsk->mm;
+        siginfo_t info;
+        int fault;
+
+        info.si_code = SEGV_MAPERR;
+
+        /*
+         * We fault-in kernel-space virtual memory on-demand. The
+         * 'reference' page table is init_mm.pgd.
+         *
+         * NOTE! We MUST NOT take any locks for this case. We may
+         * be in an interrupt or a critical region, and should
+         * only copy the information from the master page table,
+         * nothing more.
+         */
+        if (unlikely(address >= VMALLOC_START && address <= VMALLOC_END))
+                goto vmalloc_fault;
+#ifdef MODULE_START
+        if (unlikely(address >= MODULE_START && address < MODULE_END))
+                goto vmalloc_fault;
+#endif
+
+        /*
+         * If we're in an interrupt or have no user
+         * context, we must not take the fault..
+         */
+        if (in_atomic() || !mm)
+                goto bad_area_nosemaphore;
+
+        down_read(&mm->mmap_sem);
+        vma = find_vma(mm, address);
+        if (!vma)
+                goto bad_area;
+        if (vma->vm_start <= address)
+                goto good_area;
+        if (!(vma->vm_flags & VM_GROWSDOWN))
+                goto bad_area;
+        if (expand_stack(vma, address))
+                goto bad_area;
+/*
+ * Ok, we have a good vm_area for this memory access, so
+ * we can handle it..
+ */
+good_area:
+info.si_code = SEGV_ACCERR;
+
+        if (write) {
+                if (!(vma->vm_flags & VM_WRITE))
+                        goto bad_area;
+        } else {
+                if (!(vma->vm_flags & (VM_READ | VM_WRITE | VM_EXEC)))
+                        goto bad_area;
+        }
+
+        /*
+         * If for any reason at all we couldn't handle the fault,
+         * make sure we exit gracefully rather than endlessly redo
+         * the fault.
+         */
+        fault = handle_mm_fault(vma, address, write ? FAULT_FLAG_WRITE : 0);
+        if (unlikely(fault & VM_FAULT_ERROR)) {
+                if (fault & VM_FAULT_OOM)
+                        goto out_of_memory;
+                else if (fault & VM_FAULT_SIGBUS)
+                        goto do_sigbus;
+                else if (fault & VM_FAULT_SIGSEGV)
+                        goto bad_area;
+                BUG();
+        }
+        if (fault & VM_FAULT_MAJOR)
+                tsk->maj_flt++;
+        else
+                tsk->min_flt++;
+
+        up_read(&mm->mmap_sem);
+        return;
+
+/*
+ * Something tried to access memory that isn't in our memory map..
+ * Fix it, but check if it's kernel or user first..
+ */
+bad_area:
+        up_read(&mm->mmap_sem);
+
+bad_area_nosemaphore:
+        /* User mode accesses just cause a SIGSEGV */
+        if (user_mode(regs)) {
+                tsk->thread.address = address;
+                tsk->thread.error_code = write;
+#if 0
+                printk(KERN_ERR "do_page_fault() #2: sending SIGSEGV to %s for"
+                       "invalid %s\n%08lx (epc == %08lx)\n",
+                       tsk->comm,
+                       write ? "write access to" : "read access from",
+                       address,
+                       regs->pc);
+#endif
+                info.si_signo = SIGSEGV;
+                info.si_errno = 0;
+                /* info.si_code has been set above */
+                info.si_addr = (void __user *) address;
+                force_sig_info(SIGSEGV, &info, tsk);
+                return;
+        }
+
+no_context:
+        /* Are we prepared to handle this kernel fault?  */
+        if (fixup_exception(regs)) {
+                current->thread.baduaddr = address;
+                return;
+        }
+        /*
+         * Oops. The kernel tried to access some bad page. We'll have to
+         * terminate things with extreme prejudice.
+         */
+        bust_spinlocks(1);
+
+        printk(KERN_ALERT "Unable to handle kernel paging request at virtual "
+               "address %08lx, epc == %08lx\n",
+               address, regs->pc);
+	die_if_kernel("Oops", regs, write);
+
+out_of_memory:
+        /*
+         * We ran out of memory, call the OOM killer, and return the userspace
+         * (which will retry the fault, or kill us if we got oom-killed).
+         */
+        pagefault_out_of_memory();
+        return;
+
+do_sigbus:
+        up_read(&mm->mmap_sem);
+
+        /* Kernel mode? Handle exceptions or die */
+        if (!user_mode(regs))
+                goto no_context;
+        else
+        /*
+         * Send a sigbus, regardless of whether we were in kernel
+         * or user mode.
+         */
+#if 0
+                printk("do_page_fault() #3: sending SIGBUS to %s for "
+                       "invalid %s\n%0*lx (epc == %0*lx, ra == %0*lx)\n",
+                       tsk->comm,
+                       write ? "write access to" : "read access from",
+                       field, address,
+                       field, (unsigned long) regs->cp0_epc,
+                       field, (unsigned long) regs->regs[31]);
+#endif
+        tsk->thread.address = address;
+        info.si_signo = SIGBUS;
+        info.si_errno = 0;
+        info.si_code = BUS_ADRERR;
+        info.si_addr = (void __user *) address;
+        force_sig_info(SIGBUS, &info, tsk);
+
+        return;
+vmalloc_fault:
+        {
+                /*
+                 * Synchronize this task's top level page-table
+                 * with the 'reference' page table.
+                 *
+                 * Do _not_ use "tsk" here. We might be inside
+                 * an interrupt in the middle of a task switch..
+                 */
+                int offset = __pgd_offset(address);
+                pgd_t *pgd, *pgd_k;
+                pud_t *pud, *pud_k;
+                pmd_t *pmd, *pmd_k;
+                pte_t *pte_k;
+
+#ifdef CONFIG_MMU_HARD_REFILL
+                unsigned long pgd_base;
+		pgd_base = tlb_get_pgd();
+                pgd = (pgd_t *)pgd_base + offset;
+#else
+                pgd = (pgd_t *) pgd_current[raw_smp_processor_id()] + offset;
+#endif /* CONFIG_MMU_HARD_REFILL */
+                pgd_k = init_mm.pgd + offset;
+
+                if (!pgd_present(*pgd_k))
+                        goto no_context;
+                set_pgd(pgd, *pgd_k);
+
+                pud = pud_offset(pgd, address);
+                pud_k = pud_offset(pgd_k, address);
+                if (!pud_present(*pud_k))
+                        goto no_context;
+
+                pmd = pmd_offset(pud, address);
+                pmd_k = pmd_offset(pud_k, address);
+                if (!pmd_present(*pmd_k))
+                        goto no_context;
+                set_pmd(pmd, *pmd_k);
+
+                pte_k = pte_offset_kernel(pmd_k, address);
+                if (!pte_present(*pte_k))
+                        goto no_context;
+                return;
+        }
+}
+
diff --git a/arch/csky/mm/highmem.c b/arch/csky/mm/highmem.c
new file mode 100644
index 0000000..5aa6818
--- /dev/null
+++ b/arch/csky/mm/highmem.c
@@ -0,0 +1,213 @@
+#include <linux/module.h>
+#include <linux/highmem.h>
+#include <linux/smp.h>
+#include <linux/bootmem.h>
+#include <asm/fixmap.h>
+#include <asm/tlbflush.h>
+#include <asm/cacheflush.h>
+
+static pte_t *kmap_pte;
+
+unsigned long highstart_pfn, highend_pfn;
+
+void *kmap(struct page *page)
+{
+	void *addr;
+
+	might_sleep();
+	if (!PageHighMem(page))
+		return page_address(page);
+	addr = kmap_high(page);
+        local_flush_tlb_one((unsigned long)addr);
+
+	return addr;
+}
+EXPORT_SYMBOL(kmap);
+
+void kunmap(struct page *page)
+{
+	BUG_ON(in_interrupt());
+	if (!PageHighMem(page))
+		return;
+	kunmap_high(page);
+}
+EXPORT_SYMBOL(kunmap);
+
+/*
+ * kmap_atomic/kunmap_atomic is significantly faster than kmap/kunmap because
+ * no global lock is needed and because the kmap code must perform a global TLB
+ * invalidation when the kmap pool wraps.
+ *
+ * However when holding an atomic kmap is is not legal to sleep, so atomic
+ * kmaps are appropriate for short, tight code paths only.
+ */
+
+void *kmap_atomic(struct page *page)
+{
+	unsigned long vaddr;
+	int idx, type;
+
+	/* even !CONFIG_PREEMPT needs this, for in_atomic in do_page_fault */
+	pagefault_disable();
+	if (!PageHighMem(page))
+		return page_address(page);
+
+	type = kmap_atomic_idx_push();
+	idx = type + KM_TYPE_NR*smp_processor_id();
+	vaddr = __fix_to_virt(FIX_KMAP_BEGIN + idx);
+#ifdef CONFIG_DEBUG_HIGHMEM
+	BUG_ON(!pte_none(*(kmap_pte - idx)));
+#endif
+	set_pte(kmap_pte-idx, mk_pte(page, PAGE_KERNEL));
+	local_flush_tlb_one((unsigned long)vaddr);
+
+	return (void*) vaddr;
+}
+EXPORT_SYMBOL(kmap_atomic);
+
+void __kunmap_atomic(void *kvaddr)
+{
+	unsigned long vaddr = (unsigned long) kvaddr & PAGE_MASK;
+	int type;
+	
+	if (vaddr < FIXADDR_START) { // FIXME
+	    pagefault_enable();
+	    return;
+	}
+	
+	type = kmap_atomic_idx();
+#ifdef CONFIG_DEBUG_HIGHMEM
+	int idx = type + KM_TYPE_NR * smp_processor_id();
+
+	BUG_ON(vaddr != __fix_to_virt(FIX_KMAP_BEGIN + idx));
+
+	/*
+	 * force other mappings to Oops if they'll try to access
+	 * this pte without first remap it
+	 */
+	pte_clear(&init_mm, vaddr, kmap_pte-idx);
+	local_flush_tlb_one(vaddr);
+#endif
+
+	kmap_atomic_idx_pop();
+	pagefault_enable();
+}
+EXPORT_SYMBOL(__kunmap_atomic);
+
+/*
+ * This is the same as kmap_atomic() but can map memory that doesn't
+ * have a struct page associated with it.
+ */
+void *kmap_atomic_pfn(unsigned long pfn)
+{
+	unsigned long vaddr;
+	int idx, type;
+
+	pagefault_disable();
+
+	type = kmap_atomic_idx_push();
+	idx = type + KM_TYPE_NR*smp_processor_id();
+	vaddr = __fix_to_virt(FIX_KMAP_BEGIN + idx);
+	set_pte(kmap_pte-idx, pfn_pte(pfn, PAGE_KERNEL));
+	local_flush_tlb_one(vaddr);
+
+	return (void*) vaddr;
+}
+
+struct page *kmap_atomic_to_page(void *ptr)
+{
+	unsigned long idx, vaddr = (unsigned long)ptr;
+	pte_t *pte;
+
+	if (vaddr < FIXADDR_START)
+		return virt_to_page(ptr);
+
+	idx = virt_to_fix(vaddr);
+	pte = kmap_pte - (idx - FIX_KMAP_BEGIN);
+	return pte_page(*pte);
+}
+
+static void __init fixrange_init (unsigned long start, unsigned long end,
+                   pgd_t *pgd_base)
+{
+#ifdef CONFIG_HIGHMEM
+	pgd_t *pgd;
+	pud_t *pud;
+	pmd_t *pmd;
+	pte_t *pte;
+	int i, j, k;
+	unsigned long vaddr;
+
+	vaddr = start;
+	i = __pgd_offset(vaddr);
+	j = __pud_offset(vaddr);
+	k = __pmd_offset(vaddr);
+	pgd = pgd_base + i;
+
+	for ( ; (i < PTRS_PER_PGD) && (vaddr != end); pgd++, i++) {
+		pud = (pud_t *)pgd;
+		for ( ; (j < PTRS_PER_PUD) && (vaddr != end); pud++, j++) {
+			pmd = (pmd_t *)pud;
+			for (; (k < PTRS_PER_PMD) && (vaddr != end); pmd++, k++) {
+				if (pmd_none(*pmd)) {
+					pte = (pte_t *) alloc_bootmem_low_pages(PAGE_SIZE);
+#ifdef CONFIG_MMU_HARD_REFILL
+/* hard refill need fill PA. */
+					set_pmd(pmd, __pmd(__pa(pte)));
+#else
+					set_pmd(pmd, __pmd((unsigned long)pte));
+#endif
+					BUG_ON(pte != pte_offset_kernel(pmd, 0));
+				}
+				vaddr += PMD_SIZE;
+			}
+			k = 0;
+		}
+		j = 0;
+	}
+#endif
+}
+
+void __init fixaddr_kmap_pages_init(void)
+{
+	unsigned long vaddr;
+	pgd_t *pgd_base;
+#ifdef CONFIG_HIGHMEM
+	pgd_t *pgd;
+	pmd_t *pmd;
+	pud_t *pud;
+	pte_t *pte;
+#endif
+	pgd_base = swapper_pg_dir;
+
+	/*
+	 * Fixed mappings:
+	 */
+	vaddr = __fix_to_virt(__end_of_fixed_addresses - 1) & PMD_MASK;
+	fixrange_init(vaddr, 0, pgd_base);
+
+#ifdef CONFIG_HIGHMEM
+	/*
+	 * Permanent kmaps:
+	 */
+	vaddr = PKMAP_BASE;
+	fixrange_init(vaddr, vaddr + PAGE_SIZE*LAST_PKMAP, pgd_base);
+
+	pgd = swapper_pg_dir + __pgd_offset(vaddr);
+	pud = pud_offset(pgd, vaddr);
+	pmd = pmd_offset(pud, vaddr);
+	pte = pte_offset_kernel(pmd, vaddr);
+	pkmap_page_table = pte;
+#endif
+}
+
+void __init kmap_init(void)
+{
+	unsigned long kmap_vstart;
+
+	fixaddr_kmap_pages_init();
+
+	/* cache the first kmap pte */
+	kmap_vstart = __fix_to_virt(FIX_KMAP_BEGIN);
+	kmap_pte = kmap_get_fixmap_pte(kmap_vstart);
+}
diff --git a/arch/csky/mm/init.c b/arch/csky/mm/init.c
new file mode 100644
index 0000000..281f5ab
--- /dev/null
+++ b/arch/csky/mm/init.c
@@ -0,0 +1,122 @@
+#include <linux/bug.h>
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/signal.h>
+#include <linux/sched.h>
+#include <linux/kernel.h>
+#include <linux/errno.h>
+#include <linux/string.h>
+#include <linux/types.h>
+#include <linux/pagemap.h>
+#include <linux/ptrace.h>
+#include <linux/mman.h>
+#include <linux/mm.h>
+#include <linux/bootmem.h>
+#include <linux/highmem.h>
+#include <linux/memblock.h>
+#include <linux/swap.h>
+#include <linux/proc_fs.h>
+#include <linux/pfn.h>
+
+#include <asm/setup.h>
+#include <asm/cachectl.h>
+#include <asm/dma.h>
+#include <asm/pgtable.h>
+#include <asm/pgalloc.h>
+#include <asm/mmu_context.h>
+#include <asm/sections.h>
+#include <asm/tlb.h>
+
+#ifdef CONFIG_DISCONTIGMEM
+#error "CONFIG_HIGHMEM and CONFIG_DISCONTIGMEM dont work together yet"
+#endif
+
+#ifndef CONFIG_MMU_HARD_REFILL
+unsigned long pgd_current[NR_CPUS];
+#endif
+
+pgd_t swapper_pg_dir[PTRS_PER_PGD] __page_aligned_bss;
+pte_t invalid_pte_table[PTRS_PER_PTE] __page_aligned_bss;
+unsigned long empty_zero_page[PAGE_SIZE / sizeof(unsigned long)] __page_aligned_bss;
+
+void __init mem_init(void)
+{
+#ifdef CONFIG_HIGHMEM
+	unsigned long tmp;
+	max_mapnr = highend_pfn;
+#else
+	max_mapnr = max_low_pfn;
+#endif
+	high_memory = (void *) __va(max_low_pfn << PAGE_SHIFT);
+
+	free_all_bootmem();
+
+#ifdef CONFIG_HIGHMEM
+	for (tmp = highstart_pfn; tmp < highend_pfn; tmp++) {
+		struct page *page = pfn_to_page(tmp);
+
+		/* FIXME not sure about */
+		if (!memblock_is_reserved(tmp << PAGE_SHIFT))
+			free_highmem_page(page);
+	}
+#endif
+	mem_init_print_info(NULL);
+}
+
+#ifdef CONFIG_BLK_DEV_INITRD
+void free_initrd_mem(unsigned long start, unsigned long end)
+{
+	if (start < end)
+		printk(KERN_INFO "Freeing initrd memory: %ldk freed\n",
+                     (end - start) >> 10);
+
+	for (; start < end; start += PAGE_SIZE) {
+	ClearPageReserved(virt_to_page(start));
+	init_page_count(virt_to_page(start));
+	free_page(start);
+	totalram_pages++;
+    }
+}
+#endif
+
+extern char __init_begin[], __init_end[];
+extern void __init prom_free_prom_memory(void);
+
+void free_initmem(void)
+{
+	unsigned long addr;
+
+	addr = (unsigned long) &__init_begin;
+	while (addr < (unsigned long) &__init_end) {
+	        ClearPageReserved(virt_to_page(addr));
+	        init_page_count(virt_to_page(addr));
+	        free_page(addr);
+	        totalram_pages++;
+	        addr += PAGE_SIZE;
+	}
+	printk(KERN_INFO "Freeing unused kernel memory: %dk freed\n",
+	        ((unsigned int)&__init_end - (unsigned int)&__init_begin) >> 10);
+}
+
+void pgd_init(unsigned long *p)
+{
+	int i;
+
+#ifdef CONFIG_MMU_HARD_REFILL
+#define val	(unsigned long) __pa(invalid_pte_table);
+#else
+#define val	(unsigned long) invalid_pte_table;
+#endif
+
+	for (i = 0; i < USER_PTRS_PER_PGD*2; i+=8) {
+		p[i + 0] = val;
+		p[i + 1] = val;
+		p[i + 2] = val;
+		p[i + 3] = val;
+		p[i + 4] = val;
+		p[i + 5] = val;
+		p[i + 6] = val;
+		p[i + 7] = val;
+	}
+}
+
diff --git a/arch/csky/mm/ioremap.c b/arch/csky/mm/ioremap.c
new file mode 100644
index 0000000..1b75798
--- /dev/null
+++ b/arch/csky/mm/ioremap.c
@@ -0,0 +1,47 @@
+#include <linux/export.h>
+#include <linux/mm.h>
+#include <linux/vmalloc.h>
+#include <linux/io.h>
+
+#include <asm/pgtable.h>
+
+void __iomem *ioremap(phys_addr_t addr, size_t size)
+{
+	phys_addr_t last_addr;
+	unsigned long offset, vaddr;
+	struct vm_struct *area;
+	pgprot_t prot;
+
+	last_addr = addr + size - 1;
+	if (!size || last_addr < addr) {
+		return NULL;
+	}
+
+	offset = addr & (~PAGE_MASK);
+	addr &= PAGE_MASK;
+	size = PAGE_ALIGN(size + offset);
+
+	area = get_vm_area_caller(size, VM_ALLOC, __builtin_return_address(0));
+	if (!area) {
+		return NULL;
+	}
+	vaddr = (unsigned long)area->addr;
+
+	prot = __pgprot(_PAGE_PRESENT | __READABLE | __WRITEABLE |
+			_PAGE_GLOBAL | _CACHE_UNCACHED);
+
+	if (ioremap_page_range(vaddr, vaddr + size, addr, prot)) {
+		free_vm_area(area);
+		return NULL;
+	}
+
+	return (void __iomem *)(vaddr + offset);
+}
+EXPORT_SYMBOL(ioremap);
+
+void iounmap(void __iomem *addr)
+{
+	vunmap((void *)((unsigned long)addr & PAGE_MASK));
+}
+EXPORT_SYMBOL(iounmap);
+
diff --git a/arch/csky/oprofile/Makefile b/arch/csky/oprofile/Makefile
new file mode 100644
index 0000000..3038fab
--- /dev/null
+++ b/arch/csky/oprofile/Makefile
@@ -0,0 +1,15 @@
+obj-$(CONFIG_OPROFILE) += oprofile.o
+
+DRIVER_OBJS := $(addprefix ../../../drivers/oprofile/, \
+		oprof.o cpu_buffer.o buffer_sync.o \
+		event_buffer.o oprofile_files.o \
+		oprofilefs.o oprofile_stats.o \
+		timer_int.o )
+
+# FIXME:
+# HW_PERF need perf_pmu_register with kernel/event framework.
+ifeq ($(CONFIG_HW_PERF_EVENTS),y)
+DRIVER_OBJS += $(addprefix ../../../drivers/oprofile/, oprofile_perf.o)
+endif
+
+oprofile-y := $(DRIVER_OBJS) init.o
diff --git a/arch/csky/oprofile/init.c b/arch/csky/oprofile/init.c
new file mode 100644
index 0000000..241c52c
--- /dev/null
+++ b/arch/csky/oprofile/init.c
@@ -0,0 +1,14 @@
+#include <linux/kernel.h>
+#include <linux/oprofile.h>
+#include <linux/errno.h>
+#include <linux/init.h>
+
+int __init oprofile_arch_init(struct oprofile_operations *ops)
+{
+	return oprofile_perf_init(ops);
+}
+
+void oprofile_arch_exit(void)
+{
+	oprofile_perf_exit();
+}
